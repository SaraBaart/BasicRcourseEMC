[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Basic R Course",
    "section": "",
    "text": "Welcome\nHi, welcome to the Basic R Course manual."
  },
  {
    "objectID": "introduction_history.html#course-overview",
    "href": "introduction_history.html#course-overview",
    "title": "1  Introduction and History",
    "section": "1.1 Course Overview",
    "text": "1.1 Course Overview\nIn the first part of the course we are introduced to the R software package, or environment, and learn about R, how to interact with it and it’s basic programming elements. In the second part of the course we’ll learn how to use R for it’s intended function: doing statistics quickly and effectively.\nWe will cover essential topics including how to use R and why we use it; objects, classes and functions; and creating, importing, saving, manipulating, combining, sub-setting and plotting data.\nBy the end of the first couple of introductory days I expect that you can write your own code and have a reasonable understanding of what’s going on when you cut and paste other people’s code, which is typical of how people get started with R (or any other language for that matter)."
  },
  {
    "objectID": "introduction_history.html#introduction",
    "href": "introduction_history.html#introduction",
    "title": "1  Introduction and History",
    "section": "1.2 Introduction",
    "text": "1.2 Introduction\n\nHistory\nBefore R there was the statistical analysis program, S, developed at Bell Laboratories in 1976 by John Chambers. S was later commercialised as S-PLUS. John Chambers is also a current member of the R core group responsible for developing R.\nRoss Ihaka and Robert Gentleman of Dept of Statistics, University of Auckland, New Zealand begin coding (1991) the S clone, R, as an open source alternative for academic use. Together with the R core group’ they released version 1 under the GNU Public License (GPL) v2 and v3 in 2000. The name, R, probably derives from the first letter of the creator’s names. http://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-is-R-named-R_003f"
  },
  {
    "objectID": "introduction_history.html#get-it",
    "href": "introduction_history.html#get-it",
    "title": "1  Introduction and History",
    "section": "1.3 Get it",
    "text": "1.3 Get it\n\nInstall it\nTo get R on your PC first you need to install the core R application. Of course you’ll need to download the version for your operating system and architecture first.\n\nFor Linux: https://cran.r-project.org/bin/linux/\nFor Mac: https://cran.r-project.org/bin/macosx/\nFor Windows: https://cran.r-project.org/bin/windows/\n\nAlthough R for Windows (and Mac?) ships with a basic text editor, and it’s possible to execute code from the terminal under linux, a fully featured editor increases convenience and productivity. Grab an awesome text editor:\nRStudio: https://www.rstudio.com/products/rstudio/\nEmacs/ESS: http://ess.r-project.org/index.php?Section=download\nHere’s a full list available editors: https://en.wikipedia.org/wiki/R_(programming_language)#Interfaces"
  },
  {
    "objectID": "introduction_history.html#what-is-r-and-how-do-we-use-it",
    "href": "introduction_history.html#what-is-r-and-how-do-we-use-it",
    "title": "1  Introduction and History",
    "section": "1.4 What is R and how do we use it",
    "text": "1.4 What is R and how do we use it\n\nDefinition(s)\n\nWikipedia: `R is a programming language and free software environment for statistical computing and graphics supported by the R Foundation for Statistical Computing. The R language is widely used among statisticians and data miners for developing statistical software[7] and data analysis.’ http://en.wikipedia.org/wiki/R_(programming_language)\nComprehensive R Archive Network (CRAN): `R is ``GNU S’‘, a freely available language and environment for statistical computing and graphics which provides a wide variety of statistical and graphical techniques: linear and nonlinear modelling, statistical tests, time series analysis, classification, clustering, etc.’ https://cloud.r-project.org/.\nThe R Journal - Facets of R: `This paper considers six characteristics, which we will call facets. They characterize R as:\n\nan interface to computational procedures of many kinds;\ninteractive, hands-on in real time;\nfunctional in its model of programming;\nobject-oriented, “everything is an object”;\nmodular, built from standardized pieces; and,\ncollaborative, a world-wide, open-source effort.’\n\n\nBy John M. Chambers\n\nMy definition: A command based, object oriented and functional language; in contrast to excel which is a cell centric, spreadsheet managing graphical user interface (GUI).\n\n\n\nWorking with R\nYou type commands, also known as `expressions,'' into a text editor or terminal and send them toRfor evaluation.R` evaluates the command, prints the command (by default), then the result of the evaluated command, if any.\nThe simplest expressions equal simple calculations, similar to those we could do on a hand calculator\n>1 + 1\n[1] 2\n>1 - 1\n[1] 0\n>2 * 3\n[1] 6\n>2 / 3\n[1] 0.6666667\nHere we use ‘>’ to denote the R prompt. It is used in the console to indicate that R is ready for a new command. The lines in between is the output given by R.\nBut we can also ‘call’ functions on an object. Most of the functionality in R comes from these functions. There are many functions we can use including the standard mathematical ones:\n>cos(3.1415)\n[1] -1\n>exp(0)\n[1] 1\n>log(1)\n[1] 0\nThe results above are displayed but not stored. To do this we must give a name to the result. That is, we store the result in a variable. The results are now no longer displayed but using the variable name we can refer to it later.\nAssigning a result in a variable is done using <-. For example:\n>five <- 3+2\n> five\n[1] 5\n> five + 1\n[1] 6\n\n\nHow we interact with R\nNot surprisingly everything about R is built on the principle of KISS, i.e., keep it simple stupid. * We get things done in R by typing commands and asking R to execute them with the key. Assuming you know the commands, it couldn’t be any simpler. * The front end of R, the part that receives your terminal. You can type your commands directly into the terminal and hit {} to do your work. But if you need thousands of commands for a specific task, or want to share your method, this approach gets tiring fast. * Since the commands are just text, it’s easy to write a series of commands using any program built for working with text, i.e., text editors and word processors, to create code or a script, to get something done. * The easiest, most efficient way to write R code is using a text editor or integrated development environment, like RStudio or Emacs/ESS as mentioned earlier.\n\n\nRStudio: the easiest way to work with R\nFor most users, especially those new to R, RStudio is probably the best IDE to use. Like everything about R, you’re free to choose whatever editor you like. For Windows platforms, you could just use the basic editor that’s bundled with the downloadable installer. Let’s have a look at an RStudio ‘session’.\n\nThere are four panes:\n\nThe top left is the source pane. Do your typing in this pane.\nThe bottom left is your console. This is a window looking into what R is actually doing. Even though it’s fine to type your commands in this pane at the R '>' prompt, avoid this: your commands are less conveniently stored and rerun than your source code in the editor pane.\nTop right: environment pane\nBottom left: files pane\n\nType your commands in the source pane and send them to R using the keyboard short-cut This will send the line of code your cursor is on to R if no code is selected; or if there is code selected, then only the selected code is sent. Open RStudio on your PC and try it now. Since programming is all about typing commands using a keyboard, not pointing and clicking, you might appreciate lots of keyboard shortcuts. Here’s an awesome cheatsheet of (RStudio keyboard shortcuts)[https://www.rstudio.com/resources/cheatsheets/].\nA few other things about RStudio:\n\nmove the focus between panes using the key board shortcuts and for the source and console panes respectively\nthe little asterisk next your source code file name indicates unsaved code\nsave your source code!"
  },
  {
    "objectID": "introduction_history.html#backslashes",
    "href": "introduction_history.html#backslashes",
    "title": "1  Introduction and History",
    "section": "1.5 Backslashes",
    "text": "1.5 Backslashes\nOne more thing I want to mention is how R interprets backslashes and forwardslashes, i.e. \\ and / respectively, as relates to defining the locations of files on your PC. James McDonald does a better job of clarifying this than I otherwise would http://cran.r-project.org/doc/contrib/Lemon-kickstart/kr_scrpt.html:\n\nLet’s pause to note a little historical bifurcation that has caused Almost as much strife as the question of exactly what the  key should do. The convention that the slash (/) character is used as a separator in the notation for a filesystem path is not universal. PC-DOS, for example, used the backslash \\. Like Fords vs Chevrolets, French vs English, and whether you crack the egg at the big or small end, it doesn’t really matter a rat’s behind which one you use as long as it works. To make it work in R, however, where the *NIX convention of using the backslash as an escape character is respected, you will have to double backslashes in paths for them to be read properly. Thus if the filename above was: ‘1.R’ I would have to refer to it as: ‘c:\\JIM\\PSYCH\\ADOLDRUG\\PARTYUSE1.R’ in an R script."
  },
  {
    "objectID": "introduction_history.html#getting-help",
    "href": "introduction_history.html#getting-help",
    "title": "1  Introduction and History",
    "section": "1.6 Getting Help",
    "text": "1.6 Getting Help\n\nOnline help. The first place to look. Also works when you’re actually offline:\n\n\n?help\nhelp(help)\n\n\n??help\napropos(\"help\")              # quotes are needed\n\nIt’s fun, try them out!\n\nGoogle. And when you’re actually online, often the first place and **last** place you’ll go when you have no idea is (Google)[href{https://www.google.com].\nPackage Vignette’s. Where the online help is devoid of the context often needed to grasp the full potential and logical use of functions, vignette’s is the best place to find such information, with extended examples, and often more. For example, see the limma http://www.bioconductor.org/packages/release/bioc/vignettes/limma/inst/doc/usersguide.pdf\nMailing Lists. R-help http://www.r-project.org/mail.html. Do check first using Google or the R-help searchable archives http://tolstoy.newcastle.edu.au/~rking/R/ first if your question has already been asked and has the answer to solve your issue.\nOther lists: https://stat.ethz.ch/mailman/listinfo\nStack Overflow https://stackoverflow.com. Probably more questions and answers posted here than on the mailing list.\n\n\nTrouble shooting\n\nClean your environment and start again to be sure your messy environment isn’t the cause of your issue. In RStudio, click the broom in the Environment tab; in any R session you can also run:\n\n\nrm(list=ls())                 \nls()           # quotes are needed\n\n\nStart R without any customisations, i.e., omit loading the .Rprofile and .Renviron customisation files. From the command line:\n\n\nR --vanilla\n\n\ntrace.back() function: very helpful pinpointing the source of an error, and thus its cause.\n\n\n\nFurther resources\n\nR focused search engine: http://www.Rseek.org\nAggregator of all R blogs: http://www.r-bloggers.com\nQuick-R: http://www.statmethods.net/\nR on Youtube: http://www.youtube.com/watch?v=mL27TAJGlWc\nR in two minutes: http://www.twotorials.com/\nThe list of reference texts: http://www.r-project.org/doc/bib/R-publications.html\nThis course not enough? There’s a excellent free online introduction to R here: https://www.computerworld.com/article/2497143/business-intelligence-beginner-s-guide-to-r-introduction.html\nAnd more..\n\nhttp://www.ats.ucla.edu/stat/r/\nhttp://zoonek2.free.fr/UNIX/48_R/02.html\n\nA First Course in Statistical Programming with R. W. John Braun and Duncan J. Murdoch. Cambridge University Press, 2007\\ I love this book, beautifully explores the programming aspects of R."
  },
  {
    "objectID": "objects.html#introduction",
    "href": "objects.html#introduction",
    "title": "Objects in R",
    "section": "Introduction",
    "text": "Introduction\nAll the things we work with in R (such as the numbers in the calculations in the previous section) are called objects. All objects have a mode and a class. The mode describes how the data is stored in R and how it can be used. Text variables for example have to be handled differently than numbers, we cannot multiply two words.\nElementary objects can be combined with each other to form more complex objects this leads to several types of containers, like lists and data.frames\nThe class of an object is an attribute that can be used to further specify how an object is used in R. For example it can be used to indicate how it should be printed and plotted. For many objects the class will simply be equal to the mode.\nFunctions are special objects that can do things with other objectsl, for example the print function displays the contents of an object in the console. Functions are the topic of an other chapter but because we obviously want to do something with the various objects we will see we cannot avoid them altogether."
  },
  {
    "objectID": "objects.html#the-elementary-data-types",
    "href": "objects.html#the-elementary-data-types",
    "title": "Objects in R",
    "section": "The elementary data types",
    "text": "The elementary data types\nThe simplest variables just have a single value of a certain data type (Or mode1). The most important data types in R are:2:\n\n\n\n\n\n\n\nmode\ndescription\n\n\n\n\nnumeric: character: logical:\nPosibly fractional numerical values like 1.0, 1.2 or 1e12 (that is 10 raised to the power of 12) text, for example ‘man’, ‘woman’, ‘censored’, etc. TRUE and FALSE\n\n\n\nLet’s examine variables of these data types in a bit more detail:\n\nNumbers\n\nmode(1)    \n\n[1] \"numeric\"\n\n# for most basic data types the class is the same as the mode\nclass(1)    \n\n[1] \"numeric\"\n\nclass(2.14)\n\n[1] \"numeric\"\n\n# functions that start with as.* do conversion\nan_integer <- as.integer(2.14)\n# integers are special numeric values that only store whole \n# numbers\nan_integer \n\n[1] 2\n\nclass(an_integer)\n\n[1] \"integer\"\n\nmode(an_integer)\n\n[1] \"numeric\"\n\n# convert to numeric again\nback_to_numeric <- as.numeric(an_integer)\nclass(back_to_numeric)\n\n[1] \"numeric\"\n\nclass(1L) # explicit integer\n\n[1] \"integer\"\n\n\n\n\nText\n\n# character values should be surrounded by quotes \"or '\nclass(\"a\")\n\n[1] \"character\"\n\nclass('a')\n\n[1] \"character\"\n\nmode(\"a\")\n\n[1] \"character\"\n\n# even numbers in quotes are interpreted as text\nclass(\"1\")\n\n[1] \"character\"\n\nmode(\"1\")\n\n[1] \"character\"\n\n\n\n\nLogical\nIt can only be a yes or a no. More specifically, a TRUE or a FALSE.\n\nclass(TRUE)\n\n[1] \"logical\"\n\nclass(FALSE)\n\n[1] \"logical\"\n\nmode(TRUE)\n\n[1] \"logical\"\n\n\nOften logical values are he result of comparisons:\n\n\n\nOperator\nMeaning\n\n\n\n\n==\nEqual to\n\n\n!=\nNot equal to\n\n\n>\nGreater than\n\n\n<\nSmaller than\n\n\n>=\nGreater than or equal to\n\n\n<=\nSmaller than or equal to\n\n\n\nLogival values can be combined using & (and) and | or, and inverted using ! (not).\n\na <- c(TRUE, TRUE, FALSE, FALSE)\nb <- c(TRUE, FALSE, TRUE, FALSE)\n\na & b\n\n[1]  TRUE FALSE FALSE FALSE\n\na | b\n\n[1]  TRUE  TRUE  TRUE FALSE\n\n!a\n\n[1] FALSE FALSE  TRUE  TRUE"
  },
  {
    "objectID": "objects.html#vectors",
    "href": "objects.html#vectors",
    "title": "Objects in R",
    "section": "Vectors",
    "text": "Vectors\nVectors of these data types are the most elementary data structure in R. All other structures (like the data.table) are constructed using these vectors. In R there is also no structure that is smaller than a vector. A single number is not treated differently from a numeric vector of length ten; In fact R sees the single number simply as a numeric vector of length 1. The length() of a vector can be obtained by using the function length().\nA vector can be created using the function c(). (The c stands for ‘concatenate’, ‘coerce’ or ‘combine’)\n\nc(1, 2, 3)\n\n[1] 1 2 3\n\nc('spam', 'ham', 'eggs')\n\n[1] \"spam\" \"ham\"  \"eggs\"\n\nc(\"double\", \"quotes\", \"work\",\n  'like', 'single')\n\n[1] \"double\" \"quotes\" \"work\"   \"like\"   \"single\"\n\nc(TRUE, FALSE)\n\n[1]  TRUE FALSE\n\nlength(c(25, 4))\n\n[1] 2\n\n\nIn the output we see that R shows the row number of the first element of each row between straight brackets. This makes it easier to refer to a particular element, especially when the vectors are long. We can work with vectors in the same way as with single numbers. In principle all operations are carried out in an element wise fashion.\n\nc(1, 2, 3) * c(4, 5, 6)\n\n[1]  4 10 18\n\n\nNote that when the lengths do not match they are recycled.\n\nc(1, 2, 3, 4) * c(4, 5)\n\n[1]  4 10 12 20\n\n# if the larger length is not an exact multiple\n# of the smaller this often indicates a mistake\n# and a warning is given\nc(1, 2, 3) * c(4, 5) \n\nWarning in c(1, 2, 3) * c(4, 5): longer object length is not a multiple of\nshorter object length\n\n\n[1]  4 10 12\n\n\nWe can also give names to the elements of a vector:\n\nnamed_v <- c(foo=1, bar=2)\nprint(named_v)\n\nfoo bar \n  1   2 \n\nmode(named_v)\n\n[1] \"numeric\"\n\nclass(named_v)\n\n[1] \"numeric\"\n\n\nWhen we try to create a vector that consists of different data types they will be converted to a data type that is capable of containing all of them. For example:\n\nc(\"eleven\", 12)\n\n[1] \"eleven\" \"12\"    \n\n\nThe second element of the resulting vector is now also of type character. In general it is better not to trust this implicit conversion. Instead to it explicitly, in this case by using the function as.character().\nAn other way to create a vector is by using the function vector. vector('numeric', 8) creates a numeric vector of length 8. The vector function is often used to pre-allocate room where the results of future computations can be stored."
  },
  {
    "objectID": "objects.html#matrices",
    "href": "objects.html#matrices",
    "title": "Objects in R",
    "section": "Matrices",
    "text": "Matrices\nVectors have just a single dimension (every element is characterized by a single number (index) that indicates its position within the vector). They can be generalized to vectors that are two dimensional, that is they have both rows and columns. Like simple vectors all elements of a matrix have the same .\n\nmy_matrix <- matrix(data = c(1,2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12))\nmy_matrix\n\n      [,1]\n [1,]    1\n [2,]    2\n [3,]    3\n [4,]    4\n [5,]    5\n [6,]    6\n [7,]    7\n [8,]    8\n [9,]    9\n[10,]   10\n[11,]   11\n[12,]   12\n\ndim(my_matrix) # second dimension (# columns) is 1\n\n[1] 12  1\n\nmatrix2 <- matrix(data = c(1,2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12),\n                  nrow = 3)\nmatrix2\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    4    7   10\n[2,]    2    5    8   11\n[3,]    3    6    9   12\n\ndim(matrix2)\n\n[1] 3 4\n\nchar_mat <- matrix(data = c('a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'), nrow = 2)\nclass(char_mat)\n\n[1] \"matrix\" \"array\" \n\nmode(char_mat)\n\n[1] \"character\"\n\nlength(char_mat) #just counts the number of elements \n\n[1] 8\n\n\n\nArrays\nWe do not have to stop with two dimensions. Arrays are even more general than matrices as they can have any number of dimensions. All elements have to be of the same type.\n\nletters[1:12]\n\n [1] \"a\" \"b\" \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\"\n\nmy_array <- array(letters[1:12], c(2, 2, 3))\nmy_array\n\n, , 1\n\n     [,1] [,2]\n[1,] \"a\"  \"c\" \n[2,] \"b\"  \"d\" \n\n, , 2\n\n     [,1] [,2]\n[1,] \"e\"  \"g\" \n[2,] \"f\"  \"h\" \n\n, , 3\n\n     [,1] [,2]\n[1,] \"i\"  \"k\" \n[2,] \"j\"  \"l\" \n\nclass(my_array)\n\n[1] \"array\"\n\nmode(my_array)\n\n[1] \"character\""
  },
  {
    "objectID": "objects.html#lists",
    "href": "objects.html#lists",
    "title": "Objects in R",
    "section": "Lists",
    "text": "Lists\nElements of a vector, matrix or array are always of the same type. A list differs from a vector by also allowing its elements to be of a different type. We can make a list using the function list.\n\nlist1 <- list(\"eleven\", 12)\nmode(list1)\n\n[1] \"list\"\n\nclass(list1)\n\n[1] \"list\"\n\nlist2 <- list(c(1, 2, 3), c('foo', 'bar'))\n\nWe can also assign a name to the elements of a list:\n\nlist3 <- list(numbers=c(1, 2, 3), chars=c('foo', 'bar'))\n\nIt is also possible for a list to contain other lists.\n\nlist4 <- list(numbers=c(1, 2, 3), chars=c('aap', 'noot'), \n               sublist=list(1,'a'))\n\nA useful function for lists is str. It gives us its structure.\n\nstr(list4)\n\nList of 3\n $ numbers: num [1:3] 1 2 3\n $ chars  : chr [1:2] \"aap\" \"noot\"\n $ sublist:List of 2\n  ..$ : num 1\n  ..$ : chr \"a\"\n\n\n\ndata.frames\nThis is a rectangular table in which every column contains a variable and every row an observation. They are similar to the spreadsheets: a series, or list of equal length columns, or vectors. Notably, the columns (vectors) can be of different classes, unlike a matrix or array.\n\nmy_df <- data.frame(\"vec\" = c(12, 48), \"lets\" = letters[1:12])\nmy_df\n\n   vec lets\n1   12    a\n2   48    b\n3   12    c\n4   48    d\n5   12    e\n6   48    f\n7   12    g\n8   48    h\n9   12    i\n10  48    j\n11  12    k\n12  48    l\n\ndim(my_df)\n\n[1] 12  2\n\nclass(my_df)\n\n[1] \"data.frame\"\n\nmode(my_df) # a data.frame is a special kind of list\n\n[1] \"list\"\n\nstr(my_df)\n\n'data.frame':   12 obs. of  2 variables:\n $ vec : num  12 48 12 48 12 48 12 48 12 48 ...\n $ lets: chr  \"a\" \"b\" \"c\" \"d\" ...\n\n\nMost data sets come in the form of data.frames or can be converted to them so we are going to see them frequently later in the course."
  },
  {
    "objectID": "objects.html#factors",
    "href": "objects.html#factors",
    "title": "Objects in R",
    "section": "factors",
    "text": "factors\nA factoris a special kind of vector for categorical data. The factor contains different integers one for every category. Each unique value has an associated ‘label’ that tell us what the code means. Factors are frequently used when we model categorical data. An advantage of a factor over a character is that we can limit the number of possible outcomes. It is also less likely to make mistakes due to typing errors. Factors can be created by means of the function factor().\n\nf <- c('male', 'female', 'male')\nfactor(f)\n\n[1] male   female male  \nLevels: female male\n\nlevels(f)\n\nNULL\n\n\nWhen a factor is displayed R also shows us the unique values the variable can take. These are called the ‘levels’ of the factor."
  },
  {
    "objectID": "objects.html#functions",
    "href": "objects.html#functions",
    "title": "Objects in R",
    "section": "functions",
    "text": "functions\nFunctions are used to do something. We have already seen several of them. Like mode, class and as.integer and you will see lots more. Note that in R functions are objects too.\n\nmode(mode)   # like all objects functions have a mode\n\n[1] \"function\"\n\nclass(mode)\n\n[1] \"function\"\n\nprint(mode)  \n\nfunction (x) \n{\n    if (is.expression(x)) \n        return(\"expression\")\n    if (is.call(x)) \n        return(switch(deparse(x[[1L]])[1L], `(` = \"(\", \"call\"))\n    if (is.name(x)) \n        \"name\"\n    else switch(tx <- typeof(x), double = , integer = \"numeric\", \n        closure = , builtin = , special = \"function\", tx)\n}\n<bytecode: 0x000002973a2df5b8>\n<environment: namespace:base>\n\n# do not worry if you do not understand the meaning of what is printed yet\n\nNote that operators are functions to. When you want to use them in the same way as normal functions just put them between back-ticks (“`”):\n\nmode(`+`)   \n\n[1] \"function\"\n\n`+`(1, 1)\n\n[1] 2\n\n\nBase R has many factions but many more are come from various extension packages. These can be installed using install.packages() :\n\ninstall.packages(\"packageName\",\n                 lib = \"/directory/to/my custom R library\",\n                 repos = \"http://cran.xl-mirror.nl\")\n\n# usually lib and repos can be omitted (left at the default)\n\nThe package name must be quoted when installing.\n\nlibrary(\"packageName\")      ## quotes are optional when loading a package\n\nFunctions will be discussed in more detail later."
  },
  {
    "objectID": "objects.html#missing-values",
    "href": "objects.html#missing-values",
    "title": "Objects in R",
    "section": "Missing values",
    "text": "Missing values\nWhenever the value of a variable is missing this is denoted by NA in R. Usually this means that the values exists however we do not know it. Sometimes the result of a calculation is not finite (for example when we define a positive or negative number by zero). In this case the result is defined to be Inf of -Inf in R. When a value cannot be computed at all (for example when we divide zero by zero) R will define the result as NaN, which stands for ‘Not a Number’. Finally, R sometimes uses the special value NULL to indicate that a variable is not yet defined. Here we will mostly deal with data that is just missing, that is NA.\n\na <- c(1, -1, 0, NA, NULL)\na/0\n\n[1]  Inf -Inf  NaN   NA\n\nis.na(a)\n\n[1] FALSE FALSE FALSE  TRUE\n\nis.finite(a)\n\n[1]  TRUE  TRUE  TRUE FALSE\n\nis.null(a) # note this looks at the whole object\n\n[1] FALSE\n\nl <- list(foo= a, b=c('b'))\nl[1] <- NULL # deletes elements from a list\nl\n\n$b\n[1] \"b\""
  },
  {
    "objectID": "objects.html#saving-and-restoring-your-session",
    "href": "objects.html#saving-and-restoring-your-session",
    "title": "Objects in R",
    "section": "Saving and restoring your session",
    "text": "Saving and restoring your session\nBecause the typical way of using R involves writing text into a file with the .r or .R extension it’s natural to save your commands written for a specific purpose in this my-r-file.r. Hopefully you’re doing this right now. However there are other bits and pieces of your R session described below you may want or need to save.\nSave all objects to the working directory in a file called .RData:\n\nsave.image()\n\nOr give the file a name:\n\nsave.image(\"mySession.RData\") \n\nSave all commands entered into the R console during your session to the working directory in a file called .Rhistory:\n\nsavehistory()\n\nSuch a file may be hidden by default in some file browsers, including linux.\nNote that this typically occurs (console dependent) by default when you quit your R session. If an .Rhistory file already exists from a previous session, the current session is appended to the end of this file and saved. Thus, by design, a complete log of your work is saved together with your script file, if your console session contains less than 512 lines.\nSave specific objects:\n\nsave(object_1, object_2, object_3, file = \"rObjects123.RData\")\n\nRestore or load previous sessions or objects:\n\nload(\"mySession.RData\")        # load from the working directory\n\nWhen you save and load objects this way, loaded variables will have the same names as when they were stored. There is also a different way of saving objects where loaded objects are assigned explicitly.\n\nmyobject <- list(vec=c(1, 2, 3), mat=matrix(1:4,2))\nsaveRDS(myobject,file = 'myfile.rds')\nobject2 <- readRDS('myfile.rds')\nidentical(myobject, object2)\n\n[1] TRUE\n\n\nLoad .Rhistory file to access the history from the console:\n\nloadhistory()"
  },
  {
    "objectID": "objects.html#miscellaneous-tips",
    "href": "objects.html#miscellaneous-tips",
    "title": "Objects in R",
    "section": "Miscellaneous Tips",
    "text": "Miscellaneous Tips\nR is case sensitive:\n\nc(\"Hello\" == \"hello\", \"goodbye\" == \"goodbye\")\n\n[1] FALSE  TRUE\n\n\nAnd is sensitive in general:\n\n# c(\"Hello\" == \"hello\" \"goodbye\" == \"goodbye\") # not run\n\nMissing data. NA ‘Not Available’ is how R defines a missing value i.e., an empty cell in excel\n\nc(1, NA, 3, 4, NA)\n\n[1]  1 NA  3  4 NA\n\n\nR is an environment. What’s in yours?\n\nls()                              # global environment\nobjects()                         # alias for ls()\n\nToo many objects cluttering up your environment and computer memory? Remove the ones you don’t need:\n\nrm(object_name)\n\nWhat is the current where files are saved and loaded from by default?\n\ngetwd()\n\nNeed to set or change the current working directory?\n\nsetwd(dir = \"c:\\\\Windows\\\\Users\\\\karl\\\\My Documents\\\\R stuff\")\nsetwd(dir = \"c:/Windows/Users/karl/My Documents/R stuff\")\n\nNote the double backslashes required by R running under Windows. Single forward slashes, the Unix convention works equivalently.\nAlso be aware that if you started your R session by double clicking a file.name.r file, by design the directory where this file resides is set as the working directory. This directory is also a good place, and the default place, to store the respective .RData and .Rhistory files if you have any. When these files are present in the same directory they will be loaded automatically, unless you explicitly tell R not to load them by using the ---no-restore-data argument when starting R.\nQuit your R session:\n\nq()                           # not run\n\nObject names can not begin with numbers. For example:\n\n## 3vector <- c(2, 4, 6))    # not run\n\nBut can end with numbers if necessary:\n\nvector3 <- c(2, 4, 6)\n\nTry to code with style, for example:\nhttps://google.github.io/styleguide/Rguide.xml\nhttp://adv-r.had.co.nz/Style.html"
  },
  {
    "objectID": "objects_practical.html#r-as-a-calculator-expressions-and-assignments",
    "href": "objects_practical.html#r-as-a-calculator-expressions-and-assignments",
    "title": "2  Objects Practical",
    "section": "2.1 R as a calculator (expressions and assignments)",
    "text": "2.1 R as a calculator (expressions and assignments)\n\na) Expressions\nUse R as a calculator to calculate the following values:\n\n\\(17 ^4\\),\n\\(45 - 2 \\times 3\\)\n\\((45 - 2) \\times 3\\)\n\nEnter the folowing in an R-script and then run the lines using .\n\n17^4\n2^(1/3)\n45-2 * 3\n(45-2) * 3\n\n\n\nb) Assignment\n\na <- 45\nb <- 2\nc <- 3\nd <- (a - b) * c \n\na, b, c, and d are variables. You can just type the variable name (e.g. a) and hit or use the command print(a)."
  },
  {
    "objectID": "objects_practical.html#math-using-vectors-and-matrices-recycling",
    "href": "objects_practical.html#math-using-vectors-and-matrices-recycling",
    "title": "2  Objects Practical",
    "section": "2.2 Math using vectors and matrices (recycling)",
    "text": "2.2 Math using vectors and matrices (recycling)\nDefine x and A as:\n\nx <- c(1, 2, 3, 4, 5, 6)\nA <- matrix(c(1, 2, 3, 4, 5, 6),nrow = 2, ncol = 3)\n\nWhat are\n\nx + 4\nx + x\n2 * x\nx / c(2, 3, 4, 5)\n\n\nA + 4\nA + x\n2 * A\nx / c(2, 3)"
  },
  {
    "objectID": "objects_practical.html#common-r-objects",
    "href": "objects_practical.html#common-r-objects",
    "title": "2  Objects Practical",
    "section": "2.3 Common R Objects",
    "text": "2.3 Common R Objects\nIt is important to distinguish the different object in R. Therefore we will try and create some vectors, matrices, data frames, arrays and lists. We will do this using some data from the survival package.\n\nIntroduction to the data\nFor this part of the practical, we will use the heart and retinopathy data sets from the survival package. More details about the data sets can be found in:\nhttps://stat.ethz.ch/R-manual/R-devel/library/survival/html/heart.html\nhttps://stat.ethz.ch/R-manual/R-devel/library/survival/html/retinopathy.html\n\naHint a\n\n\nLoad the survival package to access the data sets. Explore the heart and retinopathy data sets - print the first six and last six rows (use the head and tail functions).\n\n\nUse the functions head(…) and tail(…) to investigate the data set. Replace the dots with the name of the data set.\n\n\n\n\n\nVectors\n\naHint a\n\n\nView the vectors event and age from the heart data set.\n\n\nUse the dollar sign to select the variables.\n\n\n\n\nbHint b\n\n\nView the vectors eye and risk from the retinopathy data set.\n\n\nUse the dollar sign to select the variables.\n\n\n\n\ncHint c\n\n\nCreate a numerical vector that consists of the values: 34, 24, 19, 23, 16. Give the name numbers to this new vector.\n\n\nUse the c(…) function. Replace the dots with the numbers.\n\n\n\n\ndHint d\n\n\nd Create a numerical vector that takes the integer values from 1 until 200. Give the name numbers_2 to this new vector.\n\n\nUse the colon operator : or seq function to create the vector. Use ?: or ?seq if needed.\n\n\n\n\neHint e\n\n\nCreate a character vector that consists of the values: yes, yes, no, no, no, yes. Give the name treatment to this new vector.\n\n\nUse the c(…) function. Replace the dots with the categories.Do not forget the quotes \".\n\n\n\n\n\nMatrices and Data Frames\nLet’s investigate some matrices and data frames.\n\naHint a\n\n\nCreate a matrix like this\n\nx <- matrix(8:11, nrow = 6, ncol = 4)\nx\n\n     [,1] [,2] [,3] [,4]\n[1,]    8   10    8   10\n[2,]    9   11    9   11\n[3,]   10    8   10    8\n[4,]   11    9   11    9\n[5,]    8   10    8   10\n[6,]    9   11    9   11\n\n\nWhy is x filled in the way it is? Hint: read about the arguments for matrix!\n\n\nHow many elements does a matrix of the indicated dimensions have. How many elements does the data vector have? Find out what is done in this case. Are rows or columns filled first?\n\n\n\n\nbHint b\n\n\nCreate a matrix using the vectors id and age from the heart data set. This matrix should have 2 columns where each column represents each variable.\n\n\nFirst combine the vectors using c. Now use the function matrix(…) to convert it to a matrix and specify that it should have two columns.\n\n\n\n\ncHint c\n\n\nCreate a data frame using the vectors id, type and trt from the retinopathy data set. This data frame should have 3 columns, where each column represents each variable.\n\n\nUse the function data.frame(…).\n\n\n\n\n\nArrays\nLet’s investigate arrays.\n\naHint a\n\n\nCreate an array that consists of 2 matrices. Matrix 1 will consist of the values 1:4 and matrix 2 will consist of the values 5:8. Both matrices will have 2 columns and 2 rows.\n\n\nUse the function array(…).\n\n\n\n\nbHint b\n\n\nGive the name ar1 to the previous array. Furthermore, investigate the argument dimnames and change the names of the rows, columns and matrices.\n\n\nUse the function array(…). Check the help page for the dimnames argument. Note that this must be in a list format.\n\n\n\n\n\nLists\nLet’s investigate lists.\n\naHint a\n\n\nCreate a list using the vectors stop from the heart data set and id, risk from the retinopathy data set. Give the names stop_heart, id_reti and risk_reti.\n\n\nUse the function list(…).\n\n\n\n\nbHint b\n\n\nCreate a list using the vectors numbers, numbers_2 and treatment. These variables can be taken from the exercise called Vectors. Give the names: numbers, many_numbers and treatment.\n\n\nUse the function list(...) using named function arguments."
  },
  {
    "objectID": "objects_practical.html#saving-files-and-data",
    "href": "objects_practical.html#saving-files-and-data",
    "title": "2  Objects Practical",
    "section": "2.4 Saving files and data",
    "text": "2.4 Saving files and data\nDo the following to practice saving and opening files in R.\n\nLook at the variables (or other objects) that are stored in your Workspace by typing either objects() or ls()\nCheck your working directory by typing getwd(). Now change it to a different directory - preferably your own flash drive - by using the function setwd(), for example:\n\n\nsetwd(\"C:/Users/Elizabeth/My Documents/R Course\")\n\n\nUse the function save.image() to save your R session to a file called YourLastName_practical1.RData (replace YourLastName with your last name). Note that this will save a .RData file that contains only those objects you see when you run ls(). It does not save any code you typed into the console or into the source pane.\nUse the RStudio ‘File’ drop-down menu to save your R source code to a file called YourLastName\\_practical1.R (replace YourLastName with your last name). Note that this will only save the text you’ve typed into the source pane. It does not save any objects or anything typed into or ran through the console.\nUse the function save() to save only the objects numbers, numbers_2 and treatment from the ‘Vectors’ exercise. to a file called YourLastName\\_objects.RData (replace YourLastName with your last name).\nNow close out RStudio entirely, select Save'' orYes’’ in any dialog boxes that pop up, and then reopen RStudio. Is your source code still there?\nRun ls(); are your objects still there?\nYou can change these kinds of options by going to Tools - Global Options. Go there and deselect ‘Restore .RData into workspace at startup’. Then close RStudio and choose to save the .RData file.\nReopen RStudio; your environment should be empty. Load your objects back in using load() (e.g. Ribble\\_practical1.RData“) and then run ls() again. Do you see your objects now?\nCheck what the working directory is by again running getwd() - has it been reset?"
  },
  {
    "objectID": "manipulating_data.html#indexing-a-vector",
    "href": "manipulating_data.html#indexing-a-vector",
    "title": "Manipulating / Selecting Data",
    "section": "Indexing a vector",
    "text": "Indexing a vector\nThere are three ways in which we can make a selection:\n\nUsing numeric values, to make selections based on the position in a vector\nUsing character values, to select values based on their name\nUsing logical values (TRUE / FALSE), to make selections based on a condition\n\n\nUsing numeric values\nThe easiest way of selecting elements in a vector is by specify positions or indices i in numbers of the data we wish to select using square brackets which are the extract' function, i.e.,object[i]`.\n\nv <- c(11, 13, 17, 15, 9)\nv[2]\n\n[1] 13\n\n\nWe can also do this for multiple elements at the same time:\n\nv[c(2, 3)]\n\n[1] 13 17\n\ni <- c(1, 2)\nv[i]\n\n[1] 11 13\n\n\nThe vector of indices does not have to be sorted and indices may be duplicated. For example:\n\nv[c(3, 2, 2)]\n\n[1] 17 13 13\n\n\nWhen we use a vector with negative integers we will select all observations except those on the specified positions:\n\nv[-2]\n\n[1] 11 17 15  9\n\n\nNote that positive and negative indexes cannot be combined.\n\n\nUsing character values\nWhen the elements in a vector all have a name we can use these names to select the elements.\n\nbp_with_name <- c(sys=135, dia=85)\nbp_with_name['dia']\n\ndia \n 85 \n\n\nWe can also give names to the vector by using the names function: Here we make use of the names attribute:\n\nages <- c(12, 3, 45)\nnames(ages) <- c(\"Kim\" , 'Arthur', 'Mark')\nages\n\n   Kim Arthur   Mark \n    12      3     45 \n\nstr(ages)\n\n Named num [1:3] 12 3 45\n - attr(*, \"names\")= chr [1:3] \"Kim\" \"Arthur\" \"Mark\"\n\nages[\"Mark\"]\n\nMark \n  45 \n\nnames(ages)\n\n[1] \"Kim\"    \"Arthur\" \"Mark\"  \n\n\nNote that we can also change the names of a data.frame in the same way we would do so for a list using the names attribute:\n\nmygenes <- data.frame(samp1 = c(33, 22, 12), \n                      samp2 = c(44, 111, 13), \n                      samp3 = c(33, 53, 65))\nnames(mygenes) <- c(\"samp10\", \"samp20\", \"samp30\")\nmygenes\n\n  samp10 samp20 samp30\n1     33     44     33\n2     22    111     53\n3     12     13     65\n\n## but let's change it back...\nnames(mygenes) <- c(\"samp1\", \"samp2\", \"samp3\")\n\nNote that the colnames function also performs the same job for data frames.\n\n\nUsing logical values\nThe third way to select elements from a vector is by using a vector of logical values (i.e.. TRUE/FALSE values) between the square brackets. In this way we select all values for which the value between the brackets is TRUE.\n\nsome_values<- c('foo', 'bar', 'baz')\nsome_values[c(TRUE, FALSE, TRUE)]\n\n[1] \"foo\" \"baz\"\n\n\nThis way of selecting is especially useful when we use some comparison (using <, <=, != , etc.) or condition to select variables.\n\nages <- c(55, 78, 92, 44)\nsex <- factor(c('Male', 'Female', 'Male', 'Female'))\nages[ages > 65]\n\n[1] 78 92\n\n# When we use a factor as filter we may compare to a character value\nages[sex == 'Female'] \n\n[1] 78 44\n\n\nTo understand why this works look at when the condition between the brackets is TRUE.\n\nages > 65\n\n[1] FALSE  TRUE  TRUE FALSE\n\nwhich(ages > 65)  # gives the TRUE indices\n\n[1] 2 3\n\n\nNote that when we aply filtering on a factor variable the possible levels are not changed:\n\nlevels(sex[sex == 'Female'] )\n\n[1] \"Female\" \"Male\""
  },
  {
    "objectID": "manipulating_data.html#making-selections-in-a-matrix-or-array",
    "href": "manipulating_data.html#making-selections-in-a-matrix-or-array",
    "title": "Manipulating / Selecting Data",
    "section": "Making selections in a matrix or array",
    "text": "Making selections in a matrix or array\nMaking selections on a matrix works more or less the same as for vectors. But because we have two dimensions we need two indices, the first for the rows and the second for columns\n\nm <- matrix(c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12), ncol = 3)\nm[1, ] # first row\n\n[1] 1 5 9\n\nm[ , 2] # second column\n\n[1] 5 6 7 8\n\nm[c(2, 4), 1:2] # combination of rows and colums\n\n     [,1] [,2]\n[1,]    2    6\n[2,]    4    8\n\nm[, -c(1, 3)]   # negative indices \n\n[1] 5 6 7 8\n\nm[m[,1]>=3,] #logical indices\n\n     [,1] [,2] [,3]\n[1,]    3    7   11\n[2,]    4    8   12\n\n\nNote that when a single row or column is selected the object is converted to a vector; a frequent source of errors. if you want to prevent this you can use drop=FALSE.\n\nm[1, , drop=FALSE]\n\n     [,1] [,2] [,3]\n[1,]    1    5    9\n\n\nWe can also use names but a matrix can have rownames as well as colnames:\n\nrownames(m) <- LETTERS[1:4]\nm\n\n  [,1] [,2] [,3]\nA    1    5    9\nB    2    6   10\nC    3    7   11\nD    4    8   12\n\nm[\"A\", ]\n\n[1] 1 5 9\n\n\nThere exist a special way of using a matrix with two columns to select individual elements out of a matrix based on their two-dimensional coordinates.\n\na <- matrix(c(2,3,3,2), ncol = 2)\na\n\n     [,1] [,2]\n[1,]    2    3\n[2,]    3    2\n\nm[a]\n\n[1] 10  7\n\n\nIndexing for arrays is similar as for matrices.\n\na <- array(c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12),dim = c(2,3,4))\ndimnames(a) <- list(NULL, c('A', 'B', 'C'), c('a', 'b', 'c', 'd'))\na\n\n, , a\n\n     A B C\n[1,] 1 3 5\n[2,] 2 4 6\n\n, , b\n\n     A  B  C\n[1,] 7  9 11\n[2,] 8 10 12\n\n, , c\n\n     A B C\n[1,] 1 3 5\n[2,] 2 4 6\n\n, , d\n\n     A  B  C\n[1,] 7  9 11\n[2,] 8 10 12\n\ncolnames(a) # still 2nd dimension\n\n[1] \"A\" \"B\" \"C\"\n\na[1, 2, ] # 3-dim array requires 3 positions between the brackets\n\na b c d \n3 9 3 9 \n\na[,,'a']\n\n     A B C\n[1,] 1 3 5\n[2,] 2 4 6"
  },
  {
    "objectID": "manipulating_data.html#making-selections-in-a-list",
    "href": "manipulating_data.html#making-selections-in-a-list",
    "title": "Manipulating / Selecting Data",
    "section": "Making selections in a list",
    "text": "Making selections in a list\nTo make selections in a list, we can use single square brackets, double square brackets and the dollar sign. The use of single square brackets works in the same way as it does for vectors.\n\nmylist <- list(\n  foo=c(1,2, 3),\n  bar=c('a', 'b'),\n  baz=list(TRUE, c(2, 4))\n  )\nmylist[c(1,3)]\n\n$foo\n[1] 1 2 3\n\n$baz\n$baz[[1]]\n[1] TRUE\n\n$baz[[2]]\n[1] 2 4\n\nmylist[c(1,2,3)==2]\n\n$bar\n[1] \"a\" \"b\"\n\nmylist['bar']\n\n$bar\n[1] \"a\" \"b\"\n\n\nWe can also use double square brackets and the dollar sign for a list. There are two important differences between using single and double square brackets: 1. Using double square brackets only allows us to select a single element from the list. 2. The result of a selection with double brackets is the element itself, while if we make the selection with single brackets the result is a list consisting of the selected elements.\n\nmylist[[1]]\n\n[1] 1 2 3\n\n\n\nmode(mylist[[1]]) # a vector\n\n[1] \"numeric\"\n\nmode(mylist[1])   # a list with with a numeric vector as its single element   \n\n[1] \"list\"\n\n\nThere is another way to select a variable from a list which is by using the dollar sign (‘$’). This is an alternative to using double square brackets in combination with a name. When we use this the result is always a vector.\n\nmylist$foo      # results is a vector\n\n[1] 1 2 3\n\n\nInstead of using the dollar sign we can use double square brackets. We now need to put the name between quotes like for single square brackets. We can also use the position of the variable using these double square brackets.\n\nmydata[['treatm']]\nmydata[[1]]\n\nIt is not possible to select more than one element using double brackets; The result will always be a vector (instead of a data.frame)"
  },
  {
    "objectID": "manipulating_data.html#selecting-observations-and-variables-in-a-data.frame",
    "href": "manipulating_data.html#selecting-observations-and-variables-in-a-data.frame",
    "title": "Manipulating / Selecting Data",
    "section": "Selecting observations and variables in a data.frame",
    "text": "Selecting observations and variables in a data.frame\nSelecting observations and variables in a data.frame works more or less the same for data.frames as it does for lists. However because a data.frame is two dimensional we can two indices between the square brackets. The first one corresponds to the observations (rows) and the second corresponds to the variables (columns). So, as an example, we can select the first two observations from the third variable in the data.frame using the syntax:\n\nmydata <- data.frame(id=c(1, 2, 3, 4, 5),\n                     sex=factor(c('M', 'F', 'M', 'F', 'F')),\n                     weight=c(77, 44, 56, 88, 49))\nmydata[c(1, 2), 3]\n\n[1] 77 44\n\n\nWhen the first or second position is left blank all rows or columns are selected. For example:\n\nmydata[, 3]       # sex (3rd variable) for all patients\n\n[1] 77 44 56 88 49\n\nmydata[c(1,2), ]  # all variables for the first two patients\n\n  id sex weight\n1  1   M     77\n2  2   F     44\n\nmydata[c(-3,-4), 'sex'] # Negative numbers and names can also be used\n\n[1] M F F\nLevels: F M\n\n\nWe have to be careful when we want to select a single variable from a data.frame, as we do above. The result will now no longer be a data.frame but it is transformed to a vector. When we want to prevent this we can use drop=FALSE, as follows:\n\nmydata[ , 3]\n\n[1] 77 44 56 88 49\n\nmydata[ , 3, drop=FALSE]       \n\n  weight\n1     77\n2     44\n3     56\n4     88\n5     49\n\n\nWe can also use a single index between the square brackets. This works as if the data.frame was a list of variables (it’s columns).\n\nmydata[1]\n\n  id\n1  1\n2  2\n3  3\n4  4\n5  5\n\nmydata[[1]]\n\n[1] 1 2 3 4 5\n\n\nA data.frame has row.names (note the dot) as well as variable names we can use for selection. Let’s look at an example where row names are gene symbols and column names are sample IDs:\n\nmygenes <- data.frame(samp1 = c(33, 22, 12), \n                      samp2 = c(44, 111, 13), \n                      samp3 = c(33, 53, 65))\nrow.names(mygenes) <- c(\"CRP\", \"BRCA1\", \"HOXA\")\nnames(mygenes)\n\n[1] \"samp1\" \"samp2\" \"samp3\"\n\nmygenes\n\n      samp1 samp2 samp3\nCRP      33    44    33\nBRCA1    22   111    53\nHOXA     12    13    65\n\nmygenes[\"CRP\", ]\n\n    samp1 samp2 samp3\nCRP    33    44    33\n\nmygenes[, \"samp1\"]\n\n[1] 33 22 12\n\nmygenes[, c(\"samp1\", \"samp3\")]\n\n      samp1 samp3\nCRP      33    33\nBRCA1    22    53\nHOXA     12    65\n\nmygenes[\"HOXA\", \"samp2\"]\n\n[1] 13\n\n\n\nOther useful functions\nBesides square brackets ([, [[), other useful functions exist for selecting data: duplicated, match, %in%, grep, is.na and $.\nTo select e.g. rows that are not duplicated:\n\nmm <- matrix(c(1, 1, 2, 2), nrow = 4, byrow = TRUE)\n\n\nmm\n\n     [,1]\n[1,]    1\n[2,]    1\n[3,]    2\n[4,]    2\n\nmm[!duplicated(mm), ]\n\n[1] 1 2\n\n\nThe above can also be done with unique, but the use of duplicated might be more appropriate in more complex situations:\n\nunique(mm)\n\n     [,1]\n[1,]    1\n[2,]    2\n\n\nCalling match returns the position of the first match of its first argument in the second argument:\n\nmatch(c(\"a\", \"b\"), c(\"a\", \"c\", \"a\", \"b\", \"a\", \"b\"))\n\n[1] 1 4\n\n\nwhereas \\%in\\% tells you whether the elements of the first argument appear in the second argument:\n\nc(\"a\", \"b\", \"d\") %in% c(\"a\", \"c\", \"a\", \"b\", \"a\", \"b\")\n\n[1]  TRUE  TRUE FALSE\n\n\nRecall our data frame mygenes:\n\nmygenes\n\n      samp1 samp2 samp3\nCRP      33    44    33\nBRCA1    22   111    53\nHOXA     12    13    65\n\nis.data.frame(mygenes)\n\n[1] TRUE\n\n\nNote that since mygenes is a data frame, it is therefore also an array, which means we can select by the name of the elements in the array:\n\nmygenes[match(c(\"samp1\", \"samp3\"), colnames(mygenes))]\n\n      samp1 samp3\nCRP      33    33\nBRCA1    22    53\nHOXA     12    65\n\nmygenes[colnames(mygenes) %in% c(\"samp1\", \"samp4\")]\n\n      samp1\nCRP      33\nBRCA1    22\nHOXA     12\n\n\nHowever, in this case we could just use the names…\n\nmygenes[c(\"samp1\", \"samp3\")]\n\n      samp1 samp3\nCRP      33    33\nBRCA1    22    53\nHOXA     12    65\n\n\nBut this gives an error:\n\nmygenes[c(\"samp1\", \"samp30\")] ## not run\n\nwhere this does not:\n\nmygenes[colnames(mygenes) %in% c(\"samp1\", \"samp30\")]\n\n      samp1\nCRP      33\nBRCA1    22\nHOXA     12\n\n\nWe can also use functions like grep to search for the names we are interested in:\n\nmygenes[grep(2, names(mygenes))]\n\n      samp2\nCRP      44\nBRCA1   111\nHOXA     13\n\nmygenes[grep(\"A\", row.names(mygenes)), ]\n\n      samp1 samp2 samp3\nBRCA1    22   111    53\nHOXA     12    13    65\n\n\nIf we want to find or exclude data with missing values, we can use is.na:\n\nz <- c(1:4, NA, 5:10)\nz\n\n [1]  1  2  3  4 NA  5  6  7  8  9 10\n\nis.na(z)\n\n [1] FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE\n\nwhich(is.na(z))\n\n[1] 5\n\nz[!is.na(z)]\n\n [1]  1  2  3  4  5  6  7  8  9 10"
  },
  {
    "objectID": "manipulating_data_practical.html#selecting-data",
    "href": "manipulating_data_practical.html#selecting-data",
    "title": "3  Indexing Practical",
    "section": "3.1 Selecting Data",
    "text": "3.1 Selecting Data\nAnswer the following without typing the commands into R. Use ? if you’re not sure what the object is or what the function does\n\nQuestion 1: length of objects\n\na\nWhat is\n\nlength(letters)\n\n\n\n\nb\nWhat is\n\nlength(letters == LETTERS)\n\n\n\n\nQuestion 2: which\n\na\nWhat is\n\nwhich(letters %in% c(\"a\", \"d\"))\n\n\n\nb\nWhat is\n\nwhich(c(\"a\", 7, \"d\") %in% letters)\n\n\n\n\n\nQuestion 3: Logical indexing of a vector\n\na\nWhat is\n\nletters[LETTERS > \"W\"]\n\n\n\n\nb\nWhat is\n\nletters[!LETTERS > \"C\"]\n\n\n\n\n\nQuestion 3: Indexing of a vector using integers\n\na\nWhat is\n\nletters[8]\n\n\n\n\nb\nWhat is\n\nletters[-26:-2]\n\n\n\n\n\nQuestion 5: Sequences\n\na\nWhat is\n\n1:6\n\n\n\nb\nWhat is\n\n10:3\n\n\n\nc\nWhat is\n\nseq(from = 1, to = 20, by = 3)\n\n\n\n\n\nQuestion 6: Selection from a matrix\nWe define x as\n\nx <- matrix(8:11, nrow = 6, ncol = 4)\n\nWhat are\n\nx[, 3] + 2 * x[, 2]\nnrow(x)\nx[x[, 3] > 10, ]\n\n\n\nQuestion 7\nUse R to answer the following:\nCreate a vector (using c()) called a (i.e. assign it to an object called a) with four elements which are the integers 5 to 8 (inclusive).\n\nDisplay element 2 of a. \nDisplay element 4 of a. \nAssign the integers 3 and 4 to object b and use b to select elements 3 and 4 of object a. \nDisplay every element of a except element 2. \nDisplay every element of a except elements 3 and 4. \nDisplay only those elements of a that are greater than or equal to 6. \nDisplay only those elements of a that are not equal to 7. \nUse the list function to create an object ab which is a list of the two objects a and b. \nDisplay ab. \nChange the names of the elements in ab to a and b. \nDisplay ab again. What has changed? \n\n\n\nQuestion 8\n\nCreate this matrix m:\n\n\nm <- matrix(1:9, nrow = 3, byrow = T)\nm\n\n     [,1] [,2] [,3]\n[1,]    1    2    3\n[2,]    4    5    6\n[3,]    7    8    9\n\n\n\nWhy are the numbers 1, 2, and 3 in the first row and not the first column? \nDisplay the element on the second row and second column of m. \nDisplay only the 2nd row of m. \nDisplay only the 3rd column of m. \nDisplay only the 2nd and 3rd columns of m. Do so in two different ways.\n\n\n\nQuestion 9\nUsing the heart data set (remember to load the survival package):\n\nSelect the first row.\nSelect the first column.\nSelect the column surgery.\n\n\n\nQuestion 10\nCreate a list:\n\nx <- c(1,2,3,4)\nmat <- matrix(1:9, 3, 3)\nmyList <- list(a=x, b=mat)\n\n\nWhat is the class of myList[[2]]\nWhat is the class of myList[2]\nWrite R code to extract the first element (the vector) by name\n\nIf you want to save your work: save your R session and/or source code!"
  },
  {
    "objectID": "Datacleaning.html#messy-data-vs-tidy-data",
    "href": "Datacleaning.html#messy-data-vs-tidy-data",
    "title": "Data Cleaning",
    "section": "Messy data vs tidy data",
    "text": "Messy data vs tidy data\nThe data set that you have, is often not ready to perform analyses on. You will need to perform some steps to clean up your data.\nBe careful that this can be a time consuming task! The amount of time and code you will spend on the “data cleaning”, can be a lot larger than the actual analysis.\nAn advantage of doing this in R, is that R solely works with syntax. This means that you cannot adjust data manually and you will always have code to reproduce your results.\nIf the source data file gets adjusted slightly; say new patients are added, or some measurements are corrected, you just have to run your code and all your data preparation steps are performed automatically!\nFirst of all we need to make sure data is in a tidy format. Tidy format:\n\n\n\n\n\n\n\n\n\nMake sure that your data is structured so that:\n\nEach variable forms a column\nEach observation forms a row\nEach cell is a single measurement\n\n\n\n\n\n\n\nTip\n\n\n\nIf possible; make sure you already think about your analysis when collecting the data. A protocol and statistical analysis plan are good ways to pre-specify your outcomes and variables. This way, you will probably need less data cleaning steps after data collection."
  },
  {
    "objectID": "Datacleaning.html#prepare-data-set-for-analysis",
    "href": "Datacleaning.html#prepare-data-set-for-analysis",
    "title": "Data Cleaning",
    "section": "Prepare data set for analysis",
    "text": "Prepare data set for analysis\n\nFirst look of your data\nLet’s explore a data set.\nWe will use a standard data set available in R (mtcars). Name this data set “data”.\n\ndata(mtcars)\ndata <- mtcars\n\nWith the function head, the first 6 rows are printed. Here we can check out the names of the variables and the first entries.\n\nhead(data)\n\n                   mpg cyl disp  hp drat    wt  qsec vs am gear carb\nMazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\nValiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1\n\n\nThe number of rows can be adjusted.\n\nhead(data, 3)\n\n               mpg cyl disp  hp drat    wt  qsec vs am gear carb\nMazda RX4     21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag 21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710    22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\n\n\ntail reports the last 6 rows of the data set\n\ntail(data)\n\n                mpg cyl  disp  hp drat    wt qsec vs am gear carb\nPorsche 914-2  26.0   4 120.3  91 4.43 2.140 16.7  0  1    5    2\nLotus Europa   30.4   4  95.1 113 3.77 1.513 16.9  1  1    5    2\nFord Pantera L 15.8   8 351.0 264 4.22 3.170 14.5  0  1    5    4\nFerrari Dino   19.7   6 145.0 175 3.62 2.770 15.5  0  1    5    6\nMaserati Bora  15.0   8 301.0 335 3.54 3.570 14.6  0  1    5    8\nVolvo 142E     21.4   4 121.0 109 4.11 2.780 18.6  1  1    4    2\n\n\nOther useful functions for the first glimpse of your data set:\n\nView(data)\n\nView opens the data set\n\ndim(data)\n\n[1] 32 11\n\nstr(data)\n\n'data.frame':   32 obs. of  11 variables:\n $ mpg : num  21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...\n $ cyl : num  6 6 4 6 8 6 8 4 4 6 ...\n $ disp: num  160 160 108 258 360 ...\n $ hp  : num  110 110 93 110 175 105 245 62 95 123 ...\n $ drat: num  3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ...\n $ wt  : num  2.62 2.88 2.32 3.21 3.44 ...\n $ qsec: num  16.5 17 18.6 19.4 17 ...\n $ vs  : num  0 0 1 1 0 1 0 1 1 1 ...\n $ am  : num  1 1 1 0 0 0 0 0 0 0 ...\n $ gear: num  4 4 4 3 3 3 3 4 4 4 ...\n $ carb: num  4 4 1 1 2 1 4 2 2 4 ...\n\n\n \nObtain the variable names\n\nnames(data)\n\n [1] \"mpg\"  \"cyl\"  \"disp\" \"hp\"   \"drat\" \"wt\"   \"qsec\" \"vs\"   \"am\"   \"gear\"\n[11] \"carb\"\n\n\n \n\n\nRename variables\nIn case there are inconvenient names in your variables, change them:\n\nnames(data)[names(data) == \"carb\"] <- \"CARB\"\n\n\n\n\n\n\n\nImportant\n\n\n\nRemember: never use spaces or special characters in variable names!\n\n\nThis variable in the test dataset is named very inconvenient.\n\n\n\n\nnames(test)\n\n [1] \"miles per gallon\" \"cyl\"              \"disp\"             \"hp\"              \n [5] \"drat\"             \"wt\"               \"qsec\"             \"vs\"              \n [9] \"am\"               \"gear\"             \"CARB\"            \n\ntest$`miles per gallon`\n\n [1] 21.0 21.0 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 17.8 16.4 17.3 15.2 10.4\n[16] 10.4 14.7 32.4 30.4 33.9 21.5 15.5 15.2 13.3 19.2 27.3 26.0 30.4 15.8 19.7\n[31] 15.0 21.4\n\n\n\n\nChange type of variable\nThe type of your variable can be changed\n\nFrom numeric to factor\n\n\ndata$vs_factor <- as.factor(data$vs)\n\ndata$vs_factor\n\n [1] 0 0 1 1 0 1 0 1 1 1 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 0 0 0 1\nLevels: 0 1\n\nstr(data$vs_factor)\n\n Factor w/ 2 levels \"0\",\"1\": 1 1 2 2 1 2 1 2 2 2 ...\n\n\n\ndata$vs_numeric <- as.numeric(data$vs_factor)\n\ndata$vs_numeric\n\n [1] 1 1 2 2 1 2 1 2 2 2 2 1 1 1 1 1 1 2 2 2 2 1 1 1 1 2 1 2 1 1 1 2\n\nstr(data$vs_numeric)\n\n num [1:32] 1 1 2 2 1 2 1 2 2 2 ...\n\n\nNotice how the values are now 1 and 2 instead of 0 and 1. This is because in vs_factor the labels are 0 and 1, but the underlying values were changed to 1 and 2. To solve this we use the function paste0. Now as.numeric() takes the labels as values for the new numeric variable.\n\ndata$vs_numeric <- as.numeric(paste0(data$vs_factor))\n\ndata$vs_numeric\n\n [1] 0 0 1 1 0 1 0 1 1 1 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 0 0 0 1\n\nstr(data$vs_numeric)\n\n num [1:32] 0 0 1 1 0 1 0 1 1 1 ...\n\n\n\n\nRound variables\nThe function round() rounds variables to the specified number of digits. The default is 0\n\nround(data$wt)\n\n [1] 3 3 2 3 3 3 4 3 3 3 3 4 4 4 5 5 5 2 2 2 2 4 3 4 4 2 2 2 3 3 4 3\n\nround(data$wt, digits = 1)\n\n [1] 2.6 2.9 2.3 3.2 3.4 3.5 3.6 3.2 3.1 3.4 3.4 4.1 3.7 3.8 5.2 5.4 5.3 2.2 1.6\n[20] 1.8 2.5 3.5 3.4 3.8 3.8 1.9 2.1 1.5 3.2 2.8 3.6 2.8\n\n\nSimilar functions are ceiling() and floor(). Can you guess what they do?\n\nceiling(data$wt)\n\n [1] 3 3 3 4 4 4 4 4 4 4 4 5 4 4 6 6 6 3 2 2 3 4 4 4 4 2 3 2 4 3 4 3\n\nfloor(data$wt)\n\n [1] 2 2 2 3 3 3 3 3 3 3 3 4 3 3 5 5 5 2 1 1 2 3 3 3 3 1 2 1 3 2 3 2\n\n\n\n\nTransform variables\nA new variable can be added to the data set, based on the values of an existing variable. For this we use the $ symbol.\nSome examples:\n\ndata$cyl2 <- data$cyl+2\n\ndata$hp10 <- data$hp/10\n\ndata$cyl2_hp10 <- data$cyl2 * data$hp10\n\n\nhead(data[, c(\"cyl\", \"hp\",\"cyl2\", \"hp10\", \"cyl2_hp10\")])\n\n                  cyl  hp cyl2 hp10 cyl2_hp10\nMazda RX4           6 110    8 11.0      88.0\nMazda RX4 Wag       6 110    8 11.0      88.0\nDatsun 710          4  93    6  9.3      55.8\nHornet 4 Drive      6 110    8 11.0      88.0\nHornet Sportabout   8 175   10 17.5     175.0\nValiant             6 105    8 10.5      84.0\n\n\n\n\nMake subset of your data\n\n\n\n\n\n\nTip\n\n\n\nCreate a new data set with a new name. Otherwise you might lose important information in your data.\n\n\nRemove observations with missings (NA) in “mpg” and “cyl”\n\ndata2 <- subset(data, !is.na(data$mpg) & !is.na(data$cyl))\n\n \nMake a new data set, including only mpg values > 20. (Don’t forget the comma in the code!)\n\ndata2 <- data[data$mpg > 20, ]\n\n \n\n\nRemove duplicates\nThis can be used if there are multiple measurement per patient, but you want to keep only the first.\n\ndata_short <- data[!duplicated(data$gear),]\n\n \n\nMake a subset: Remove variables\n\ndata2 <- data[, -c(1, 2)]\n\n \nOr\n\ndata2 <- subset(data, select = -c(mpg, cyl))\n\n\n\n\nMake a subset: Keep variables\n\ndata2 <- data[, c(\"mpg\", \"cyl\")]\n\nOr:\n\ndata2 <- subset(data, select = c(mpg, cyl))\n\n \n\nSort data\n\ndata2 <- data[order(data$mpg),]\nhead(data2)\n\n                     mpg cyl disp  hp drat    wt  qsec vs am gear CARB\nCadillac Fleetwood  10.4   8  472 205 2.93 5.250 17.98  0  0    3    4\nLincoln Continental 10.4   8  460 215 3.00 5.424 17.82  0  0    3    4\nCamaro Z28          13.3   8  350 245 3.73 3.840 15.41  0  0    3    4\nDuster 360          14.3   8  360 245 3.21 3.570 15.84  0  0    3    4\nChrysler Imperial   14.7   8  440 230 3.23 5.345 17.42  0  0    3    4\nMaserati Bora       15.0   8  301 335 3.54 3.570 14.60  0  1    5    8\n                    vs_factor vs_numeric cyl2 hp10 cyl2_hp10\nCadillac Fleetwood          0          0   10 20.5       205\nLincoln Continental         0          0   10 21.5       215\nCamaro Z28                  0          0   10 24.5       245\nDuster 360                  0          0   10 24.5       245\nChrysler Imperial           0          0   10 23.0       230\nMaserati Bora               0          0   10 33.5       335\n\n\n \n\n\nLongitudinal data\nWith repeated measures data can be in long format or wide format.\nWide format:\n\n\n\n\n\n\n\n\n\n\nLong format:\n\n\n\n\n\n\n\n\n\nIn wide format, the repeatedly measured variable has a new column for each measurement. In the long format, these measurements are placed in new rows. In the long format, each patient/observation will have multiple rows.\nHere is an example of a dataset in long format:\n\n\n\n\nhead(Orthodont, 10)\n\nGrouped Data: distance ~ age | Subject\n   distance age Subject  Sex\n1      26.0   8     M01 Male\n2      25.0  10     M01 Male\n3      29.0  12     M01 Male\n4      31.0  14     M01 Male\n5      21.5   8     M02 Male\n6      22.5  10     M02 Male\n7      23.0  12     M02 Male\n8      26.5  14     M02 Male\n9      23.0   8     M03 Male\n10     22.5  10     M03 Male\n\n\nEach subject (M01, M02, etc.) has 4 rows.\nIt depends on the analysis, which format is preferred and we might want to use this data in wide format. Use the function dcast() from the reshape2 package.\n\nSubject and Sex are measured only at baseline\nage indicates when the repeated measure is measured\ndistance is the value of this measurement\n\n\nlibrary(reshape2)\n\nWarning: package 'reshape2' was built under R version 4.2.3\n\nOrthodont_w <- dcast(Orthodont, Subject + Sex ~ age, value.var = \"distance\")\nhead(Orthodont_w)\n\n  Subject  Sex    8   10   12   14\n1     M16 Male 22.0 21.5 23.5 25.0\n2     M05 Male 20.0 23.5 22.5 26.0\n3     M02 Male 21.5 22.5 23.0 26.5\n4     M11 Male 23.0 23.0 23.5 25.0\n5     M07 Male 22.0 22.0 24.5 26.5\n6     M08 Male 24.0 21.5 24.5 25.5\n\n\nNotice how the variables age and distance have been replaced with their values.\nIf I start with a data set in wide format, but need to transform it to long format, I use the function melt() (also from reshape2).\n\nid denotes the variables that are only measured once (at baseline)\nmeasure are the variables that you want to stack\nvalue.name will be the variable name for the repeatedly measured variable\nvariable.name will denote which measurement it is (age of patient)\n\n\n\nlibrary(reshape2)\n\nOrthodont_L <- melt(Orthodont_w, id = c(\"Subject\", \"Sex\"),\n                     measure =c(\"8\", \"10\", \"12\", \"14\"), \n                     value.name = \"distance\",\n                     variable.name = \"age\")\nhead(Orthodont_L)\n\n  Subject  Sex age distance\n1     M16 Male   8     22.0\n2     M05 Male   8     20.0\n3     M02 Male   8     21.5\n4     M11 Male   8     23.0\n5     M07 Male   8     22.0\n6     M08 Male   8     24.0"
  },
  {
    "objectID": "Datacleaning.html#explore-data-set",
    "href": "Datacleaning.html#explore-data-set",
    "title": "Data Cleaning",
    "section": "Explore data set",
    "text": "Explore data set\n\nObtain the summaries of each variable\n\nsummary(data)\n\n      mpg             cyl             disp             hp       \n Min.   :10.40   Min.   :4.000   Min.   : 71.1   Min.   : 52.0  \n 1st Qu.:15.43   1st Qu.:4.000   1st Qu.:120.8   1st Qu.: 96.5  \n Median :19.20   Median :6.000   Median :196.3   Median :123.0  \n Mean   :20.09   Mean   :6.188   Mean   :230.7   Mean   :146.7  \n 3rd Qu.:22.80   3rd Qu.:8.000   3rd Qu.:326.0   3rd Qu.:180.0  \n Max.   :33.90   Max.   :8.000   Max.   :472.0   Max.   :335.0  \n      drat             wt             qsec             vs        \n Min.   :2.760   Min.   :1.513   Min.   :14.50   Min.   :0.0000  \n 1st Qu.:3.080   1st Qu.:2.581   1st Qu.:16.89   1st Qu.:0.0000  \n Median :3.695   Median :3.325   Median :17.71   Median :0.0000  \n Mean   :3.597   Mean   :3.217   Mean   :17.85   Mean   :0.4375  \n 3rd Qu.:3.920   3rd Qu.:3.610   3rd Qu.:18.90   3rd Qu.:1.0000  \n Max.   :4.930   Max.   :5.424   Max.   :22.90   Max.   :1.0000  \n       am              gear            CARB       vs_factor   vs_numeric    \n Min.   :0.0000   Min.   :3.000   Min.   :1.000   0:18      Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:3.000   1st Qu.:2.000   1:14      1st Qu.:0.0000  \n Median :0.0000   Median :4.000   Median :2.000             Median :0.0000  \n Mean   :0.4062   Mean   :3.688   Mean   :2.812             Mean   :0.4375  \n 3rd Qu.:1.0000   3rd Qu.:4.000   3rd Qu.:4.000             3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :5.000   Max.   :8.000             Max.   :1.0000  \n      cyl2             hp10         cyl2_hp10    \n Min.   : 6.000   Min.   : 5.20   Min.   : 31.2  \n 1st Qu.: 6.000   1st Qu.: 9.65   1st Qu.: 57.9  \n Median : 8.000   Median :12.30   Median : 98.4  \n Mean   : 8.188   Mean   :14.67   Mean   :130.0  \n 3rd Qu.:10.000   3rd Qu.:18.00   3rd Qu.:180.0  \n Max.   :10.000   Max.   :33.50   Max.   :335.0  \n\n\n \n\n\nObtain the summaries of one variable\nWith the $ symbol we access a variable in a data set.\n\nsummary(data$mpg)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  10.40   15.43   19.20   20.09   22.80   33.90 \n\n\nWith summary(), we can also look at the outliers and the missings (NA).\n\n\nGet the other summary statisitics\n\nmean(data$mpg)\n\n[1] 20.09062\n\nsd(data$mpg)\n\n[1] 6.026948\n\nmedian(data$mpg)\n\n[1] 19.2\n\nquantile(data$mpg)\n\n    0%    25%    50%    75%   100% \n10.400 15.425 19.200 22.800 33.900 \n\n\n\n\nGet summary statistics per group\nUse the function aggregate to obtain your summary statistics per group.\nThe last element in the function specifies what you want to calculate.\n\naggregate(mpg ~ vs, data = data, mean)\n\n  vs      mpg\n1  0 16.61667\n2  1 24.55714\n\naggregate(mpg ~ vs, data = data, sd)\n\n  vs      mpg\n1  0 3.860699\n2  1 5.378978\n\naggregate(mpg ~ vs, data = data, median)\n\n  vs   mpg\n1  0 15.65\n2  1 22.80\n\naggregate(mpg ~ vs, data = data, summary)\n\n  vs mpg.Min. mpg.1st Qu. mpg.Median mpg.Mean mpg.3rd Qu. mpg.Max.\n1  0 10.40000    14.77500   15.65000 16.61667    19.07500 26.00000\n2  1 17.80000    21.40000   22.80000 24.55714    29.62500 33.90000\n\n\n\n\nFrequency tables\nUse the function table() for this\n\ntable(data$vs)\n\n\n 0  1 \n18 14 \n\n\nprop.table() gives us proportions.\n\nprop.table(table(data$vs))\n\n\n     0      1 \n0.5625 0.4375 \n\n\nNotice how I need to use the function table() inside prop.table().\n\ntab1 <- table(data$vs)\nprop.table(tab1)\n\n\n     0      1 \n0.5625 0.4375 \n\n\nManually, I can multiply the proportions to obtain percentages.\n\nround(prop.table(tab1)*100,1)\n\n\n   0    1 \n56.2 43.8 \n\n\n\n\nCrosstabs\nTo investigate two categorical variables, I again use the function table().\n\ntable(data$vs, data$gear)\n\n   \n     3  4  5\n  0 12  2  4\n  1  3 10  1\n\n\nThis functions do not provide me with the variable names, so can be tricky to interpret this. The function with() can help with that.\n\nwith(data, table(vs, gear))\n\n   gear\nvs   3  4  5\n  0 12  2  4\n  1  3 10  1\n\n\nAgain use prop.table() for the proportions.\n\ntab2 <- with(data, table(vs, gear))\nprop.table(tab2) # cell percentages\n\n   gear\nvs        3       4       5\n  0 0.37500 0.06250 0.12500\n  1 0.09375 0.31250 0.03125\n\nprop.table(tab2, 1) # row percentages\n\n   gear\nvs           3          4          5\n  0 0.66666667 0.11111111 0.22222222\n  1 0.21428571 0.71428571 0.07142857\n\nprop.table(tab2, 2) # column percentages\n\n   gear\nvs          3         4         5\n  0 0.8000000 0.1666667 0.8000000\n  1 0.2000000 0.8333333 0.2000000"
  },
  {
    "objectID": "Datacleaning_practical.html",
    "href": "Datacleaning_practical.html",
    "title": "4  Data Cleaning - Practical",
    "section": "",
    "text": "For this practical we will use the data set R_data you can find on Canvas. This is a .csv file. Load the data in R. Make sure you specify the correct file path!\n\n\n\n\nR_data <- read.csv(\"~/R_data.csv\")\n\n\nQuestion 1\n\n\nWhat functions are useful for the first exploration of the data? How many observations and variables are in the data set? What type of variables are there?\n\n\n\n\nQuestion 2\n\n\nThere is a typo in one of the variable names (Stauts instead of Status). Change this.\n\n\n\n\nQuestion 3\n\n\nRound the variable folicacid_erys to two decimals.\nVerify by evaluating the first 20 values of this new variables (there are several ways to do this).\n\n\n\n\nQuestion 4\n\n\nMake a new variable birhtweight_kg that gives the birth weight in kilo’s What did you choose for the number of decimals to round the variable?\nVerify by evaluating the first 10 values of this new variables (there are several ways to do this).\n\n\n\n\nQuestion 5\n\n\nThe variables pregnancy_length_weeks and pregnancy_length_days together denote the total length of the pregnancy. For example: pregnancy_length_weeks = 38 and pregnancy_length_days = 4, means this patient is pregnant for 38 weeks plus 4 days. Combine the variables to obtain the length of the pregnancy in days.\nVerify by evaluating the first 12 values of this new variables (there are several ways to do this).\n\n\n\n\nQuestion 6\n\n\nDivide the variable BMI into categories: <18.5 (“Underweight”), 18.5 - 24.9 (“Healthy weight”), 25 - 29.9 (“Overweight”), and >30 (Obesity). How many patients (and %) are in each category?\n\n\n\n\nQuestion 7\n\n\nFor a current analysis, I am only interested in the patients with “Healthy weight”. Additionally, I only want to look at the relation between Status and birthweight. Make a data set with only these two variables and patientnumber, for a subset of the data with the patients with “Healthy weight”.\nWhat are the dimensions of this data set? First try to think yourself and then check with R code.\n\n\n\n\nQuestion 8\n\n\nMake a third data set containing the variables: patientnumber, Status and BMI. Then merge the data set you created in Question 7 with this data set.\nMerging these two data sets can be done several different ways. Describe two ways. What are the dimensions of these data sets?\n\n\n\n\nQuestion 9\n\n\nThere are several biomarkers collected in the data set. Investigate whether there are outliers in the biomarkers: cholesterol, triglycerides, and vitaminB12. Which functions did you use?\n\n\n\n\nQuestion 10\n\n\nIn question 9 we found an outlier. How do you deal with this outlier?\n\n\n\n\nQuestion 11Hint\n\n\nFill in the table with summary statistics below\n\n\n\n\n\n\n\n\n\n\n\nIntellectual disability\nNormal brain development\n\n\n\n\n\n\n(n = …)\n(n = …)\n\n\nBMI, median [IQR]\n\n\n\n\n\n\nmissing (n = )\n\n\n\n\nEducational level\nLow, n(%)\n\n\n\n\n\nIntermediate, n(%)\n\n\n\n\n\nHigh, n(%)\n\n\n\n\n\nmissing (n = )\n\n\n\n\nSmoking\nNo, n(%)\n\n\n\n\n\nYes, n(%)\n\n\n\n\n\nmissing (n = )\n\n\n\n\nSAM, mean (SD)\n\n\n\n\n\n\nmissing (n = )\n\n\n\n\nSAH, median [IQR]\n\n\n\n\n\n\nmissing (n = )\n\n\n\n\nVitamin B12, median [IQR]\n\n\n\n\n\n\nmissing (n = )\n\n\n\n\n\n\n\nYou can change the order of factors\nR_data$educational_level <- factor(R_data$educational_level, levels = c('low', 'intermediate', 'high'))"
  },
  {
    "objectID": "Datacleaning_answers.html",
    "href": "Datacleaning_answers.html",
    "title": "5  Data Cleaning - Answers",
    "section": "",
    "text": "Warning\n\n\n\nMake sure that you try the exercises yourself first before looking at the answers\n\n\n\n\n\n\nQuestion 1Answer 1\n\n\nWhat functions are useful for the first exploration of the data? How many observations and variables are in the data set? What type of variables are there?\n\n\nwith dim() and str() we can find out the dimensions of the data and the type of variables. The function head() can be used to view the first couple of observations.\n\ndim(R_data)\n\n[1] 190  20\n\nstr(R_data)\n\n'data.frame':   190 obs. of  20 variables:\n $ patientnumber         : int  1 2 3 4 5 6 7 8 9 10 ...\n $ Stauts                : chr  \"intellectual disability\" \"normal brain development\" \"intellectual disability\" \"normal brain development\" ...\n $ iodine_deficiency     : chr  \"no\" \"no\" \"no\" \"yes\" ...\n $ BMI                   : int  32 23 29 22 22 24 24 28 33 32 ...\n $ educational_level     : chr  \"intermediate\" \"intermediate\" \"low\" \"low\" ...\n $ alcohol               : chr  \"no\" \"yes\" \"no\" \"no\" ...\n $ smoking               : chr  \"no\" \"yes\" \"no\" \"no\" ...\n $ medication            : chr  \"no\" \"no\" \"no\" \"no\" ...\n $ birthweight           : int  2618 3541 2619 3810 4136 4030 3377 2500 4255 2952 ...\n $ pregnancy_length_weeks: int  38 40 38 40 42 41 40 37 42 39 ...\n $ pregnancy_length_days : int  4 2 3 5 3 1 4 1 0 2 ...\n $ SAM                   : num  54.5 84 61 43 83 69 79 71.5 56 42.5 ...\n $ SAH                   : num  14.8 23.6 18.7 23.2 17.1 19.6 22.4 18 20 23.4 ...\n $ homocysteine          : num  18.8 15.6 15.2 16.5 19.5 17.5 14.9 22.2 19.1 16 ...\n $ cholesterol           : num  16.5 17.5 16.4 16.4 16.9 15.9 16.9 16 18.6 16.7 ...\n $ HDL                   : num  26.1 26.7 26.2 25.9 26.7 ...\n $ triglycerides         : num  8.84 7.78 7.54 8.95 7.57 7.35 7.63 7.38 8.25 8.27 ...\n $ vitaminB12            : int  303 370 533 346 389 611 604 518 288 520 ...\n $ folicacid_serum       : num  26.4 37.8 33.7 35.1 29 28.3 33.8 31.1 27.7 33.4 ...\n $ folicacid_erys        : num  1132 1467 1528 1539 1178 ...\n\n\nThere are 190 observations and 20 variables. There are integers (int), factors (Factors), and numeric variables (num).\n\n\n\n\nQuestion 2Answer 2\n\n\nThere is a typo in one of the variable names (Stauts instead of Status). Change this.\n\n\n\nnames(R_data)[names(R_data) == \"Stauts\"] <- \"Status\"\nnames(R_data)\n\n [1] \"patientnumber\"          \"Status\"                 \"iodine_deficiency\"     \n [4] \"BMI\"                    \"educational_level\"      \"alcohol\"               \n [7] \"smoking\"                \"medication\"             \"birthweight\"           \n[10] \"pregnancy_length_weeks\" \"pregnancy_length_days\"  \"SAM\"                   \n[13] \"SAH\"                    \"homocysteine\"           \"cholesterol\"           \n[16] \"HDL\"                    \"triglycerides\"          \"vitaminB12\"            \n[19] \"folicacid_serum\"        \"folicacid_erys\"        \n\n\n\n\n\n\nQuestion 3Answer 3\n\n\nRound the variable folicacid_erys to two decimals.\nVerify by evaluating the first 20 values of this new variables (there are several ways to do this).\n\n\n\nR_data$folicacid_erys_round <- round(R_data$folicacid_erys, digits = 2)\nR_data[1:20, \"folicacid_erys_round\"]\n\n [1] 1132.00 1467.18 1527.81 1539.13 1177.54 1175.00 1396.00 1341.20 1228.52\n[10] 1327.22 1110.88 1289.36 1333.85 1329.62 1207.11 1340.00 1173.00 1653.00\n[19] 1088.00  970.00\n\n\n\n\n\n\nQuestion 4Answer 4\n\n\nMake a new variable birthweight_kg that gives the birth weight in kilo’s. What did you choose for the number of decimals to round the variable?\nVerify by evaluating the first 10 values of this new variables (there are several ways to do this).\n\n\n\nR_data$birthweight_kg <- round(R_data$birthweight/1000, digits = 1)\nR_data$birthweight_kg[1:10]\n\n [1] 2.6 3.5 2.6 3.8 4.1 4.0 3.4 2.5 4.3 3.0\n\n\n\n\n\n\nQuestion 5Answer 5\n\n\nThe variables pregnancy_length_weeks and pregnancy_length_days together denote the total length of the pregnancy. For example: pregnancy_length_weeks = 38 and pregnancy_length_days = 4, means this patient is pregnant for 38 weeks plus 4 days. Combine the variables to obtain the length of the pregnancy in days.\nVerify by evaluating the first 12 values of this new variables (there are several ways to do this).\n\n\n\nR_data$total_preg_days <- R_data$pregnancy_length_weeks*7 + R_data$pregnancy_length_days\nhead(R_data$total_preg_days, 12)\n\n [1] 270 282 269 285 297 288 284 260 294 275 263 249\n\n\n\n\n\n\nQuestion 6HintAnswer 6\n\n\nDivide the variable BMI into categories: <18.5 (“Underweight”), 18.5 - 24.9 (“Healthy weight”), 25 - 29.9 (“Overweight”), and >30 (Obesity). How many patients (and %) are in each category?\n\n\nUse the function cut()\n\n\n\nR_data$BMI_cat <- cut(R_data$BMI, breaks=c(-Inf, 18.5, 24.9, 29.9, Inf),\n                       labels=c(\"Underweight\", \"Healthy weight\", \"Overweight\", \"Obesity\"))\n\ntable(R_data$BMI_cat)\n\n\n   Underweight Healthy weight     Overweight        Obesity \n             1            104             76              9 \n\nprop.table(table(R_data$BMI_cat))\n\n\n   Underweight Healthy weight     Overweight        Obesity \n   0.005263158    0.547368421    0.400000000    0.047368421 \n\n\n\n\n\n\nQuestion 7HintAnswer 7\n\n\nFor a current analysis, I am only interested in the patients with “Healthy weight”. Additionally, I only want to look at the relation between Status and birthweight. Make a data set with only these two variables and patientnumber, for a subset of the data with the patients with “Healthy weight”.\nWhat are the dimensions of this data set? First try to think yourself and then check with R code.\n\n\nGive this data set a different name, so you don’t overwrite the original data set.\n\n\nOther solutions might be possible!\n\nR_data2 <- R_data[R_data$BMI_cat == \"Healthy weight\", c(\"patientnumber\",\"Status\", \"birthweight\")]\n\nstr(R_data2)\n\n'data.frame':   104 obs. of  3 variables:\n $ patientnumber: int  2 4 5 6 7 14 16 19 20 21 ...\n $ Status       : chr  \"normal brain development\" \"normal brain development\" \"intellectual disability\" \"intellectual disability\" ...\n $ birthweight  : int  3541 3810 4136 4030 3377 2828 2959 3383 2500 2720 ...\n\ndim(R_data2)\n\n[1] 104   3\n\n\n\n\n\n\nQuestion 8HintAnswer 8\n\n\nMake a third data set containing the variables: patientnumber, Status and BMI. Then merge the data set you created in Question 7 with this data set.\nMerging these two data sets can be done several different ways. Describe two ways. What are the dimensions of these data sets?\n\n\nFor these two data sets inner join and left join will give the same results. The same goes for right join and full join.\n\n\n\nR_data3 <- R_data[, c(\"patientnumber\",\"Status\", \"BMI\")]\n\n\ndata_inner <- merge(R_data2, R_data3, by = c(\"patientnumber\", \"Status\"))\ndata_right <- merge(R_data2, R_data3, by = c(\"patientnumber\", \"Status\"), all.y = T)\n\n\ndim(data_inner)\n\n[1] 104   4\n\ndim(data_right)\n\n[1] 190   4\n\n\n\n\n\n\nQuestion 9Answer 9\n\n\nThere are several biomarkers collected in the data set. Investigate whether there are outliers in the biomarkers: cholesterol, triglycerides, and vitaminB12. Which functions did you use?\n\n\n\n# Cholesterol\nhist(R_data$cholesterol)\n\n\n\nplot(R_data$cholesterol)\n\n\n\nboxplot(R_data$cholesterol)\n\n\n\nsummary(R_data$cholesterol)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  15.10   16.30   16.80   16.94   17.50   20.30 \n\n# triglycerides\nhist(R_data$triglycerides)\n\n\n\nplot(R_data$triglycerides)\n\n\n\nboxplot(R_data$triglycerides)\n\n\n\nsummary(R_data$triglycerides)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  7.350   7.710   7.925   8.068   8.270  10.300 \n\n# vitaminB12\nhist(R_data$vitaminB12)\n\n\n\nplot(R_data$vitaminB12)\n\n\n\nboxplot(R_data$vitaminB12)\n\n\n\nsummary(R_data$vitaminB12)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  201.0   307.0   370.5   409.7   463.0  3360.0 \n\n\nThere is one outlier in vitaminB12.\n\n\n\n\nQuestion 10Answer 10\n\n\nIn question 9 we found an outlier. How do you deal with this outlier?\n\n\nKnowing that the value of 3360 is an impossible value for vitamin B12, we can decide to remove this measurement. We can either put this measurement to missing (NA)\n\nR_data$vitaminB12_cor <- R_data$vitaminB12\nR_data$vitaminB12_cor[R_data$vitaminB12_cor  == 3360] <- NA \nsummary(R_data$vitaminB12_cor)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n  201.0   307.0   370.0   394.1   463.0   766.0       1 \n\n\nor we can remove the whole patient\n\nR_data_cor <- R_data[R_data$vitaminB12 != 3360,]\ndim(R_data_cor)\n\n[1] 189  25\n\n\n\n\n\n\nQuestion 11HintAnswer 11\n\n\nFill in the table with summary statistics below\n\n\n\n\n\n\n\n\n\n\n\nIntellectual disability\nNormal brain development\n\n\n\n\n\n\n(n = …)\n(n = …)\n\n\nBMI, median [IQR]\n\n\n\n\n\n\nmissing (n = )\n\n\n\n\nEducational level\nLow, n(%)\n\n\n\n\n\nIntermediate, n(%)\n\n\n\n\n\nHigh, n(%)\n\n\n\n\n\nmissing (n = )\n\n\n\n\nSmoking\nNo, n(%)\n\n\n\n\n\nYes, n(%)\n\n\n\n\n\nmissing (n = )\n\n\n\n\nSAM, mean (SD)\n\n\n\n\n\n\nmissing (n = )\n\n\n\n\nSAH, median [IQR]\n\n\n\n\n\n\nmissing (n = )\n\n\n\n\nVitamin B12, median [IQR]\n\n\n\n\n\n\nmissing (n = )\n\n\n\n\n\n\n\nYou can change the order of factors\nR_data$educational_level <- factor(R_data$educational_level, levels = c('low', 'intermediate', 'high'))\n\n\n\ntable(R_data$Status)\n\naggregate(BMI ~ Status, data = R_data, summary)\nR_data$educational_level <- factor(R_data$educational_level, levels = c('low', 'intermediate', 'high'))\nwith(R_data, table(educational_level, Status))\nprop.table(with(R_data, table(educational_level, Status)),2)\n\nwith(R_data, table(smoking, Status))\nprop.table(with(R_data, table(smoking, Status)),2)\n\naggregate(SAM ~ Status, data = R_data, mean)\naggregate(SAM ~ Status, data = R_data, sd)\n\naggregate(SAH ~ Status, data = R_data, summary)\n\naggregate(vitaminB12_cor ~ Status, data = R_data, summary)\n\n\n\n\n\n\n\n\n\n\n\n\nIntellectual disability\nNormal brain development\n\n\n\n\n\n\n(n = 82)\n(n = 108)\n\n\nBMI, median [IQR]\n\n24 [22 - 27]\n24 [22 - 26]\n\n\n\nmissing (n = 0 )\n\n\n\n\nEducational level\nLow, n(%)\n31 (38%)\n14 (13%)\n\n\n\nIntermediate, n(%)\n34 (41%)\n48 (44%)\n\n\n\nHigh, n(%)\n17 (21%)\n46 (43%)\n\n\n\nmissing (n = 0)\n\n\n\n\nSmoking\nNo, n(%)\n55 (67%)\n96 (89%)\n\n\n\nYes, n(%)\n27 (33%)\n12 (11%)\n\n\n\nmissing (n = 0)\n\n\n\n\nSAM, mean (SD)\n\n72 (16)\n75 (18)\n\n\n\nmissing (n = 0)\n\n\n\n\nSAH, median [IQR]\n\n16 [15 - 18]\n18 [16 - 20]\n\n\n\nmissing (n = 0)\n\n\n\n\nVitamin B12, median [IQR]\n\n378 [310 - 477]\n363 [305 - 449]\n\n\n\nmissing (n = 1)"
  },
  {
    "objectID": "Analysis.html#hypothesis-testing-and-confidence-intervals",
    "href": "Analysis.html#hypothesis-testing-and-confidence-intervals",
    "title": "Analysis",
    "section": "Hypothesis testing and Confidence Intervals",
    "text": "Hypothesis testing and Confidence Intervals\nComparison is the most common basic principle in medical research. A statement about the truth is compared against a reference statement (the null).\n\n\\(H_0\\): Null hypothesis, e.g. cholesterol is comparable between men and women\n\\(H_1\\): Alternative hypothesis, e.g. men and women differ on average in cholesterol\n\nThe p-value is the probability of obtaining the observed data in the sample (or some- thing more extreme than the observed data), given that the null hypothesis is true. The p-value is calculated based on a point estimate (e.g. mean) of the sample. The decision to reject a null hypothesis based on the p-value depends on a chosen \\(\\alpha\\) level.\n\n\n\n\n\n\n\n\n\nFor a given dataset and corresponding test statistic, we say the results of the test are “statistically significant” if the p-value is less than the pre-selected and fixed significance level, \\(\\alpha\\) (often 0.05).\nNote that there is a distinction between statistical significance and clinical relevance:\n\nIf the sample size is large enough, even a small difference of 0.1 mmHg blood pressure can be statistically signifcant between groups, though it is not relevant from a clinical point of view.\nIf the sample size is too small, even a sample mean of 150 mmHg can be not statistically significantly different from 130 mmHg, though 20 mmHg is clinically relevant.\n\nA confidence interval (CI) is another way to show the reliability of a point estimate. The decision to reject or not reject the null hypothesis aligns with whether or not the CI contains the null value (e.g. \\(H_0\\): mean = 0; if CI does not contain 0 then reject, otherwise do not reject \\(H_0\\)). In other words, the decision made by comparing the test statistic’s p-value to \\(\\alpha\\) will be the same as a decision made using a \\((1 - \\alpha) * 100\\%\\) CI. An interpretation of e.g. a 95% CI is “if the testing procedure were repeated on many (k) samples, the confidence intervals would encompass the true population parameter in 95% of the k samples” or, more abstractly, “we are 95% confident that the true [e.g. mean] lies in the confidence interval”."
  },
  {
    "objectID": "Analysis.html#comparing-groups",
    "href": "Analysis.html#comparing-groups",
    "title": "Analysis",
    "section": "Comparing groups",
    "text": "Comparing groups\n\nt-Test\nThe t-test is a statistical procedure used to test for the difference in means between two independent populations. The samples should come from normal distributions (can check using e.g. qqnorm()) and the variances from each population are assumed to be equal.\n\n\n\n\n\n\n\n\n\nThe t-test in R makes a correction that does not require equal variances of the two populations. The null hypothesis is that the difference between means is 0; the alternative is that this difference is not 0.\nHere is an example of how to do this test in R. In a data set on tooth growth, it appears that OJ recipients in the sample had a larger tooth growth than VC recipients, on average. We can test if this is true in the larger population using a t-test. Let’s set \\(H_0\\) to be that the two mean tooth lengths are the same and \\(H_a\\) will be that the two mean tooth lengths are not equal. Let’s use a 0.10 significance level, which means the probability we falsely reject the null is 0.10. Note that the function t.test also provides a confidence interval - the confidence level specified should be \\(1 - \\alpha\\) for the interpretations to align.\n\ndata(\"ToothGrowth\")\n\nttooth <- t.test(ToothGrowth$len~ToothGrowth$supp, conf.level = 0.90)\nttooth\n\n\n    Welch Two Sample t-test\n\ndata:  ToothGrowth$len by ToothGrowth$supp\nt = 1.9153, df = 55.309, p-value = 0.06063\nalternative hypothesis: true difference in means between group OJ and group VC is not equal to 0\n90 percent confidence interval:\n 0.4682687 6.9317313\nsample estimates:\nmean in group OJ mean in group VC \n        20.66333         16.96333 \n\n\nHere the p-value is less than our chosen significance level so we reject the null. Therefore, at the 10% significance level, the data provide sufficient evidence that our alternative hypothesis, that there is a difference between using OJ and VC to grow teeth, is true.\nNow consider the following example. Suppose we believe the mean reaction velocity in an enzymatic reaction will be higher in cells treated with Puromycin compared to cells not treated with Puromycin. Let’s use the 0.05 significance level, allowing for a slightly smaller Type I error probability than in the previous example.\n\ndata(\"Puromycin\")\n\nt.test(rate ~ state, data = Puromycin, alternative = \"greater\")\n\n\n    Welch Two Sample t-test\n\ndata:  rate by state\nt = 1.6375, df = 19.578, p-value = 0.05875\nalternative hypothesis: true difference in means between group treated and group untreated is greater than 0\n95 percent confidence interval:\n -1.677431       Inf\nsample estimates:\n  mean in group treated mean in group untreated \n               141.5833                110.7273 \n\n\nHere our p-value is greater than \\(\\alpha\\) so we do not reject the null hypothesis. We therefore conclude that, at the 5% significance level, the data do not provide sufficient evidence that Puromycin increases the mean reaction velocity.\nWe can extract statistics from the output:\n\nmytest <- t.test(rate~state, data = Puromycin, alternative = \"greater\")\nmytest$p.value\n\n[1] 0.05874922\n\nmytest$conf.int\n\n[1] -1.677431       Inf\nattr(,\"conf.level\")\n[1] 0.95\n\n\nCan you guess why the CI goes to Inf (infinity)?\nIf samples are matched or paired (e.g. before/after), use argument paired=TRUE.\n\n\nMann-Whitney U Test\nThe Mann-Whitney U test (also known as the Wilcoxon Rank Sum test) is a non- parametric test for a location shift between two independent populations without assuming normality. However, the values should be sampled from two populations with very similar distributions. The null hypothesis is that there is no shift in the centers of the distributions of the two populations; the alternative is that there is a shift.\n\n\n\n\n\n\n\n\n\n\nwtest <- wilcox.test(rate~state, data = Puromycin, conf.int = TRUE)\nwtest\n\n\n    Wilcoxon rank sum exact test\n\ndata:  rate by state\nW = 88, p-value = 0.1896\nalternative hypothesis: true location shift is not equal to 0\n95 percent confidence interval:\n -10  75\nsample estimates:\ndifference in location \n                    36 \n\nwtest$p.value\n\n[1] 0.1895867\n\n\nThe test statistic W in R is defined to be the sum of the ranks of one of the groups minus \\(n_1(n_1 +1)/2\\). The procedure to obtain a confidence interval is quite involved, but thankfully R will provide it to us upon request.\n\n\nANOVA\nA two-sample t-test is used to test hypotheses about the means of two normal populations using two datasets which were sampled independently of one another from the two respective populations. An analysis of variance (ANOVA) allows for comparing the means of one variable among more than two populations (each of which is normally distributed), again under the assumption that the samples are independent.\n\nIf the variance between groups is higher than the variance within groups, then there is evidence for a difference in means between groups.\nThe null hypothesis is that the means of all groups are equal; the alternative is that at least one group has a different mean from the others.\nANOVA does not provide which group is different nor in what direction; visualization and/or post-hoc pairwise t-tests can provide this information.\n\nHere is a small illustration of the analysis of variance:\n\n\n\n\n\n\n\n\n\nIn the left image there is more variability within each of the three groups (boxplots) than between the three group means (\\(\\bar{x}_1\\), \\(\\bar{x}_2\\), \\(\\bar{x}_3\\)). In the right image there is more variability between the three group means than within each of the three groups..\nAs with the previous testing procedures we’ve seen, we compare the p-value to the pre-selected significance level. If \\(p \\leq \\alpha\\) we reject the null and conclude we have evidence that at least one population (or group) mean is different from the others, while if \\(p > \\alpha\\), we fail to reject the null and conclude we do not have evidence that any of the means are different.\nR will calculate all of the statistics for us! For example, let’s test at the 5% significance level the alternative hypothesis that at least one of the mean BMIs for three different educational levels are different from the other two (versus the null of three equal means).\n\n\nWarning: package 'readr' was built under R version 4.2.3\n\n\n\nlibrary(readr)\nR_data <- read_csv(\"~/R_data2.csv\")\n\n\nbaby_aov1 <- aov(BMI ~ educational_level, data = R_data)\nsummary(baby_aov1)\n\n                   Df Sum Sq Mean Sq F value Pr(>F)  \neducational_level   2   63.8   31.90   3.409 0.0351 *\nResiduals         187 1749.8    9.36                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nHere the F-statistic is large enough to get a p-value smaller than 0.05 so we conclude at least one population mean BMI is different from the other two. But which group is it? Let’s look at a boxplot:\n\nboxplot(R_data$BMI ~ R_data$educational_level)\n\n\n\n\nThis visual information is informative but we can actually make pairwise comparisons of all the means using Tukey’s HSD (for example). We initially used a significance level of 0.05, but will now conduct several tests and use a multiple test procedure that adjusts the family-wise error rate to 5%:\n\nTukeyHSD(baby_aov1)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = BMI ~ educational_level, data = R_data)\n\n$educational_level\n                       diff         lwr      upr     p adj\nintermediate-high 1.1397600 -0.07099027 2.350510 0.0697761\nlow-high          1.3587302 -0.05180238 2.769263 0.0617385\nlow-intermediate  0.2189702 -1.12174472 1.559685 0.9212512\n\n\nNote that we use the multiple testing procedure to account for the fact that we are simultaneously performing more than one test or CI which compounds the error rates of each test. Since all of the CIs contain 0 and none of the p-values are significant at the 5% level, the initial test result is overturned! We do not actually have evidence that education level affects average BMI.\nAlso note you would not bother with these posthoc tests/CIs if your initial ANOVA results were not statistically significant.\n\n\nKruskal-Wallis Test\nThe single-factor ANOVA model for comparing population or treatment means assumed that for all groups, random samples were drawn from normal populations each having the same variance. This normality assumption is required for a valid F test, but the next procedure for testing the equality of the centers of the distributions only requires that the populations have the same continuous distribution.\nThe null hypothesis is that all of the group centers are the same and the alternative is that at least one of the group centers is different. The Kruskal-Wallis test examines the validity of these hypotheses by working on ranks of the data without assuming the data come from a specific distribution.\nThe procedure starts by ranking all the data together on the assumption of the null, that if the centers of the groups are equal, the ranks from all the groups will be intermingled. If the null is false, then some samples will consist mostly of observations having small ranks in the combined sample, whereas others will consist mostly of observations having large ranks.\nThe Kruskal-Wallis test statistic is a measure of the extent to which the sums of the ranks within each group deviate from their common expected value, and the null is rejected if the computed value of the statistic indicates too great a discrepancy between observed and expected rank averages.\nExample. The accompanying observations on axial stiffness index resulted from a study of metal-plate connected trusses in which five different plate lengths (4 in., 6 in., 8 in., 10 in., and 12 in.) were used.\n\n\n\n\n\n\n\n\n\nHere we read in the data:\n\n\n\n\nlibrary(readr)\nstiffness <- read_csv(\"Data/stiffness.csv\")\n\nIf we look at the boxplot of the stiffness values for each length, we see that the means are probably different and that the boxplots don’t look very normal:\n\nboxplot(stiffness~lengths, data = stiffness)\n\n\n\n\nThe output of the Kruskal-Wallis test confirms that the means are indeed different. The p-value is quite small, indicating at least two of the group centers are different:\n\nkruskal.test(stiffness~lengths, data = stiffness)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  stiffness by lengths\nKruskal-Wallis chi-squared = 20.122, df = 4, p-value = 0.0004724\n\n\n\n\nChi-squared test\nA \\(\\chi^2\\) (read: chi-squared) test of independence tests the null hypothesis that rows and columns are independent in a c x r contingency table (r is number of rows, c columns); the alternative is that they are not independent. The counts must be independent and sampled randomly. We can calculate a chi-squared statistic as follows:\n\\(\\chi^2 = \\sum \\frac{(O_i-E_i)^2}{E_i}\\)\nwhere \\(O_i\\) is the observed count for cell i in the table, and \\(E_i\\) is the expected count, calculated by multiplying the row and column totals for i divided by the overall total. The p-value for the calculated \\(\\chi^2\\) statistic depends on the \\(\\chi^2\\) distribution with \\((r -1)*(c-1)\\) degrees of freedom. R will provide us with the statistic and p-value.\nSuppose we have the following table:\n\n\n\n\nevent\nno event\ntotal\n\n\n\n\ntreatment\n20\n80\n100\n\n\nplacebo\n50\n50\n100\n\n\ntotal\n70\n130\n200\n\n\n\nand we want to know whether our treatment prevents events, that is, does the occurence of an event depend on the type of treatment?\n\nmytable <- matrix(c(20, 50, 80, 50), nrow=2)\nmytable\n\n     [,1] [,2]\n[1,]   20   80\n[2,]   50   50\n\ncstest <- chisq.test(mytable)\ncstest\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  mytable\nX-squared = 18.484, df = 1, p-value = 1.714e-05\n\ncstest$p.value\n\n[1] 1.713801e-05\n\n\n\n\nCorrelations\nIf we want to know the degree of a linear association between 2 variables, we can calculate correlation. Correlation does not make any a priori assumptions about whether one variable is dependent on the other and is not concerned with the relationship between the variables. We have 4 general types of association to consider:\n\n\n\n\n\n\n\n\n\nPearson’s r can only lie in the interval [-1,1] (inclusive), where\n\nr = 0, no linear correlation\nr > 0, positive linear correlation\nr < 0, negative linear correlation\nr = 1, perfect positive linear correlation\nr = -1, perfect negative linear correlation\n\nNote that correlation does not imply causation. If two variables are highly correlated you cannot infer that one is causing the other; they could both be varying along with a third, possibly unknown confounding factor (either causal or not).\nFor Pearson’s r we assume a linear relationship between x and y and that they both follow a normal distribution.\nIf data are not normally distributed, the degree of association can be determined by the ranked correlation coefficient, Spearman’s \\(\\rho\\), which replaces the x’s and y’s in the Pearson formula with their ranks.\nR provides p-values and confidence intervals for both Pearson and Spearman correlations.\nLet’s look at an example of how BMI and cholesterol are associated:\n\nplot(R_data$BMI,  R_data$cholesterol)\n\n\n\ncor(R_data$BMI,  R_data$cholesterol)\n\n[1] 0.2004703\n\ncor(R_data$BMI,  R_data$cholesterol, method=\"spearman\")\n\n[1] 0.1876358\n\ncor.test(R_data$BMI,  R_data$cholesterol)\n\n\n    Pearson's product-moment correlation\n\ndata:  R_data$BMI and R_data$cholesterol\nt = 2.8057, df = 188, p-value = 0.00555\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.05982424 0.33331173\nsample estimates:\n      cor \n0.2004703 \n\ncor.test(R_data$BMI,  R_data$cholesterol, method=\"spearman\")\n\nWarning in cor.test.default(R_data$BMI, R_data$cholesterol, method =\n\"spearman\"): Cannot compute exact p-value with ties\n\n\n\n    Spearman's rank correlation rho\n\ndata:  R_data$BMI and R_data$cholesterol\nS = 928642, p-value = 0.009531\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n      rho \n0.1876358 \n\n\nNote the warning message (which is not an error!) that indicates if your data have tied values (e.g. 1, 1, 3, 5) then the p-value is approximated and is not exact. It’s nothing to worry about (especially if you’re not a statistician…)."
  },
  {
    "objectID": "Analysis.html#regression",
    "href": "Analysis.html#regression",
    "title": "Analysis",
    "section": "Regression",
    "text": "Regression\n\nLinear regression\nThere is a high positive correlation between birth weight and gestational age, but this says nothing about predictive power of the variables. We would like to explain how gestational age influences changes in birth weight.\n\nplot(R_data$pregnancy_length_weeks, R_data$birthweight)\n\n\n\ncor(R_data$pregnancy_length_weeks, R_data$birthweight)\n\n[1] 0.9785784\n\n\nWe’ll quantify this relationship using linear regression, distinguishing between an in- dependent, or predictor or explanatory, variable (gestational age) and a dependent, or response or outcome, variable (birth weight). Simple linear regression uses the following model:\n\\(Y_i = \\beta_0 + \\beta_1*X_i + \\varepsilon_i\\)\nwhere \\(1 \\leq i \\leq n\\), the model is a straight line, and error is remaining variation which cannot be explained by the model. The parameters \\(beta_0\\) and \\(\\beta_1\\) are the intercept and slope of a straight line, respectively.\nThe \\(\\beta_0\\) and \\(\\beta_1\\) of the one straight line that best fits the data is estimated via the method of least squares. The “best” line is the one that has the lowest sum of squared residuals. The command to get these estimates in R is lm:\n\nlm1 <- lm(birthweight ~ pregnancy_length_weeks, data = R_data)\nlm1\n\n\nCall:\nlm(formula = birthweight ~ pregnancy_length_weeks, data = R_data)\n\nCoefficients:\n           (Intercept)  pregnancy_length_weeks  \n              -12441.4                   400.3  \n\n\nYou can predict for given values\n\npredict(lm1)[R_data$pregnancy_length_weeks==35]\n\n      12       73      141 \n1568.921 1568.921 1568.921 \n\n\nYou can also use predict() to predict y for x’s that are not already in your data:\n\npredict(lm1, newdata=data.frame(pregnancy_length_weeks=c(seq(25,50,5))))\n\n         1          2          3          4          5          6 \n-2434.0284  -432.5538  1568.9207  3570.3952  5571.8698  7573.3443 \n\n\nbut watch out for extrapolating (predicting outside the range of your data) - clearly we can’t have negative birth weights!\nNow, before we make inference on or, actually, even find and use this line, we must check that the following assumptions hold, otherwise we will not obtain trustworthy results: - relationship between x and y can be described by a straight line - outcomes y are independent - variance of residuals is constant across values of x - residuals follow a normal distribution\nTo get diagnostic plots in R, we can check a histogram of the data and additionally plot our model to check that the residuals are normal and homoscedastic (have constant variance) across the weeks:\n\nhist(R_data$birthweight)\n\n\n\npar(mfrow=c(2,2))\nplot(lm1)\n\n\n\n\nThe top left plot tells us if our residuals are homoscedastic, and the top right plot displays a quantile-quantile (QQ) plot to check for normality. Here are examples of bad QQ plots and heteroscedasticity:\n\nset.seed(1234)\npar(mfrow=c(2,2))\nx <- sort(rnorm(100))\ny1 <- sort(rt(100,2))\nplot(x, y1, xlim=c(-3,3), xlab=\"normal\", ylab=\"t, df=2\")\nabline(0, 1)\ny2 <- sort(rexp(100))\nplot(x, y2, xlim=c(-3,3), ylim=c(-6,6), xlab=\"normal\", ylab=\"exponential\")\nabline(0, 1)\nplot(x, x^2-5+rexp(100))\nabline(0, 0, col=\"red\")\nplot(x, x*rexp(100))\nabline(0, 0, col=\"red\")\n\n\n\n\nHowever, the assumptions reasonably hold for our baby data, so we’ll go ahead and use the model fit to make inference on the slope.\nActually, R has already done the inference…we just need to extract it from the model:\n\nsummary(lm1)\n\n\nCall:\nlm(formula = birthweight ~ pregnancy_length_weeks, data = R_data)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-280.1 -106.7   -2.9  101.2  331.4 \n\nCoefficients:\n                         Estimate Std. Error t value Pr(>|t|)    \n(Intercept)            -12441.401    242.033  -51.40   <2e-16 ***\npregnancy_length_weeks    400.295      6.142   65.17   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 135.7 on 188 degrees of freedom\nMultiple R-squared:  0.9576,    Adjusted R-squared:  0.9574 \nF-statistic:  4248 on 1 and 188 DF,  p-value: < 2.2e-16\n\n\nR has performed a one-sample t-test on the intercept b1 and slope b0 to determine if they are each statistically significantly different from 0. The probabilities are quite small, so we can reject the null hypothesis that they are equal to 0 and conclude that birthweight significantly increases, on average, by 400 grams per every additional week of gestation. The intercept is (usually) unimportant and we don’t really care that it is different from 0. If the p-value for the slope is not small (e.g. greater than 0.05) then we would say “we do not have enough evidence to reject the null hypothesis that the slope is 0.”\nNow, how good does the model actually fit our data? How well does x predict y? The square of Pearson’s correlation coefficient, r, is a measure of goodness of fit. It is the proportion of variance in y that can be explained by the model (so, x). In our example, r2 is:\n\ncor(R_data$pregnancy_length_weeks, R_data$birthweight)^2\n\n[1] 0.9576157\n\nsummary(lm1)$r.squared\n\n[1] 0.9576157\n\n\nwhich means that 96% of the variability in birth weight can be explained by gestational age.\nSimple linear regression models one y on one x. If we have multiple predictor variables, we use multiple linear regression to determine if the variability in y can be explained by this set of variables. In addition to the assumptions required for a valid simple linear regression, we now include that the covariates have no perfect multicollinearity, that is there is no strong correlation between the multiple x’s. The model is\n\\(Y_i = \\beta_0 + \\beta_1*X_{1i} + ... + \\beta_k*X_{ki}+\\varepsilon_i\\)\nIn R, the addition of an extra variable is quite straightforward:\n\ncor(R_data$pregnancy_length_weeks, R_data$BMI)\n\n[1] 0.01068054\n\nlm2 <- lm(birthweight ~ pregnancy_length_weeks + BMI, data = R_data)\nlm2stats <- summary(lm2)\nlm2stats\n\n\nCall:\nlm(formula = birthweight ~ pregnancy_length_weeks + BMI, data = R_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-279.39 -105.78   -1.85  105.25  333.50 \n\nCoefficients:\n                         Estimate Std. Error t value Pr(>|t|)    \n(Intercept)            -12377.339    253.444 -48.837   <2e-16 ***\npregnancy_length_weeks    400.351      6.147  65.133   <2e-16 ***\nBMI                        -2.738      3.190  -0.858    0.392    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 135.8 on 187 degrees of freedom\nMultiple R-squared:  0.9578,    Adjusted R-squared:  0.9573 \nF-statistic:  2121 on 2 and 187 DF,  p-value: < 2.2e-16\n\n\nSince the 2 variables are uncorrelated, we can add BMI to the model. We see that it does not significantly predict birth weight, but gestational age still does. We use the adjusted \\(r^2\\) to check goodness of fit:\n\nlm2stats$adj.r.squared\n\n[1] 0.9573304\n\n\nSo adding BMI does not help explain any of the variability in birth weight (since r2 was previously already 0.96). This is also confirmed by visualization:\n\nplot(R_data$BMI, R_data$birthweight)\n\n\n\n\nNote that the summary function returns a lot of information. If, for example, you wanted to extract only the p-values you could do the following:\n\nnames(lm2stats)\n\n [1] \"call\"          \"terms\"         \"residuals\"     \"coefficients\" \n [5] \"aliased\"       \"sigma\"         \"df\"            \"r.squared\"    \n [9] \"adj.r.squared\" \"fstatistic\"    \"cov.unscaled\" \n\nlm2stats$coef[,4]\n\n           (Intercept) pregnancy_length_weeks                    BMI \n         2.179929e-108          1.815592e-130           3.918778e-01 \n\n\nWe can predict birthweights with new data:\n\npredict(lm2, newdata=data.frame(pregnancy_length_weeks=32,\nBMI=30))\n\n      1 \n351.771 \n\n\nBut we cannot forget to check assumptions!\n\npar(mfrow=c(2,2))\nplot(lm2)\n\n\n\npar(mfrow=c(1,1))\nhist(lm2$residuals)\n\n\n\n\n\n\nLogistic regression\nThere are many research topics for with the dependent variable y is binary (0/1), e.g.\n\nmortality (dead/alive)\ntreatment response (responder/non-responder)\ndevelopment of disease (yes/no)\n\nand we want to predict the membership of an individual to one of the two categories based on a set of predictors.\nIn this situation we have to work with probabilities, which are numbers between 0 and 1. A value \\(P(y)\\) that is close to 0 means that y is very unlikely to occur, while a value close to 1 means that y is very likely to occur.\nIn simple/multiple linear regression a continuous variable y is predicted by continuous/categorical x(s), but if y can only have 2 values (e.g. y = 0 or y = 1), how do we predict the probability that y = 1 given one or more predictors? Could we apply a linear regression model…?\nwe would try to fit \\(P(y = 1) = \\beta_0 + \\beta_1X\\), which doesn’t work. In linear regression we assume the relationship between x and y is linear, but in the case of binary outcomes this assumption is no longer valid. Results obtained from a linear regression model wouldn’t makes sense! Probabilities beyond the interval (0,1) are not interpretable.\nInstead we’re going to use a logistic curve:\n\\(ln(\\frac{p}{1-p}) = \\beta_0 + \\beta_1X\\)\nThe function \\(ln(p/(1- p))\\) is called a logit of p and it is this function of y that is linear in x instead of y itself.\nThis model formulation assures that the predicted probability of an event falls between 0 and 1, unlike a linear regression model.\nAlso note that we’ve made no assumptions about linearity, normality or homoscedasticity! The values of the intercept and slope are estimated using the maximum likelihood method, which finds the values of the coefficients that make the observed data most likely to occur. Statistical significance of estimate coefficients is testing with the Wald test, which is based on the \\(\\chi^2\\) distribution (though R calls it “z”). The goodness of fit is assessed by deviance, which is based on the differences observed-expected principle. Also, the Akaike information criterion (AIC) gives a measure of the quality of the model. The coefficients are most usefully interpreted with the following:\n\\(e^{\\beta} \\ \\frac{\\textrm{odds after a unit change}}{\\textrm{original odds}}\\)\nand when x is binary, \\(e^{\\beta}\\) is the odds ratio from the 2 by 2 contingency table!\nIn R:\n\nR_data$StatusNew <- factor(R_data$Status, \n                           levels = c(\"normal brain development\", \"intellectual disability\"))\nlevels(R_data$StatusNew)\n\n[1] \"normal brain development\" \"intellectual disability\" \n\nlr1 <- glm(StatusNew ~ BMI, family = binomial(logit), data = R_data)\nsummary(lr1)\n\n\nCall:\nglm(formula = StatusNew ~ BMI, family = binomial(logit), data = R_data)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-1.2759  -1.0805  -0.9168   1.2680   1.4627  \n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)  \n(Intercept) -2.40591    1.18095  -2.037   0.0416 *\nBMI          0.08782    0.04822   1.821   0.0685 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 259.83  on 189  degrees of freedom\nResidual deviance: 256.44  on 188  degrees of freedom\nAIC: 260.44\n\nNumber of Fisher Scoring iterations: 4\n\n\nso \\(logit(p) = -2.40591+0.08782* BMI\\). Thus the probability of having a baby with an intellectual disability when BMI is 32, is:\n\nlogit_p1 <- -2.40591+0.08782*32\nlogit_p1\n\n[1] 0.40433\n\n\nOr\n\npredict(lr1, newdata = data.frame(BMI = 32), se.fit = TRUE)\n\n$fit\n        1 \n0.4043502 \n\n$se.fit\n[1] 0.3995839\n\n$residual.scale\n[1] 1\n\n\nTo obtain the probability of the event use type = \"response\"\n\npredict(lr1, newdata = data.frame(BMI = 32), se.fit = TRUE, type = \"response\")\n\n$fit\n        1 \n0.5997324 \n\n$se.fit\n        1 \n0.0959215 \n\n$residual.scale\n[1] 1\n\n\nThe coefficient b1 = 0.08782 can be exponentiated to obtain the odds ratio:\n\nsummary(lr1)$coef\n\n               Estimate Std. Error   z value   Pr(>|z|)\n(Intercept) -2.40591055 1.18095490 -2.037259 0.04162413\nBMI          0.08782065 0.04821621  1.821393 0.06854720\n\nb1 <- summary(lr1)$coef[2, 1]\nb1\n\n[1] 0.08782065\n\nexp(b1)\n\n[1] 1.091792\n\n\nLike multiple linear regression, we can add variables into the model here as well:\n\nlr2 <- glm(StatusNew ~ BMI + smoking, family = binomial(logit), data = R_data)\nsummary(lr2)$coef\n\n               Estimate Std. Error   z value    Pr(>|z|)\n(Intercept) -2.52420359 1.22600372 -2.058887 0.039505027\nBMI          0.08128428 0.04997051  1.626645 0.103812552\nsmokingyes   1.34305855 0.38824022  3.459349 0.000541482\n\n\nThus the probability of having a baby with an intellectual disability when BMI is 32, and the mother is a smoker is:\n\nmynewdata <- data.frame(BMI = 32, smoking = factor(\"yes\"))\nlogit_p2 <- predict(lr2, newdata = mynewdata, type = \"response\")\nlogit_p2\n\n        1 \n0.8053309"
  },
  {
    "objectID": "Analysis_practical.html",
    "href": "Analysis_practical.html",
    "title": "Analysis - Practical",
    "section": "",
    "text": "For this practical we will use the data set R_data2 you can find on Canvas. This is a .csv file. Load the data in R. Make sure you specify the correct file path!\n\n\n\n\n\n\nImportant\n\n\n\nThis is a slightly different version of the data set used in the practical on data cleaning! You can still answer the questions, but the results might differ a bit!\n\n\n\n\nWarning: package 'readr' was built under R version 4.2.3\n\n\n\nlibrary(readr)\nR_data <- read_csv(\"~/R_data2.csv\")\n\n\nQuestion 1\n\n\nIn this question we will look at the variable SAH.\n\nWhat are the mean, median, variance and standard deviation of SAH?\nCreate a histogram and a horizontal boxplot of SAH.\nUtilize the graphs and the summary statistics to describe the shape of the distribution of SAH.\nLog-transform SAH (assign it to log_SAH).\nDescribe the distribution of log_SAH, based on the same techniques.\n\n\n\n\n\nQuestion 2Hint 1Hint 2\n\n\nAre the values of SAH different for the two levels of Status (normal brain development or intellectual disability)? Formulate a hypothesis, test it, and make a decision about whether or not you can reject the null hypothesis. Can you use a t-test (either on the raw or log-transformed data)? Why or why not?\n\n\nCheck the distributions with plots.\n\n\nFor normally distributed data you can use a t-test, for non-normally distributed data you can use the Wilcoxon signed rank test (also knows as the Mann-Whitney U test).\n\n\n\n\nQuestion 3\n\n\nMake a boxplot of the SAH values of the 2 groups and calculate the median difference of SAH between the 2 groups.\nDoes the difference seem clinically relevant? Why or why not?\n\n\n\n\nQuestion 4Hint\n\n\nWe suspect that people who drink alcohol (alcohol is yes) might also be smokers (smoking is yes). Formulate a hypothesis, test it using the appropriate test, and make a decision about statistical significance.\n\n\nuse table()\n\n\n\n\nQuestion 5Hint\n\n\nIn the previous practical we made a Table 1 of baseline characteristics between cases and controls (Intellectual disability and Normal brain development). Test per variable whether the groups are significantly different.\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntellectual disability\nNormal brain development\np-value\n\n\n\n\n\n\n(n = 82)\n(n = 108)\n\n\n\nBMI, median [IQR]\n\n24 [22 - 27]\n24 [22 - 26]\n\n\n\n\nmissing (n = 0 )\n\n\n\n\n\nEducational level\nLow, n(%)\n31 (38%)\n14 (13%)\n\n\n\n\nIntermediate, n(%)\n34 (41%)\n48 (44%)\n\n\n\n\nHigh, n(%)\n17 (21%)\n46 (43%)\n\n\n\n\nmissing (n = 0)\n\n\n\n\n\nSmoking\nNo, n(%)\n55 (67%)\n96 (89%)\n\n\n\n\nYes, n(%)\n27 (33%)\n12 (11%)\n\n\n\n\nmissing (n = 0)\n\n\n\n\n\nSAM, mean (SD)\n\n72 (16)\n75 (18)\n\n\n\n\nmissing (n = 0)\n\n\n\n\n\nSAH, median [IQR]\n\n16 [15 - 18]\n18 [16 - 20]\n\n\n\n\nmissing (n = 0)\n\n\n\n\n\nVitamin B12, median [IQR]\n\n378 [310 - 477]\n363 [305 - 449]\n\n\n\n\nmissing (n = 1)\n\n\n\n\n\n\n\n\n\nFirst decide which test to use based on the distribution of the variable\n\n\n\n\nQuestion 6\n\n\nFor this question we will look at the correlation between vitaminB12 and homocysteine.\n\nPlot a histogram of each variable to decide whether the Pearson correlation is appropriate to use. Is it?\nMake a scatterplot of vitaminB12 and homocysteine. What correlation do you see in the the graph (postive, negative, none)?\nWhat is the correlation between vitaminB12 and homocysteine? Formulate a hypothesis, do a test, and make a decision as to whether either the Pearson or Spearman correlation is statistically significant.\n\n\n\n\n\nQuestion 7Hint aHint c\n\n\nLet’s see what happens when we categorize a continuous variable.\n\nCut vitaminB12 into 4 groups, where the breaks are the 5 quantile points of vitaminB12 Make sure you include the lowest breakpoint by specifying incl=TRUE. Assign the output to catB12. What are the levels of this new variable?\nUsing the log-transformed variable of homocysteine, asses how log_hc and catB12 relate. Make a boxplot of log_hc for the levels of catB12.\nAre the means of log_-homocysteine_hc equal across all levels of catB12? Formulate a hypothesis, test it, and make a decision for statistical significance.\n\n\n\nUse the function cut() for this. Running ?cut() will give you more information on the function.\n\n\nTest this with an ANOVA test.\n\n\n\n\nQuestion 8Hint\n\n\nRepeat questions 6b and 6c, without transforming homocysteine.\n\n\nWhich statistical test is appropriate in this case?\n\n\n\n\nQuestion 9Hint bHint e\n\n\nWe previously saw that there was an association between vitaminB12 and homocysteine. We will now quantify the magnitude of this relationship and see if we can explain the variabiliy of homocysteine with values of vitaminB12.\n\nWe will estimate a regression model with homocysteine as the dependent variable and vitaminB12 as the independent variable. Write down the equation for the regression model.\nEstimate the regression model and evaluate the residuals. Are the assumptions of the model met?\nThe residuals look a bit skewed. We saw earlier that our dependent variable follows a skewed distribution. The residuals might look better using the transformed version of the variable (log_hc). Re-estimate the model with this variable and evaluate the residuals again. Are you now satisfied?\nAssuming the assumptions hold (even if they don’t), we’ll make inference on the slope. Is vitaminB12 statistically significant in the model? What percent variability does it explain in log_hc?\nWhat is the predicted log_hc level for a person with vitaminB12 equal to 650? What is this value when unlogged (exponentiated)?\n\n\n\nLook at the normality of the residuals and the homoskedasticity\n\n\nUse the predict() function\n\n\n\n\nQuestion 10\n\n\nNow let’s consider a framework where we want to use more than one predictor. We want to build a regression model for SAM using vitaminB12, cholesterol, homocysteine and folicacid_erys (folic acid red blood cells).\n\nRun this multiple regression model in R. Check the assumptions. Do the assumptions hold?\nAssuming the assumptions hold (even if they don’t), we’ll make inference on the covariates. Are any of the variables statistically significant in the model? What percent variability do the variables explain in SAM?\nWhat is the predicted SAM level for a person with the following:\n\nvitaminB12 = 650\ncholesterol = 17\nhomocysteine = 16\nfolicacid erys = 1340\n\n\n\n\nQuestion 11\n\n\nWe would like to know if smoking and vitaminB12 can be used to predict Status.\n\nWhat type of model would you use for this?\nStatus and smoking should be factors for this analysis. Check if this is the case, otherwise use the following code to make factors of these variables:\n\n\nR_data$Status <- as.factor(R_data$Status)\nR_data$smoking <- as.factor(R_data$smoking)\n\nIf we run the model on the data as it is now, R will consider “normal brain development” as the event because it is second in the levels of Status:\n\nlevels(R_data$Status)\n\n[1] \"intellectual disability\"  \"normal brain development\"\n\n\nSo we need to first change these factor levels so we treat “intellectual disability” as the event and “normal brain development” as the baseline. Run the following to change the levels\n\nR_data$StatusNew <- factor(R_data$Status, \n                           levels = c(\"normal brain development\", \"intellectual disability\"))\nlevels(R_data$StatusNew)\n\n[1] \"normal brain development\" \"intellectual disability\" \n\n\n\nRun a logistic regression model in R with StatusNew as the outcome and smoking and vitaminB12 as the predictors. Can either variable significantly predict mental retardation?\nWhat is the probability of having a baby with an intellectual disability given the mother smokes and has a vitaminB12 level of 400? What is the probability of having a baby with an intellectual disability given the mother smokes and has a vitaminB12 level of 650?"
  },
  {
    "objectID": "Analysis_answers.html",
    "href": "Analysis_answers.html",
    "title": "6  Analysis - Answers",
    "section": "",
    "text": "Warning\n\n\n\nMake sure that you try the exercises yourself first before looking at the answers\n\n\n\n\nWarning: package 'readr' was built under R version 4.2.3\n\n\n\nQuestion 1Answer 1\n\n\nIn this question we will look at the variable SAH.\n\nWhat are the mean, median, variance and standard deviation of SAH?\nCreate a histogram and a horizontal boxplot of SAH.\nUtilize the graphs and the summary statistics to describe the shape of the distribution of SAH.\nLog-transform SAH (assign it to log_SAH).\nDescribe the distribution of log_SAH, based on the same techniques.\n\n\n\n\n\n\n\nround(mean(R_data$SAH), 2)\n\n[1] 17.59\n\nround(median(R_data$SAH), 2)\n\n[1] 17.3\n\nround(var(R_data$SAH), 2)\n\n[1] 11.27\n\nround(sd(R_data$SAH), 2)\n\n[1] 3.36\n\n\n\n\n\n\nhist(R_data$SAH)\n\n\n\nboxplot(R_data$SAH, horizontal=TRUE)\n\n\n\n\n\n\n\nSAH has a skewed distribution.\n\n\n\n\nR_data$log_SAH <- log(R_data$SAH)\n\n\n\n\n\nsummary(R_data$log_SAH)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  2.241   2.723   2.851   2.850   2.948   3.350 \n\nhist(R_data$log_SAH)\n\n\n\nboxplot(R_data$log_SAH, horizontal=TRUE)\n\n\n\n\nThe log transformed variable looks a lot more normally distributed.\n\n\n\n\nQuestion 2Hint 1Hint 2Answer 2\n\n\nAre the values of SAH different for the two levels of Status (normal brain development or intellectual disability)? Formulate a hypothesis, test it, and make a decision about whether or not you can reject the null hypothesis. Which test did you use?\n\n\nCheck the distributions with plots\n\n\nFor normally distributed data you can use a t-test, for non-normally distributed data you can use the Wilcoxon signed rank test (also knows as the Mann-Whitney U test).\n\n\nWe already saw that SAH is not normally distributed.\nWe will use the Wilcoxon singed rank test on the untransformed data.\nHypotheses:\n\\(H_0: \\textrm{median}_0 = \\textrm{median}_1\\)\n\\(H_a: \\textrm{median}_0 \\neq \\textrm{median}_1\\)\n\nwilcox.test(SAH ~ Status, data = R_data) \n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  SAH by Status\nW = 2868, p-value = 3.264e-05\nalternative hypothesis: true location shift is not equal to 0\n\n\nThe p-value <0.001. Based on a significance level of 5% there is enough evidence to reject the null hypothesis.\n\n\n\n\n\n\nNote\n\n\n\nRemember that you can save the test as an object and extract elements from it (such as the p-value)\n\ntest1 <- wilcox.test(SAH ~ Status, data = R_data) \ntest1$p.value\n\n[1] 3.264271e-05\n\n\n\n\n\n\n\n\nQuestion 3Answer 3\n\n\nMake a boxplot of the SAH values of the 2 groups and calculate the median difference of SAH between the 2 groups.\nDoes the difference seem clinically relevant? Why or why not?\n\n\n\nboxplot(SAH ~ Status, data = R_data)\n\n\n\naggregate(SAH ~ Status, data = R_data, median)\n\n                    Status   SAH\n1  intellectual disability 15.85\n2 normal brain development 18.00\n\n\nThe medians and boxplots also show a clinically relevant difference.\n\n\n\n\nQuestion 4HintAnswer 4\n\n\nWe suspect that people who drink alcohol (alcohol is yes) might also be smokers (smoking is yes). Formulate a hypothesis, test it using the appropriate test, and make a decision about statistical significance.\n\n\nuse table()\n\n\nHypotheses\n\\(H_0: P_{alcohol} = P_{no-alcohol}\\)\n\\(H_a: P_{alcohol} \\neq P_{no-alcohol}\\)\n\ntab1 <- with(R_data, table(alcohol, smoking))\ntab1\n\n       smoking\nalcohol no yes\n    no  75   9\n    yes 76  30\n\nprop.table(tab1, 1)\n\n       smoking\nalcohol        no       yes\n    no  0.8928571 0.1071429\n    yes 0.7169811 0.2830189\n\n\nBased on the tables, we see that in the group of patients that drinks alcohol, 28% smokes vs 10% in the non-alcohol group.\nTo test whether this difference is statistically signficant, we use the Chi-square test.\n\nchisq <- chisq.test(tab1)\nchisq\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  tab1\nX-squared = 7.8407, df = 1, p-value = 0.005108\n\n\nThe p-value is 0.005, this is significant on a 5% significance level.\n\n\n\n\nQuestion 5HintAnswer 5\n\n\nIn the previous practical we made a Table 1 of baseline characteristics between cases and controls (Intellectual disability and Normal brain development). Test per variable whether the groups are significantly different.\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntellectual disability\nNormal brain development\np-value\n\n\n\n\n\n\n(n = 82)\n(n = 108)\n\n\n\nBMI, median [IQR]\n\n24 [22 - 27]\n24 [22 - 26]\n\n\n\n\nmissing (n = 0 )\n\n\n\n\n\nEducational level\nLow, n(%)\n31 (38%)\n14 (13%)\n\n\n\n\nIntermediate, n(%)\n34 (41%)\n48 (44%)\n\n\n\n\nHigh, n(%)\n17 (21%)\n46 (43%)\n\n\n\n\nmissing (n = 0)\n\n\n\n\n\nSmoking\nNo, n(%)\n55 (67%)\n96 (89%)\n\n\n\n\nYes, n(%)\n27 (33%)\n12 (11%)\n\n\n\n\nmissing (n = 0)\n\n\n\n\n\nSAM, mean (SD)\n\n72 (16)\n75 (18)\n\n\n\n\nmissing (n = 0)\n\n\n\n\n\nSAH, median [IQR]\n\n16 [15 - 18]\n18 [16 - 20]\n\n\n\n\nmissing (n = 0)\n\n\n\n\n\nVitamin B12, median [IQR]\n\n378 [310 - 477]\n363 [305 - 449]\n\n\n\n\nmissing (n = 1)\n\n\n\n\n\n\n\n\n\nFirst decide which test to use based on the distribution of the variable\n\n\n\nwilcox.test(BMI ~ Status, data = R_data)$p.value \nchisq.test(R_data$educational_level, R_data$Status)$p.value\nchisq.test(R_data$smoking, R_data$Status)$p.value\nt.test(SAM ~ Status, data = R_data)$p.value \nwilcox.test(SAH ~ Status, data = R_data)$p.value \nwilcox.test(vitaminB12 ~ Status, data = R_data)$p.value \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntellectual disability\nNormal brain development\np-value\n\n\n\n\n\n\n(n = 82)\n(n = 108)\n\n\n\nBMI, median [IQR]\n\n24 [22 - 27]\n24 [22 - 26]\n0.175\n\n\n\nmissing (n = 0 )\n\n\n\n\n\nEducational level\nLow, n(%)\n31 (38%)\n14 (13%)\n<0.001\n\n\n\nIntermediate, n(%)\n34 (41%)\n48 (44%)\n\n\n\n\nHigh, n(%)\n17 (21%)\n46 (43%)\n\n\n\n\nmissing (n = 0)\n\n\n\n\n\nSmoking\nNo, n(%)\n55 (67%)\n96 (89%)\n<0.001\n\n\n\nYes, n(%)\n27 (33%)\n12 (11%)\n\n\n\n\nmissing (n = 0)\n\n\n\n\n\nSAM, mean (SD)\n\n72 (16)\n75 (18)\n0.267\n\n\n\nmissing (n = 0)\n\n\n\n\n\nSAH, median [IQR]\n\n16 [15 - 18]\n18 [16 - 20]\n<0.001\n\n\n\nmissing (n = 0)\n\n\n\n\n\nVitamin B12, median [IQR]\n\n378 [310 - 477]\n363 [305 - 449]\n0.348\n\n\n\nmissing (n = 1)\n\n\n\n\n\n\n\n\n\n\n\nQuestion 6Answer 6\n\n\nFor this question we will look at the correlation between vitaminB12 and homocysteine.\n\nPlot a histogram of each variable to decide whether the Pearson correlation is appropriate to use. Is it?\nMake a scatterplot of vitaminB12 and homocysteine. What correlation do you see in the the graph (postive, negative, none)?\nWhat is the correlation between vitaminB12 and homocysteine? Formulate a hypothesis, do a test, and make a decision as to whether either the Pearson or Spearman correlation is statistically significant.\n\n\n\n\n\n\n\nhist(R_data$homocysteine)\n\n\n\nhist(R_data$vitaminB12)\n\n\n\n\nBoth variables look skewed, so the Spearman correlation coefficient is more appropriate.\n\n\n\n\nplot(R_data$homocysteine, R_data$vitaminB12)\n\n\n\n\nWe see a slight negative correlation.\n\n\n\n\n\n\nNote\n\n\n\nThis code will give the same result :\n\nplot(vitaminB12 ~ homocysteine, data = R_data)\n\n\n\n\n\n\nHypotheses\n\\(H_0: \\textrm{cor}_{\\textrm{vit, hc}} = 0\\)\n\\(H_a: \\textrm{cor}_{\\textrm{vit, hc}} \\neq 0\\)\n\ncor.test(R_data$homocysteine, R_data$vitaminB12, method = \"spearman\")\n\nWarning in cor.test.default(R_data$homocysteine, R_data$vitaminB12, method =\n\"spearman\"): Cannot compute exact p-value with ties\n\n\n\n    Spearman's rank correlation rho\n\ndata:  R_data$homocysteine and R_data$vitaminB12\nS = 1511019, p-value = 5.962e-06\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n       rho \n-0.3218201 \n\n\nThe correlation coefficient is -0.322 and is highly significant (p-value < 0.001).\n\n\n\n\n\n\nImportant\n\n\n\nWe often find correlations interesting when they are > 0.5 (or < -0.5). Therefore, testing for significance is not very relevant here.\n\n\n\n\n\n\nQuestion 7Hint aHint cAnswer 7\n\n\nLet’s see what happens when we categorize a continuous variable.\n\nCut vitaminB12 into 4 groups, where the breaks are the 5 quantile points of vitaminB12 Make sure you include the lowest breakpoint by specifying incl=TRUE. Assign the output to catB12. What are the levels of this new variable?\nUsing the log-transformed variable of homocysteine, asses how log_hc and catB12 relate. Make a boxplot of log_hc for the levels of catB12.\nAre the means of log_-homocysteine_hc equal across all levels of catB12? Formulate a hypothesis, test it, and make a decision for statistical significance.\n\n\n\nUse the function cut() for this. Running ?cut() will give you more information on the function.\n\n\nTest this with an ANOVA test.\n\n\n\n\n\n\nR_data$catB12 <- cut(R_data$vitaminB12, breaks = quantile(R_data$vitaminB12), incl=TRUE)\nlevels(R_data$catB12)\n\n[1] \"[201,307]\" \"(307,370]\" \"(370,463]\" \"(463,766]\"\n\n\n\n\n\n\nR_data$log_hc <- log(R_data$homocysteine)\nboxplot(R_data$log_hc ~ R_data$catB12)\n\n\n\n\nThere appears to be a trend: the higher levels of catB12 correspond to lower levels of log-transformed homocysteine.\n\n\n\nHypotheses\n\\(H_0: \\mu_1 = \\mu_2 = \\mu_3 = \\mu_4\\)\n\\(H_a: \\textrm{not all means are equal}\\)\n\nANOVA1 <- aov(R_data$log_hc ~ R_data$catB12)\n\nsummary(ANOVA1)\n\n               Df Sum Sq Mean Sq F value   Pr(>F)    \nR_data$catB12   3  0.626 0.20880   6.286 0.000438 ***\nResiduals     186  6.179 0.03322                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThe p-value is < 0.05, so we conclude that there is a statistically significant difference between the mean log-homocysteine of at least one of the groups and the others.\n\n\n\n\nQuestion 8HintAnswer 8\n\n\nRepeat questions 6b and 6c, without transforming homocysteine.\n\n\nWhich statistical test is appropriate in this case?\n\n\n\nboxplot(R_data$homocysteine ~ R_data$catB12)\n\n\n\n\nHypotheses\n\\(H_0: \\textrm{No difference in the distributions}\\)\n\\(H_a: \\textrm{A difference in the distributions}\\)\n\nKW.1 <- kruskal.test(R_data$homocysteine ~ R_data$catB12)\n\nKW.1\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  R_data$homocysteine by R_data$catB12\nKruskal-Wallis chi-squared = 16.928, df = 3, p-value = 0.0007311\n\n\nThe Kruskal-Wallis test is also highly significant.\n\n\n\n\nQuestion 9Hint bHint eAnswer 9\n\n\nWe previously saw that there was an association between vitaminB12 and homocysteine. We will now quantify the magnitude of this relationship and see if we can explain the variabiliy of homocysteine with values of vitaminB12.\n\nWe will estimate a regression model with homocysteine as the dependent variable and vitaminB12 as the independent variable. Write down the equation for the regression model.\nEstimate the regression model and evaluate the residuals. Are the assumptions of the model met?\nThe residuals look a bit skewed. We saw earlier that our dependent variable follows a skewed distribution. The residuals might look better using the transformed version of the variable (log_hc). Re-estimate the model with this variable and evaluate the residuals again. Are you now satisfied?\nAssuming the assumptions hold (even if they don’t), we’ll make inference on the slope. Is vitaminB12 statistically significant in the model? What percent variability does it explain in log_hc?\nWhat is the predicted log_hc level for a person with vitaminB12 equal to 650? What is this value when unlogged (exponentiated)?\n\n\n\nLook at the normality of the residuals and the homoskedasticity\n\n\nUse the predict() function\n\n\n\n\n\n\\(\\textrm{homocysteine}_i = \\beta_0 + \\beta_1*\\textrm{vitaminB12}_i + \\varepsilon_i\\)\n\n\n\n\nLM1 <- lm(homocysteine ~ vitaminB12, data = R_data)\nplot(LM1)\n\n\n\n\n\n\n\n\n\n\n\n\nhist(LM1$residuals)\n\n\n\n\nIt seems the residuals do not follow a normal distribution, so this assumption does not hold\n\n\n\n\nLM2 <- lm(log_hc ~ vitaminB12, data = R_data)\nplot(LM2)\n\n\n\n\n\n\n\n\n\n\n\n\nhist(LM2$residuals)\n\n\n\n\nThe residuals now look more symmetrical. We are satisfied with these residuals.\n\n\n\n\nsummary(LM2)\n\n\nCall:\nlm(formula = log_hc ~ vitaminB12, data = R_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.5501 -0.1288 -0.0041  0.1176  0.5334 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  3.0369329  0.0457556  66.373  < 2e-16 ***\nvitaminB12  -0.0004881  0.0001113  -4.386 1.92e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1812 on 188 degrees of freedom\nMultiple R-squared:  0.09281,   Adjusted R-squared:  0.08799 \nF-statistic: 19.23 on 1 and 188 DF,  p-value: 1.923e-05\n\n\nThe value of the slope for vitaminB12 is statistically significant. So per point increase in vitaminB12, the mean log_hc decreases with 0.0004881.\nThe R-squared is 0.093, meaning that roughly 9% of the variations in log_hc are explained by vitaminB12.\n\n\n\n\nPatient1 <- predict(LM2, newdata = data.frame(vitaminB12 = 650))\nPatient1\n\n       1 \n2.719635 \n\nexp(Patient1)\n\n       1 \n15.17479 \n\n\nThe predicted homocysteine value for a patient with a vitaminB12 value of 650 is 15.2.\n\n\n\n\n\n\nNote\n\n\n\nYou can also calculate this manually:\n\\(\\beta_0 + \\beta_1*650 = 3.037 - 0.0005*650 =\\) 2.712\n\n\n\n\n\n\nQuestion 10Answer 10\n\n\nNow let’s consider a framework where we want to use more than one predictor. We want to build a regression model for SAM using vitaminB12, cholesterol, homocysteine and folicacid_erys (folic acid red blood cells).\n\nRun this multiple regression model in R. Check the assumptions. Do the assumptions hold?\nAssuming the assumptions hold (even if they don’t), we’ll make inference on the covariates. Are any of the variables statistically significant in the model? What percent variability do the variables explain in SAM?\nWhat is the predicted SAM level for a person with the following:\n\nvitaminB12 = 650\ncholesterol = 17\nhomocysteine = 16\nfolicacid erys = 1340\n\n\n\n\n\n\nLM3 <- lm(SAM ~ vitaminB12 + cholesterol + homocysteine + folicacid_erys, data = R_data)\n\nplot(LM3)\n\n\n\n\n\n\n\n\n\n\n\n\nhist(LM3$residuals)\n\n\n\n\nThe residuals look good, meaning that the asumptions hold.\n\n\n\n\nsummary(LM3)\n\n\nCall:\nlm(formula = SAM ~ vitaminB12 + cholesterol + homocysteine + \n    folicacid_erys, data = R_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-35.704 -12.367  -1.047  11.972  49.505 \n\nCoefficients:\n                Estimate Std. Error t value Pr(>|t|)    \n(Intercept)     1.800739  27.877405   0.065 0.948566    \nvitaminB12     -0.002684   0.011286  -0.238 0.812288    \ncholesterol     4.583482   1.369695   3.346 0.000992 ***\nhomocysteine   -0.645535   0.413510  -1.561 0.120206    \nfolicacid_erys  0.005033   0.006812   0.739 0.460939    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 16.94 on 185 degrees of freedom\nMultiple R-squared:  0.09232,   Adjusted R-squared:  0.0727 \nF-statistic: 4.704 on 4 and 185 DF,  p-value: 0.001225\n\n\nCholesterol is the only significant variable (p-value < 0.05). The R squared is 0.092. So this model explains 9% of variability in SAM.\n\n\n\n\n\n\nNote\n\n\n\nThe adjusted R-squared is 0.0727. This measure gives a penalty for including more covariates in the model and can be used when comparing different models.\n\n\n\n\n\n\nPatient2 <- predict(LM3, newdata = data.frame(vitaminB12 = 650,\n                                              cholesterol = 17,\n                                              homocysteine = 16,\n                                              folicacid_erys = 1340))\nPatient2\n\n       1 \n74.39131 \n\n\n\n\n\n\nQuestion 11Answer 11\n\n\nWe would like to know if smoking and vitaminB12 can be used to predict Status.\n\nWhat type of model would you use for this?\nStatus and smoking should be factors for this analysis. Check if this is the case, otherwise use the following code to make factors of these variables:\n\n\nR_data$Status <- as.factor(R_data$Status)\nR_data$smoking <- as.factor(R_data$smoking)\n\nIf we run the model on the data as it is now, R will consider “normal brain development” as the event because it is second in the levels of Status:\n\nlevels(R_data$Status)\n\nSo we need to first change these factor levels so we treat “intellectual disability” as the event and “normal brain development” as the baseline. Run the following to change the levels\n\nR_data$StatusNew <- factor(R_data$Status, \n                           levels = c(\"normal brain development\", \"intellectual disability\"))\nlevels(R_data$StatusNew)\n\n\nRun a logistic regression model in R with StatusNew as the outcome and smoking and vitaminB12 as the predictors. Can either variable significantly predict mental retardation?\nWhat is the probability of having a baby with an intellectual disability given the mother smokes and has a vitaminB12 level of 400? What is the probability of having a baby with an intellectual disability given the mother smokes and has a vitaminB12 level of 650?\n\n\n\n\n\n\nA logistic regression model\n\n\n\n\n\n\n\n\n\n\nstr(R_data)\n\n'data.frame':   190 obs. of  24 variables:\n $ patientnumber         : num  1 2 3 4 5 6 7 8 9 10 ...\n $ Status                : Factor w/ 2 levels \"intellectual disability\",..: 1 2 1 2 1 1 1 1 1 1 ...\n $ iodine_deficiency     : chr  \"no\" \"no\" \"no\" \"yes\" ...\n $ BMI                   : num  32 23 29 22 22 24 24 28 33 32 ...\n $ educational_level     : chr  \"intermediate\" \"intermediate\" \"low\" \"low\" ...\n $ alcohol               : chr  \"no\" \"yes\" \"no\" \"no\" ...\n $ smoking               : Factor w/ 2 levels \"no\",\"yes\": 1 2 1 1 1 1 1 1 2 1 ...\n $ medication            : chr  \"no\" \"no\" \"no\" \"no\" ...\n $ birthweight           : num  2618 3541 2619 3810 4136 ...\n $ pregnancy_length_weeks: num  38 40 38 40 42 41 40 37 42 39 ...\n $ pregnancy_length_days : num  4 2 3 5 3 1 4 1 0 2 ...\n $ SAM                   : num  54.5 84 61 43 83 69 79 71.5 56 42.5 ...\n $ SAH                   : num  14.8 23.6 18.7 23.2 17.1 19.6 22.4 18 20 23.4 ...\n $ homocysteine          : num  18.8 15.6 15.2 16.5 19.5 17.5 14.9 22.2 19.1 16 ...\n $ cholesterol           : num  16.5 17.5 16.4 16.4 16.9 15.9 16.9 16 18.6 16.7 ...\n $ HDL                   : num  26.1 26.7 26.2 25.9 26.7 ...\n $ triglycerides         : num  8.84 7.78 7.54 8.95 7.57 7.35 7.63 7.38 8.25 8.27 ...\n $ vitaminB12            : num  303 370 533 346 389 611 604 518 288 520 ...\n $ folicacid_serum       : num  26.4 37.8 33.7 35.1 29 28.3 33.8 31.1 27.7 33.4 ...\n $ folicacid_erys        : num  1132 1467 1528 1539 1178 ...\n $ log_SAH               : num  2.69 3.16 2.93 3.14 2.84 ...\n $ catB12                : Factor w/ 4 levels \"[201,307]\",\"(307,370]\",..: 1 2 4 2 3 4 4 4 1 4 ...\n $ log_hc                : num  2.93 2.75 2.72 2.8 2.97 ...\n $ StatusNew             : Factor w/ 2 levels \"normal brain development\",..: 2 1 2 1 2 2 2 2 2 2 ...\n\n\n\n\n\n\nGLM1 <- glm(StatusNew ~ smoking + vitaminB12, \n            family = binomial(logit), data = R_data)\nsummary(GLM1)\n\n\nCall:\nglm(formula = StatusNew ~ smoking + vitaminB12, family = binomial(logit), \n    data = R_data)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-1.6107  -0.9567  -0.8531   1.2649   1.5909  \n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -1.397552   0.555095  -2.518 0.011813 *  \nsmokingyes   1.435938   0.391342   3.669 0.000243 ***\nvitaminB12   0.002088   0.001301   1.604 0.108610    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 259.83  on 189  degrees of freedom\nResidual deviance: 243.59  on 187  degrees of freedom\nAIC: 249.59\n\nNumber of Fisher Scoring iterations: 4\n\n\nSmoking is a significant predictor, but vitaminB12 is not.\nTo obtain ORs and their corresponding 95% CI, we might use:\n\nexp(coef(GLM1))\n\n(Intercept)  smokingyes  vitaminB12 \n  0.2472015   4.2035866   1.0020900 \n\nexp(confint(GLM1))\n\nWaiting for profiling to be done...\n\n\n                 2.5 %    97.5 %\n(Intercept) 0.08107013 0.7206897\nsmokingyes  1.99336189 9.3392849\nvitaminB12  0.99955623 1.0046944\n\n\n\n\n\n\nmynew <- data.frame(smoking = factor(c(\"yes\", \"yes\")), vitaminB12 = c(400, 650))\npredict(GLM1, newdata = mynew, type = \"response\")\n\n        1         2 \n0.7054726 0.8014592 \n\n\nThe probabilities are 71% and 80% for these two patients."
  },
  {
    "objectID": "basic_plotting_intro.html",
    "href": "basic_plotting_intro.html",
    "title": "Basic plotting",
    "section": "",
    "text": "R is a very powerful tool for producing custom graphics ranging from basic scatterplots to 3D plots. In this introduction to plotting we will learn how to create basic graphs like scatterplots, line graphs and bar charts, as well as histograms and boxplots, all of which are available in the base package. Different methods for saving plots will be introduced. We will use the data ToothGrowth throughout the following examples:\n\ndata(ToothGrowth)\nstr(ToothGrowth)\n\n'data.frame':   60 obs. of  3 variables:\n $ len : num  4.2 11.5 7.3 5.8 6.4 10 11.2 11.2 5.2 7 ...\n $ supp: Factor w/ 2 levels \"OJ\",\"VC\": 2 2 2 2 2 2 2 2 2 2 ...\n $ dose: num  0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 ..."
  },
  {
    "objectID": "basic_plotting.html#scatterplots-and-line-graphs",
    "href": "basic_plotting.html#scatterplots-and-line-graphs",
    "title": "7  Basic plotting",
    "section": "7.1 Scatterplots and Line Graphs",
    "text": "7.1 Scatterplots and Line Graphs\n\nScatterplots\nThe plot function is the most basic function for plotting continuous data. If we use plot on one variable, the values of the variable will be plotted against their index, i.e., the order of the data within the object they’re stored:\n\nplot(ToothGrowth$len)\n\n\n\n\nWith two variables plot puts the first variable on the x-axis and the second variable on the y-axis (y versus x):\n\nplot(ToothGrowth$dose, ToothGrowth$len)\n\n\n\n\nMany parameters are available for customizing your plot. See ?par for an extensive list. We will just look at a couple here, like changing the axis labels:\n\nplot(ToothGrowth$dose, ToothGrowth$len, xlab = \"Dose\", ylab = \"Tooth Length\")\n\n\n\n\nWe can also add a title:\n\nplot(ToothGrowth$dose, ToothGrowth$len, xlab = \"Dose\", ylab = \"Tooth Length\", main = \"Guinea Pig Tooth Growth by Dosage\")\n\n\n\n\nand even change the colors and characters of specific points:\n\nplot(ToothGrowth$dose, \n     ToothGrowth$len, \n     xlab = \"Dose\", \n     ylab = \"Tooth Length\", \n     main = \"Guinea Pig Tooth Growth by Dosage\", \n     col = ToothGrowth$supp, \n     pch = as.numeric(ToothGrowth$supp))\n\n\n\n\nThe legend function adds a legend so we can easily identify which points represent which groups:\n\nplot(ToothGrowth$dose, ToothGrowth$len, xlab = \"Dose\", ylab = \"Tooth Length\", main = \"Guinea Pig Tooth Growth by Dosage\", col = ToothGrowth$supp, pch = as.numeric(ToothGrowth$supp))\n\nlegend(1.5, 15, c(\"OJ\", \"VC\"), col = 1:2, pch = 1:2)\n\n\n\n\nThe location of the legend can also be specified by stating a region of the plot e.g. “bottomright” to place it in the very bottom righthand corner of the plot.\nThe argument cex stands for “character expansion” and will enlarge the size of points:\n\nplot(ToothGrowth$dose, ToothGrowth$len, xlab = \"Dose\",\n     ylab = \"Tooth Length\", main = \"Guinea Pig Tooth Growth by Dosage\",\n     col = ToothGrowth$supp, pch = as.numeric(ToothGrowth$supp),\n     cex = 2)\n\nlegend(1.5, 15, c(\"OJ\", \"VC\"), col = 1:2, pch = as.numeric(ToothGrowth$supp), cex=2)\n\n\n\n\n\n\nLine Graphs\nTo create a plot using lines instead of points, we can actually still use plot, but we need to specify the type of plot we want, e.g.:\n\nplot(ToothGrowth$len, type = \"l\") # note type is the letter l for \"line\"\n\n\n\n\n\nplot(ToothGrowth$len, type = \"b\") # note type is the letter b for \"both\"\n\n\n\n\nWe can add additional lines by calling lines:\n\nplot(ToothGrowth$len, type = \"l\")\nlines(ToothGrowth$len + 2)\n\n\n\n\nThe line type, width, and color can be adjusted as follows:\n\nplot(ToothGrowth$len, type = \"l\")\nlines(ToothGrowth$len + 2, lty = 3, lwd = 3, col = \"darkgreen\")"
  },
  {
    "objectID": "basic_plotting.html#bar-charts-and-histograms",
    "href": "basic_plotting.html#bar-charts-and-histograms",
    "title": "7  Basic plotting",
    "section": "7.2 Bar Charts and Histograms",
    "text": "7.2 Bar Charts and Histograms\n\nBar Charts\nViewing categorical data in a scatterplot often doesn’t make sense. For example, if we want to see the number of guinea pigs who received each dosage, the following doesn’t provide this information in the most intuitive format:\n\nplot(ToothGrowth$dose)\n\n\n\n\n\ntable(ToothGrowth$dose)\n\n\n0.5   1   2 \n 20  20  20 \n\n\n\nbarplot(table(ToothGrowth$dose))\n\n\n\n\nWe can plot proportions instead of frequencies, as is often helpful (though not in this case):\n\nprops <- table(ToothGrowth$dose)/nrow(ToothGrowth)\nprops\n\n\n      0.5         1         2 \n0.3333333 0.3333333 0.3333333 \n\n\n\nbarplot(props)\n\n\n\n\nNote that the y-axis doesn’t quite extend to the height of the bars. The range of the y-axis is easily change in plots by adjusting the parameter ylim (similarly xlim for the x-axis):\n\nbarplot(props, ylim = c(0, .4))\n\n\n\n\nYet again, there are many parameters available for customizing the plot. Let’s try changing the width and colors of the bars:\n\nbarplot(props, ylim = c(0, .4), width = .2, col = c(\"blue\", \"white\", \"red\"))\n\n\n\n\nAnd we can plot the bars horizontally, if preferable:\n\nbarplot(props, xlim = c(0, .4),\n  width = .2, col = c(\"blue\", \"white\", \"red\"),\n  horiz = TRUE)\n\n\n\n\nNote that we adjusted the range of the x-axis now instead of the y-axis.\n\n\nHistograms\nA bar chart is slightly different from a histogram. We use bar charts to plot frequencies (or proportions) of values present in categories. Continuous data don’t have categories, so to make a similar plot we have to create “categories”. They are often called bins or cells and are created by delining ranges in which the frequencies are calculated. Thankfully, R will do this, and plot the histogram, when we call the function hist:\n\nhist(ToothGrowth$len)\n\n\n\n\nNote that in a histogram the sides of the cells touch, whereas they do not in a bar chart. We can also plot the proportions, now called “density”, by changing a single parameter:\n\nhist(ToothGrowth$len, freq = FALSE)\n\n\n\n\nIn the next graph we plot the histogram with a different bin width by specifying where to make the breakpoints between the bars:\n\nhist(ToothGrowth$len, freq = FALSE, breaks = seq(0, 35, 2))\n\n\n\n\nNote how the granularity of the plot changes with the width of the bin. We can also change the breaks by delining the number of cells to use:\n\nhist(ToothGrowth$len, freq = FALSE, breaks = 25)\n\n\n\n\nThe same parameters that change the axes and labels are applicable here:\n\nhist(ToothGrowth$len, freq = FALSE, breaks = seq(0, 35, 2),\n  main = \"Histogram of Tooth Growth\", xlab = \"Tooth Length\",\n  ylim = c(0, .07), col = \"orange\")"
  },
  {
    "objectID": "basic_plotting.html#boxplots",
    "href": "basic_plotting.html#boxplots",
    "title": "7  Basic plotting",
    "section": "7.3 Boxplots",
    "text": "7.3 Boxplots\nA boxplot is another graph we use to view the distribution of a continuous variable. It displays the specified quantiles of the data in the following way:\n\nboxplot(ToothGrowth$len)\n\n\n\n\nA single boxplot is nice for visualizing the distribution of one variable, but plotting several side by side allows for a simultaneous comparison of distributions. Here we will use the formula notation. The format y ~ x, where y is a numeric vector and x is a factor, tells the boxplot function that we want to separate the continuous y values into as many boxplots as there are levels of the factor x.\n\nboxplot(ToothGrowth$len~ToothGrowth$supp)\n\n\n\n\nJust like in the bar chart, we can plot the boxes horizontally and change the colors, labels and axes:\n\nboxplot(ToothGrowth$len~ToothGrowth$supp,\n  col = c(\"darkgreen\", \"purple\"),\n  ylab = \"Supplement Type\", xlab = \"Tooth Length\",\n  ylim = c(0, 40), horizontal = TRUE)\n\n\n\n\nThe settings of the parameters of a plot, including the margins, can be specified by calling par() before creating a plot. One nice setting we’ll introduce here is how to put multiple plots into one graphics device:\n\npar(mfrow = c(1, 2))\n  boxplot(ToothGrowth$len~ToothGrowth$supp, main = \"Boxplot\",\n  xlab = \"Supplement Type\")\n  \nhist(ToothGrowth$len, main = \"Histogram\", xlab = \"Tooth Length\")\n\n\n\n\nThe settings will stay fixed until we close the device (e.g. by calling dev.off()) or reset par (e.g. par(mfrow = c(1, 1))). It is highly recommended to get familiar with the help page for par to control graphing parameters to create custom graphs. Another helpful function is axis, which allows the specification of custom axis labels (e.g. where to put them and at what angle). See ?axis for more information."
  },
  {
    "objectID": "basic_plotting.html#saving-plots",
    "href": "basic_plotting.html#saving-plots",
    "title": "7  Basic plotting",
    "section": "7.4 Saving Plots",
    "text": "7.4 Saving Plots\nUp until now we have been creating graphs in a single graphics window that gets overwritten every time we create new plots. If we want to save the images created, we can use “Export” in RStudio to specify what type of file we want to write, its size, location, and name.\nAlternatively we can use functions such as png, pdf, and jpeg. Since we can save our code and not our mouse clicks, the use of these functions avoids any confusion about how an image was written, allows for quick simple changes, and provides a convenient way to reproduce multiple, similar plots. For example:\n\n# note: run getwd() to see the working directory -\n# that is the directory to which files will be written\npdf(\"plot1.pdf\", width = 6, height = 9)\nboxplot(ToothGrowth$len~ToothGrowth$supp,\n  col = c(\"darkgreen\", \"purple\"),\n  xlab = \"Supplement Type\", ylab = \"Tooth Length\",\n  ylim = c(0, 40), horizontal = TRUE)\ndev.off()\n\npdf(\"plot2.pdf\", width = 4, height = 8)\nboxplot(ToothGrowth$len~ToothGrowth$supp,\n  col = c(\"darkgreen\", \"purple\"),\n  xlab = \"Supplement Type\", ylab = \"Tooth Length\",\n  ylim = c(0, 40), horizontal = TRUE)\ndev.off()\n\nNote that you have to call dev.off() to finish writing the image to the file. If more than one device is open, the return of that function will display a number larger than 1.\nThe units for the width and height arguments of pdf are in inches (7 by 7), but the default for e.g. png is pixels (there is an argument units to change it to in, cm, or mm):\n\npng(\"plot1.png\", units = \"in\", res = 300,\n  width = 6, height = 9)\n\nboxplot(ToothGrowth$len~ToothGrowth$supp,\n  col = c(\"darkgreen\", \"purple\"),\n  xlab = \"Supplement Type\", ylab = \"Tooth Length\",\n  ylim = c(0, 40), horizontal = TRUE)\n\ndev.off()"
  },
  {
    "objectID": "basic_plotting_practicals_questions.html",
    "href": "basic_plotting_practicals_questions.html",
    "title": "8  Basic Plotting: Questions",
    "section": "",
    "text": "Use R to do the following exercises on the BOD data\n\nQuestion 1\n\n\nDisplay the built-in dataset called BOD by running BOD.\n\n\n\n\nQuestion 2\n\n\nWhat is the data structure of BOD? What are the dimensions?\n\n\n\n\nQuestion 3\n\n\nWhat are the names of BOD? Use a function other than str.\n\n\n\n\nQuestion 3\n\n\nMake a line graph of demand versus time, where the line is a deep pink dot-dashed line [Hint: run ?par and look for the parameter lty to see the line types]. Add a blue dashed line of 1.1 times the demand and give it a thickness of 2 using the line width parameter lwd. Make sure both lines are entirely visible by adjusting the range of y using the parameter ylim in the original plot.\n\n\n\nUse R to do the following exercises on the chickwts data.\n\nQuestion 4\n\n\nDisplay the built-in chickwts data.\n\n\n\n\nQuestion 5\n\n\nWhat are the names of chickwts? Use a function other than str\n\n\n\n\nQuestion 6\n\n\nWhat are the levels of feed?\n\n\n\n\nQuestion 7\n\n\nMake the following plots in one 2 x 2 image: - A bar chart of the feed types, each bar a different color. - A bar chart of the proportions of feed types, each bar a different color. - A boxplot of the weights by feed type, each box a different color. - A horizontal boxplot of the weights by feed type, each box a different color.\n\n\n\nUse R to do the following exercises on the Puromycin data.\n\nQuestion 8\n\n\nDisplay the built-in Puromycin data.\n\n\n\n\nQuestion 9\n\n\nMake a scatterplot of the rate versus the concentration. Describe the relationship.\n\n\n\n\nQuestion 10\n\n\nMake a scatterplot of the rate versus the log of the concentration. Describe the relationship.\n\n\n\n\nQuestion 11\n\n\nMake a scatterplot of the rate versus the log of the concentration and color the points by treatment group (state). Describe what you see.\n\n\n\n\nQuestion 12\n\n\nMake a scatterplot of the rate versus the log of the concentration, color the points by treatment group (state), label the x-axis “Concentration” and the y-axis “Rate”, and label the plot “Puromycin”.\n\n\n\n\nQuestion 13\n\n\nAdd a legend to the above plot indicating what the points represent.\n\n\n\n\nQuestion 14\n\n\nMake a boxplot of the treated versus untreated rates. Using the function pdf, save the image to a file with a width and height of 7 inches.\n\n\n\n\nQuestion 15\n\n\nMake a histogram of the frequency of concentrations. What is the width of the bins?\n\n\n\n\nQuestion 16\n\n\nMake a histogram of the frequency of concentrations with a bin width of 0.10. How is this different from the histogram above?\n\n\n\n\nQuestion 17\n\n\nPlot the histograms side by side in the same graphic window and make sure they have the same range on the y-axis. Does this make it easier to answer the question of how the two histograms differ?"
  },
  {
    "objectID": "basic_plotting_practicals_answers.html",
    "href": "basic_plotting_practicals_answers.html",
    "title": "9  Basic Plotting: Answers",
    "section": "",
    "text": "Warning\n\n\n\nMake sure that you try the exercises yourself first before looking at the answers\n\n\nUse R to do the following exercises on the BOD data\n\nQuestion 1Answer\n\n\nDisplay the built-in dataset called BOD by running BOD.\n\n\n\nBOD\n\n  Time demand\n1    1    8.3\n2    2   10.3\n3    3   19.0\n4    4   16.0\n5    5   15.6\n6    7   19.8\n\n\n\n\n\n\nQuestion 2Answer\n\n\nWhat is the data structure of BOD? What are the dimensions?\n\n\n\nstr(BOD)\n\n'data.frame':   6 obs. of  2 variables:\n $ Time  : num  1 2 3 4 5 7\n $ demand: num  8.3 10.3 19 16 15.6 19.8\n - attr(*, \"reference\")= chr \"A1.4, p. 270\"\n\ndim(BOD)\n\n[1] 6 2\n\n\n\n\n\n\nQuestion 3Answer\n\n\nWhat are the names of BOD? Use a function other than str.\n\n\n\nnames(BOD)\n\n[1] \"Time\"   \"demand\"\n\n\n\n\n\n\nQuestion 3Answer\n\n\nMake a line graph of demand versus time, where the line is a deep pink dot-dashed line [Hint: run ?par and look for the parameter lty to see the line types]. Add a blue dashed line of 1.1 times the demand and give it a thickness of 2 using the line width parameter lwd. Make sure both lines are entirely visible by adjusting the range of y using the parameter ylim in the original plot.\n\n\n\nplot(BOD$Time, BOD$demand, type = \"l\", lty = 4,\n  col = \"pink\", ylim = c(0, 25))\nlines(BOD$Time, 1.1 * BOD$demand, lwd = 2, col = \"blue\")\n\n\n\n\n\n\n\nUse R to do the following exercises on the chickwts data.\n\nQuestion 4Answer\n\n\nDisplay the built-in chickwts data.\n\n\n\nchickwts\n\n   weight      feed\n1     179 horsebean\n2     160 horsebean\n3     136 horsebean\n4     227 horsebean\n5     217 horsebean\n6     168 horsebean\n7     108 horsebean\n8     124 horsebean\n9     143 horsebean\n10    140 horsebean\n11    309   linseed\n12    229   linseed\n13    181   linseed\n14    141   linseed\n15    260   linseed\n16    203   linseed\n17    148   linseed\n18    169   linseed\n19    213   linseed\n20    257   linseed\n21    244   linseed\n22    271   linseed\n23    243   soybean\n24    230   soybean\n25    248   soybean\n26    327   soybean\n27    329   soybean\n28    250   soybean\n29    193   soybean\n30    271   soybean\n31    316   soybean\n32    267   soybean\n33    199   soybean\n34    171   soybean\n35    158   soybean\n36    248   soybean\n37    423 sunflower\n38    340 sunflower\n39    392 sunflower\n40    339 sunflower\n41    341 sunflower\n42    226 sunflower\n43    320 sunflower\n44    295 sunflower\n45    334 sunflower\n46    322 sunflower\n47    297 sunflower\n48    318 sunflower\n49    325  meatmeal\n50    257  meatmeal\n51    303  meatmeal\n52    315  meatmeal\n53    380  meatmeal\n54    153  meatmeal\n55    263  meatmeal\n56    242  meatmeal\n57    206  meatmeal\n58    344  meatmeal\n59    258  meatmeal\n60    368    casein\n61    390    casein\n62    379    casein\n63    260    casein\n64    404    casein\n65    318    casein\n66    352    casein\n67    359    casein\n68    216    casein\n69    222    casein\n70    283    casein\n71    332    casein\n\n\n\n\n\n\nQuestion 5Answer\n\n\nWhat are the names of chickwts? Use a function other than str\n\n\n\nnames(chickwts)\n\n[1] \"weight\" \"feed\"  \n\n\n\n\n\n\nQuestion 6Answer\n\n\nWhat are the levels of feed?\n\n\n\nlevels(chickwts$feed)\n\n[1] \"casein\"    \"horsebean\" \"linseed\"   \"meatmeal\"  \"soybean\"   \"sunflower\"\n\n\n\n\n\n\nQuestion 7Answer\n\n\nMake the following plots in one 2 x 2 image: - A bar chart of the feed types, each bar a different color. - A bar chart of the proportions of feed types, each bar a different color. - A boxplot of the weights by feed type, each box a different color. - A horizontal boxplot of the weights by feed type, each box a different color.\n\n\n\npar(mfrow = c(2, 2))\n\nbarplot(table(chickwts$feed),\n  col = c(\"red\", \"orange\", \"yellow\",\n  \"green\", \"blue\", \"purple\"))\n\nbarplot(table(chickwts$feed)/length(chickwts$feed),\n  col = c(\"red\", \"orange\", \"yellow\",\n  \"green\", \"blue\", \"purple\"))\n\nboxplot(chickwts$weight~chickwts$feed,\n  col = c(\"red\", \"orange\", \"yellow\",\n  \"green\", \"blue\", \"purple\"))\n\nboxplot(chickwts$weight~chickwts$feed,\n  col = c(\"red\", \"orange\", \"yellow\",\n  \"green\", \"blue\", \"purple\"),\n  horizontal = TRUE)\n\n\n\n\n\n\n\nUse R to do the following exercises on the Puromycin data.\n\nQuestion 8Answer\n\n\nDisplay the built-in Puromycin data.\n\n\n\nPuromycin\n\n   conc rate     state\n1  0.02   76   treated\n2  0.02   47   treated\n3  0.06   97   treated\n4  0.06  107   treated\n5  0.11  123   treated\n6  0.11  139   treated\n7  0.22  159   treated\n8  0.22  152   treated\n9  0.56  191   treated\n10 0.56  201   treated\n11 1.10  207   treated\n12 1.10  200   treated\n13 0.02   67 untreated\n14 0.02   51 untreated\n15 0.06   84 untreated\n16 0.06   86 untreated\n17 0.11   98 untreated\n18 0.11  115 untreated\n19 0.22  131 untreated\n20 0.22  124 untreated\n21 0.56  144 untreated\n22 0.56  158 untreated\n23 1.10  160 untreated\n\n\n\n\n\n\nQuestion 9Answer\n\n\nMake a scatterplot of the rate versus the concentration. Describe the relationship.\n\n\n\nplot(Puromycin$conc, Puromycin$rate)\n\n\n\n\nThe rate increases faster at lower concentrations than at higher concentrations.\n\n\n\n\nQuestion 10Answer\n\n\nMake a scatterplot of the rate versus the log of the concentration. Describe the relationship.\n\n\n\nplot(log(Puromycin$conc), Puromycin$rate)\n\n\n\n\nThe two variables have a linear relationship\n\n\n\n\nQuestion 11Answer\n\n\nMake a scatterplot of the rate versus the log of the concentration and color the points by treatment group (state). Describe what you see.\n\n\n\nplot(log(Puromycin$conc), Puromycin$rate, col = Puromycin$state)\n\n\n\n\nIt appears that the the treated group has higher rates than the untreated group, on average. (Note that default colors are black for the first level and red for the second level).\n\n\n\n\nQuestion 12Answer\n\n\nMake a scatterplot of the rate versus the log of the concentration, color the points by treatment group (state), label the x-axis “Concentration” and the y-axis “Rate”, and label the plot “Puromycin”.\n\n\n\nplot(log(Puromycin$conc), Puromycin$rate, col = Puromycin$state,\n  xlab = \"Concentration\", ylab = \"Rate\", main = \"Puromycin\")\n\n\n\n\n\n\n\n\nQuestion 13Answer\n\n\nAdd a legend to the above plot indicating what the points represent.\n\n\n\nplot(log(Puromycin$conc), Puromycin$rate, col = Puromycin$state,\n  xlab = \"Concentration\", ylab = \"Rate\", main = \"Puromycin\")\n\nlegend(\"topleft\",c(\"Treated\", \"Untreated\"), col = 1:2, pch = 1)\n\n\n\n\n\n\n\n\nQuestion 14Answer\n\n\nMake a boxplot of the treated versus untreated rates. Using the function pdf, save the image to a file with a width and height of 7 inches.\n\n\n\npdf(\"puromycin.pdf\",width = 7, height = 7)\nboxplot(Puromycin$rate~Puromycin$state)\ndev.off()\n\n\n\n\n\nQuestion 15Answer\n\n\nMake a histogram of the frequency of concentrations. What is the width of the bins?\n\n\n\nhist(Puromycin$conc)\n\n\n\n\nThe bin width is 0.20.\n\n\n\n\nQuestion 16Answer\n\n\nMake a histogram of the frequency of concentrations with a bin width of 0.10. How is this different from the histogram above?\n\n\n\nhist(Puromycin$conc, breaks = seq(0, 1.2, .10))\n\n\n\n\nThe bins are narrower, so we see in finer detail the distribution of the concentrations.\n\n\n\n\nQuestion 17Answer\n\n\nPlot the histograms side by side in the same graphic window and make sure they have the same range on the y-axis. Does this make it easier to answer the question of how the two histograms differ?\n\n\n\npar(mfrow = c(1, 2))\nhist(Puromycin$conc, ylim = c(0, 12))\nhist(Puromycin$conc, breaks = seq(0, 1.2, .10), ylim = c(0, 12))\n\n\n\n\nIn some situations it may be of use to view plots simultaneously. In this case, on the right we see clearly that more values are between 0 and 0.10 than 0.10 and 0.20 whereas the plot on the left does not display this information. In the histogram on the right we see that no concentrations fall between 0.30 and 0.50, whereas this is not apparent in the histogram on the left."
  },
  {
    "objectID": "ggplot2_intro.html#grammar-of-graphics",
    "href": "ggplot2_intro.html#grammar-of-graphics",
    "title": "ggplot2",
    "section": "Grammar of graphics",
    "text": "Grammar of graphics\nThe grammar of graphics consists of a number of “layers”, which generate a ggplot when correctly put together. These five basic layers will be discussed here:\n\nData\nAesthetics\nGeometries\nFacets\nScales\nThemes"
  },
  {
    "objectID": "ggplot2.html#data",
    "href": "ggplot2.html#data",
    "title": "10  Data visualization using ggplot2",
    "section": "10.1 Data",
    "text": "10.1 Data\nThe basis of each plot is the data. To plot data with ggplot the data needs to be of the class “data.frame”. The structure of your data.frame is important when you want to plot it with ggplot. Each variable you want to use has to be in a separate column in your data.frame. Take for example the “Indometh” data set which comes with R.\n\n?Indometh\n\nThe “Indometh”” data set describes the pharmacokinetics of indomethacin after intravenous injection of indomethacin in six subjects. The data.frame has three columns one containing the subject number, one containing the time of sampling in hours, and one containing the indomethacin concentration ug/ml. This data set is easily plotted with ggplot because it is a data.frame and there is a good separation of variables in the columns.\n\n\n  Subject time conc\n1       1 0.25 1.50\n2       1 0.50 0.94\n3       1 0.75 0.78\n4       1 1.00 0.48\n5       1 1.25 0.37\n6       1 2.00 0.19\n\n\nAn example of a badly formatted data set for visualization with ggplot is a data set of monthly deaths from lung diseases in the UK:\n\n?ldeaths\n\nThis data set contains three separate data sets for female, male and both male and female deaths (ldeaths, fdeaths, and mdeaths). The columns contain values per month and the rows indicate the year. (also they are not data.frames)\n\n\n      Jan  Feb  Mar  Apr  May  Jun  Jul  Aug  Sep  Oct  Nov  Dec\n1974 3035 2552 2704 2554 2014 1655 1721 1524 1596 2074 2199 2512\n1975 2933 2889 2938 2497 1870 1726 1607 1545 1396 1787 2076 2837\n1976 2787 3891 3179 2011 1636 1580 1489 1300 1356 1653 2013 2823\n1977 3102 2294 2385 2444 1748 1554 1498 1361 1346 1564 1640 2293\n1978 2815 3137 2679 1969 1870 1633 1529 1366 1357 1570 1535 2491\n1979 3084 2605 2573 2143 1693 1504 1461 1354 1333 1492 1781 1915\n\n\nSince there are two separate data sets, there is no column indicating the sex. There is also no column indicating the year and no column indicating the month. This means that we cannot use these variables in ggplot to visualize, for instance, the difference between the number of deaths in men and women in a certain year. We can use some more advanced R data reshaping to get these data sets in the right shape.\n\n\n  Deaths Year Month    Sex\n1    901 1974   Jan female\n2    689 1974   Feb female\n3    827 1974   Mar female\n4    677 1974   Apr female\n5    522 1974   May female\n6    406 1974   Jun female\n\n\n\nggplot(data, aes(x=Month, y=Deaths, color=Sex)) + geom_point()\n\n\n\n\n\n\n\n\nHowever, it is much more easy to keep in mind that any variable that you want to use as a part of your ggplot should get its own column when you are designing your data set (in Excel). With the data in the right class and the right format we can easily call the ggplot function, and add a scatter plot layer to it."
  },
  {
    "objectID": "ggplot2.html#aesthetics",
    "href": "ggplot2.html#aesthetics",
    "title": "10  Data visualization using ggplot2",
    "section": "10.2 Aesthetics",
    "text": "10.2 Aesthetics\nAfter figuring out what data to plot it is necessary to indicate how to plot it. Aesthetics are used to indicate how to plot what. As we saw in the plot of the ldeaths data we start with indicating what data.frame to plot and use aes() to indicate what to plot on the x axis, the y axis and what to use as color. We do not have to indicate what to plot where and which color to give to which category. We simply map a column of our data.frame to an aesthetic. Depending on the geom we use there are a number of aesthetics that can be mapped to a variable:\n\nx\ny\ncolor\nfill\nsize\nalpha\nlinetype\nlabels\nshape\ngroup\n\nAesthetics can also be specified per geom layer. This allows plotting multiple geom layers with different aesthetics. However, when using one data source and one geom layer this will result in exactly the same plot.\n\nggplot(data) + geom_point(aes(x=Month, y=Deaths, color=Sex))\n\nWe can also use plotting parameters without mapping them to a variable to change all dots in the geom_point. This can only be done in the geom itself.\n\nggplot(data, aes(x=Month, y=Deaths, color=Sex)) + geom_point(size=3)"
  },
  {
    "objectID": "ggplot2.html#geometries",
    "href": "ggplot2.html#geometries",
    "title": "10  Data visualization using ggplot2",
    "section": "10.3 Geometries",
    "text": "10.3 Geometries\nFor the previous ggplots we have used the geom_point function which generates a scatter plot layer that can be added to the ggplot. “point” is one of the many geometry layers available in the ggplot library. There are over thirty different geoms in ggplot which can be found at http://docs.ggplot2.org/. We will have a look at the plot types that we have already encountered using the basic R plotting functions and replace them with their ggplot counterparts.\n\nScatter plots\nJust like with other objects in R a ggplot object can be saved to a variable using “<-”. This makes it possible to store the basic plot in a variable and add different geoms to it. Geometries are added to a plot using “+”.\n\n#Basic graphics:\nplot(ToothGrowth$len)\n\n\n\n\n\n\n\n\n\np <- ggplot(ToothGrowth)\np + geom_point(aes(x=as.numeric(rownames(ToothGrowth)), y=len), size=2)\n\n\n\n\n\n\n\n\nWe now map the numeric row names of ToothGrowth to the x aesthetic, however, we could also create a new column called index in the data.frame.\n\nToothGrowth$index <- as.numeric(rownames(ToothGrowth))\n\nWhen we change the data of the ggplot object we saved in variable p we need to recreate the ggplot object with the new data set.\n\np <- ggplot(ToothGrowth)\n\n\n\nLine graphs\n\n#Basic graphics:\nplot(ToothGrowth$len, type = \"l\")\n\n\n\n\n\n\n\np + geom_line(aes(x=index, y=len))\n\n\n\n\n\n\n\n\n\n\nBar charts\n\n#Basic graphics:\nbarplot(table(ToothGrowth$dose))\n\n\n\n\n\n\n\np + geom_bar(aes(x=dose))\n\n\n\n\n\n\n\n\nBecause dose is a continuous variable, ggplot creates a x axis with a continuous scale, which is why there is an empty spot for the 1.5 dose. If we want to use a continuous value as a categorical value we can change it into a factor on the fly in the geom function:\n\np + geom_bar(aes(x=as.factor(dose)))\n\n\n\n\n\n\n\n\n\n\nHistograms\n\n#Basic graphics:\nhist(ToothGrowth$len,breaks = 50)\n\n\n\n\n\n\n\np + geom_histogram(aes(x=len), binwidth = 0.5)\n\n\n\n\n\n\n\n\n\n\nBox plots\n\n#Basic graphics:\nboxplot(ToothGrowth$len~ToothGrowth$supp)\n\n\n\n\n\n\n\n\n\np + geom_boxplot(aes(x=supp,y=len))\n\n\n\n\n\n\n\n\nIf we want whiskers in our plot we can add an error bar geom\n\np + geom_errorbar(aes(x=supp, ymin=..., ymax=...),width=0.5)\n\n\n\n\n\n\n\n\n\n\nHowever, as you can see, this geom requires ymin and ymax as aesthetics and does not calculate the values by itself. We could calculate the min and max values for tooth length grouped by supplement, but we will use a trick using ggplot’s box plot statistics function. (if you want to know more, please read more about these “stat” functions online)\nFirst, we add the error bars with the “stat_boxplot” function, and then add the box plots on top of them.\n\np + stat_boxplot(aes(x=supp,y=len), geom=\"errorbar\", width=0.5) + \n    geom_boxplot(aes(x=supp,y=len))\n\n\n\n\n\n\n\n\nAs we can see the aesthetics of both geoms have to be defined separately in this plot. To reduce typing we could also write the ggplot as follows.\n\np <- ggplot(ToothGrowth, aes(x=supp,y=len)) \np + stat_boxplot(geom=\"errorbar\", width=0.5) + geom_boxplot()\n\nWhen the aesthetics are specified in the base ggplot object it is not necessary to specify them in the added layers.\n\n\nHeatmaps\nOne popular way of displaying large grids of data is using a heatmap. The tile geom generates a tile at each provided x and y value and uses the fill aesthetic to fill the tiles according to another variable. The border color of the tiles are can be changed by using the color aesthetic.\n\np <- ggplot(ToothGrowth)\n\np + geom_tile(aes(x = supp, y = as.factor(dose), fill = len), color=\"black\")\n\n\n\n\n\n\n\n\nThere are dedicated packages for plotting heatmaps, which also perform horizontal and vertical clustering of the tiles. These are, however, out of the scope of this course, but it should be easy to find them online."
  },
  {
    "objectID": "ggplot2.html#facets",
    "href": "ggplot2.html#facets",
    "title": "10  Data visualization using ggplot2",
    "section": "10.4 Facets",
    "text": "10.4 Facets\nApart from using aesthetics to map variables to, ggplot has another feature which can help visualizing data called “facets”. We have added multiple plots to the viewing window before, using “par(mfrow=c(…,…))”. However, after specifying how many plots should be printed in the plot viewer we have to call the plot function multiple times to populate the viewer.\nIf we want to compare the effect of orange juice versus vitamin C depending on the dose we can plot three box plots next to each other.\n\npar(mfrow = c(1, 3))\n\nlow <- ToothGrowth[which(ToothGrowth$dose==0.5),]\nmed <- ToothGrowth[which(ToothGrowth$dose==1),]\nhigh <- ToothGrowth[which(ToothGrowth$dose==2),]\n\nboxplot(low$len~low$supp, main = \"Low dose\", xlab = \"Supplement Type\")\nboxplot(med$len~med$supp, main = \"Medium dose\", xlab = \"Supplement Type\")\nboxplot(high$len~high$supp, main = \"High dose\", xlab = \"Supplement Type\")\n\n\n\n\n\n\n\n\nHowever, using ggplot we can simply map the dose column to a ggplot facet grid. The mapping of variables is not done via a aes(), but in formula form. Variables on the right indicate the columns in the grid and variables on the left indicate the rows of the grid. A “.” can be used if we want to use only one variable for faceting. This will also preserve the scales, making it more easy to compare the three plots. For fun, let’s add the actual data points in an additional geom on top of the box plot.\n\nggplot(ToothGrowth, aes(x=supp,y=len)) + \n    stat_boxplot(geom=\"errorbar\", width=0.5) + \n    geom_boxplot() + geom_point(color=\"red\") + \n    facet_grid(. ~ as.factor(dose))\n\n\n\n\n\n\n\n\nWe can do the same with two variables in a grid.\n\nggplot(ToothGrowth, aes(x=len)) + \n    geom_histogram(bins = 5) + \n    facet_grid(dose ~ as.factor(supp))"
  },
  {
    "objectID": "ggplot2.html#scales",
    "href": "ggplot2.html#scales",
    "title": "10  Data visualization using ggplot2",
    "section": "10.5 Scales",
    "text": "10.5 Scales\nWhen mapping a variable to one of the aesthetics of a ggplot, ggplot uses the default scales. It is however possible to adjust the scales of the plot and their color using the scales functions. The scales that are generally used the most are those for the x, y, color and fill of the plot. The type of function to adjust the scale of one of the aesthetics depends on the aesthetic and the type of variable (continuous or discrete). Some of the possible scale adjustments, such as limits, transformation, breaks, labels, and color, are exemplified by the plot below.\n\nggplot(ToothGrowth, aes(x=index, y=as.factor(dose), color=len)) + \n    geom_point() + \n    scale_x_continuous(limits=c(1,100), trans = \"log2\", \n        breaks=c(2,4,8,16,32,64), \n        label=c(\"two\",\"four\",\"eight\",\"sixteen\",\"thirtytwo\",\"sixtyfour\")) + \n    scale_y_discrete(label=c(\"low\",\"medium\",\"high\")) + \n    scale_color_gradient2(limits=c(0,40), low = \"green\", mid = \"black\", high = \"red\", \n        midpoint = 20)\n\n\n\n\n\n\n\n\nHave a look at the scales chapter at http://ggplot2.tidyverse.org/reference/ to explore the other possibilities!"
  },
  {
    "objectID": "ggplot2.html#themes",
    "href": "ggplot2.html#themes",
    "title": "10  Data visualization using ggplot2",
    "section": "10.6 Themes",
    "text": "10.6 Themes\nUntil now we have simply mapped a variable from our data set to an aesthetics parameter, potentially change the scales, and let ggplot handle the styling of the graph. However, ggplot has many options to customize the style of your plot using themes. There are several standard themes that we can use, however it is possible to create our own style from scratch.\nThe standard themes available in the ggplot package are:\n\ntheme_gray\ntheme_bw\ntheme_linedraw\ntheme_light\ntheme_dark\ntheme_minimal\ntheme_classic\ntheme_void\n\nTo add a standard theme we simply add the theme to the ggplot like we would with a geom.\n\np <- ggplot(ToothGrowth)\np + geom_point(aes(x = index, y = len, color = supp, size = dose)) + theme_light()\n\n\n\n\n\n\n\n\nCustom themes can be made from scratch using the “theme()” function. To have a look at all customization parameters visit http://ggplot2.tidyverse.org/reference/theme.html. Labels can be edited by adding “labs()” to the plot.\n\np <- ggplot(ToothGrowth)\np + geom_point(aes(x = index, y = len, color = supp, size = dose)) + \n    theme(text = element_text(family = \"serif\", colour = \"#6f898e\"), \n      line = element_line(color = \"#163f47\"), \n      rect = element_rect(fill = \"#163f47\", color = \"#163f47\"),\n        axis.text.x = element_text(color=\"black\"), \n        axis.text.y = element_text(color=\"white\"), \n      axis.ticks = element_line(color = \"#6f898e\"), \n      axis.line = element_line(color = \"#163f47\", linetype = 1),\n        legend.background = element_blank(), \n        legend.key = element_blank(), \n        panel.background = element_rect(fill = \"#215c68\", colour = \"#163f47\"), \n        panel.border = element_blank(), \n      panel.grid = element_line(color = \"#163f47\"), \n      panel.grid.major = element_line(color = \"#163f47\"), \n      panel.grid.minor = element_line(color = \"#163f47\"), \n      plot.background = element_rect(fill = NULL, colour = NA, linetype = 0)\n    ) + \n    labs(title=\"Toothgrowth\", \n        subtitle = \"Orange juice or Vitamin C?\", x=\"Index\", y=\"Toothlength\", \n        size=\"Dose\", color=\"Supplement\") +\n    scale_color_manual(label=c(\"Orange juice\",\"Vitamin C\"), \n        values = c(\"VC\"=\"green\",\"OJ\"=\"orange\"))"
  },
  {
    "objectID": "ggplot2.html#saving-ggplots",
    "href": "ggplot2.html#saving-ggplots",
    "title": "10  Data visualization using ggplot2",
    "section": "10.7 Saving ggplots",
    "text": "10.7 Saving ggplots\nWe can save out plots by using the ggsave() function. ggsave takes two argument, the first argument being the ggplot and the second being the location where the file should be saved. If we do not specify the complete path, it will save the plot in our current working directory (getwd()). The type of the file depends on the file extension we use. Possible file extensions are “eps”, “ps”, “tex” (pictex), “pdf”, “jpeg”, “tiff”, “png”, “bmp”, “svg” or “wmf” (windows only).\n\np <- ggplot(ToothGrowth)\n\nmyplot <- p + geom_point(aes(x = index, y = len, color = supp, size = dose))\n\nggsave(\"my_plot.pdf\",myplot)"
  },
  {
    "objectID": "ggplot2.html#ggplot2-extensions",
    "href": "ggplot2.html#ggplot2-extensions",
    "title": "10  Data visualization using ggplot2",
    "section": "10.8 ggplot2 extensions",
    "text": "10.8 ggplot2 extensions\nBasic ggplot functions are enough to create a rich variety of plots. However, depending on the field of research, specific plots are popular to visualize specific types of data. Sometimes these plots cannot be made directly from “basic” ggplot. Since ggplot is an opensource package, several people have extended it fulfill the custom needs of users. Many of these ggplot extension packages can be found online with a quick google. The ggplot2 extensions gallery shows some nice examples of add-ons https://exts.ggplot2.tidyverse.org/gallery/. Below are a handful of examples, which we will not explain in detail, but should serve as a source of inspiration.\n\n\n\nggridgeshttps://cran.r-project.org/web/packages/ggridges/\n\n\n\n\n\nplotROC https://github.com/sachsmc/plotROC\n\n\n\n\n\nsurvminer https://rpkgs.datanovia.com/survminer/index.html"
  },
  {
    "objectID": "ggplot2_practicals_questions.html",
    "href": "ggplot2_practicals_questions.html",
    "title": "11  ggplot: Questions",
    "section": "",
    "text": "Load the ggplot2 library (install it if you have to) and the diamonds data set using data()\n\n# if needed install.packages(\"ggplot2\")\nlibrary(ggplot2)\ndata(\"diamonds\")\n\n\nQuestion 1\n\n\nExplore the data set using dim(), str() and help(), which variables are continuous, which variables are discrete? Is this data set ready for plotting with ggplot?\n\n\n\n\nQuestion 2\n\n\nUse ggplot to plot a scatterplot of the relationship between the diamonds’ carat a\n\n\n\n\nQuestion 3\n\n\nMake all dots darkblue and set the alpha value to 0.1\n\n\n\n\nQuestion 4\n\n\nVisualize the influence of the color of a diamond on its price by mapping the diamond color to the color aesthetic\n\n\n\n\nQuestion 5\n\n\nUse a ggplot barplot to visualize diamond clarity depending on color, map diamond color to x and diamond clarity to fill\n\n\n\n\nQuestion 6\n\n\nCreate a boxplot of the carat of a diamond based on its clarity and add whiskers using stat_boxplot\n\n\n\n\nQuestion 7\n\n\nAdd a geom_point layer to the previous plot mapping the diamonds price to the color\n\n\n\n\nQuestion 8\n\n\nCreate a histogram of the price of the diamonds and separate the histograms into facets using diamond color, choose a good binwith or number of bins\n\n\n\n\nQuestion 9\n\n\nCreate a grid of facets of the same histogram by comparing both color and cut\n\n\n\n\nQuestion 10\n\n\nUse aggregate(diamonds, by = list(cut = diamonds$cut, color = diamonds$color), mean) to calculate the mean of all variables by cut and color. Create a heatmap of the mean prices by cut and color using geom_tile\n\n\n\n\nQuestion 11\n\n\nChange the title of the heatmap to “Average prices”\n\n\n\n\nQuestion 12\n\n\nChange the gradient of the fill scale using ‘scale_fill_gradient2’. Have it go from darkblue to white to darkred, set the midpoint to 4500\n\n\n\n\nQuestion 13\n\n\nChoose and add a theme to the heatmap, or create a theme yourself using the options listed at http://ggplot2.tidyverse.org/reference/theme.html"
  },
  {
    "objectID": "ggplot2_practicals_answers.html",
    "href": "ggplot2_practicals_answers.html",
    "title": "12  ggplot: Answers",
    "section": "",
    "text": "Warning\n\n\n\nMake sure that you try the exercises yourself first before looking at the answers\n\n\n\nQuestion 1Answer 1\n\n\nExplore the data set using dim(), str() and help(), which variables are continuous, which variables are discrete? Is this data set ready for plotting with ggplot?\n\n\nExplore the data set using dim(), str() and help(), which variables are continuous, which variables are discrete? Is this data set ready for plotting with ggplot?\n\ndim(diamonds)\nstr(diamonds)\nhelp(diamonds)\n\n\n\n\n\nQuestion 2Answer 2\n\n\nUse ggplot to plot a scatterplot of the relationship between the diamonds’ carat and their price\n\n\nUse ggplot to plot a scatterplot of the relationship between the diamonds’ carat and their price\n\nggplot() + geom_point(data=diamonds, aes(x=carat, y=price))\n\n#or\n\nggplot(diamonds) + geom_point(aes(x=carat, y=price))\n\n#or\n\nggplot(diamonds, aes(x=carat, y=price)) + geom_point()\n\nCut, color, and clarity are factors, and therefore discrete. The others are numeric continuous variables.\n\n\n\n\nQuestion 3Answer 3\n\n\nMake all dots darkblue and set the alpha value to 0.1\n\n\nMake all dots darkblue and set the alpha value to 0.1\n\nggplot(diamonds, aes(x=carat, y=price)) + geom_point(color=\"darkblue\", alpha=0.1)\n\n\n\n\n\nQuestion 4Answer 4\n\n\nVisualize the influence of the color of a diamond on its price by mapping the diamond color to the color aesthetic\n\n\nVisualize the influence of the color of a diamond on its price by mapping the diamond color to the color aesthetic\n\n#The color of the dots will be overwritten if we specify it statically  \n#in the geom_point function itself\nggplot(diamonds, aes(x=carat, y=price, color=color)) + geom_point(alpha=0.1)\n\n\n\n\n\nQuestion 5Answer 5\n\n\nUse a ggplot barplot to visualize diamond clarity depending on color, map diamond color to x and diamond clarity to fill\n\n\nUse a ggplot barplot to visualize diamond clarity depending on color, map diamond color to x and diamond clarity to fill\n\nggplot(diamonds, aes(x=color, fill=clarity)) + geom_bar()\n\n\n\n\n\nQuestion 6Answer 6\n\n\nCreate a boxplot of the carat of a diamond based on its clarity and add whiskers using stat_boxplot\n\n\nCreate a boxplot of the carat of a diamond based on its clarity and add whiskers using stat_boxplot\n\nggplot(diamonds, aes(x=clarity, y=carat)) + \n    stat_boxplot(geom=\"errorbar\", width=0.5) + \n    geom_boxplot()\n\n\n\n\n\nQuestion 7Answer 7\n\n\nAdd a geom_point layer to the previous plot mapping the diamonds price to the color\n\n\nAdd a geom_point layer to the previous plot mapping the diamonds price to the color\n\nggplot(diamonds, aes(x=clarity, y=carat)) + \n    stat_boxplot(geom=\"errorbar\", width=0.5) + \n    geom_boxplot() + \n    geom_point(aes(color=price))\n\n\n\n\n\nQuestion 8Answer 8\n\n\nCreate a histogram of the price of the diamonds and separate the histograms into facets using diamond color, choose a good binwith or number of bins\n\n\nCreate a histogram of the price of the diamonds and separate the histograms into facets using diamond color, choose a good binwith or number of bins\n\nggplot(diamonds, aes(x=price)) + \n    geom_histogram(binwidth = 100) + \n    facet_grid(color ~ .)\n\n\n\n\n\nQuestion 9Answer 9\n\n\nCreate a grid of facets of the same histogram by comparing both color and cut\n\n\nCreate a grid of facets of the same histogram by comparing both color and cut\n\nggplot(diamonds, aes(x=price)) + \n    geom_histogram(binwidth = 100) + \n    facet_grid(color ~ cut)\n\n\n\n\n\nQuestion 10Answer 10\n\n\nUse aggregate(diamonds, by = list(cut = diamonds$cut, color = diamonds$color), mean) to calculate the mean of all variables by cut and color. Create a heatmap of the mean prices by cut and color using geom_tile\n\n\nUse aggregate(diamonds, by = list(cut = diamonds$cut, color = diamonds$color), mean) to calculate the mean of all variables by cut and color. Create a heatmap of the mean prices by cut and color using geom_tile\n\n#Aggregate uses a function (in this case mean) to aggregate all variables \n#in a given data.frame by a list of variables given in \"by\"\nmean.price <- aggregate(diamonds, by = list(cut = diamonds$cut, color = diamonds$color), mean)\n\nggplot(mean.price, aes(x=cut, y=color, fill=price)) + \n    geom_tile()\n\n\n\n\n\nQuestion 11Answer 11\n\n\nChange the title of the heatmap to “Average prices”\n\n\nChange the title of the heatmap to “Average prices”\n\nggplot(mean.price, aes(x=cut, y=color, fill=price)) + \n    geom_tile() + \n    labs(title=\"Average prices\")\n\n\n\n\n\nQuestion 12Answer 12\n\n\nChange the gradient of the fill scale using ‘scale_fill_gradient2’. Have it go from darkblue to white to darkred, set the midpoint to 4500\n\n\nChange the gradient of the fill scale using ‘scale_fill_gradient2’. Have it go from darkblue to white to darkred, set the midpoint to 4500\n\nggplot(mean.price, aes(x=cut, y=color, fill=price)) + \n    geom_tile() + \n    labs(title=\"Average prices\") + \n    scale_fill_gradient2(low=\"darkblue\", mid=\"white\", high=\"darkred\", midpoint = 4500)\n\n\n\n\n\nQuestion 13Answer 13\n\n\nChoose and add a theme to the heatmap, or create a theme yourself using the options listed at http://ggplot2.tidyverse.org/reference/theme.html\n\n\nChoose and add a theme to the heatmap, or create a theme yourself using the options listed at http://ggplot2.tidyverse.org/reference/theme.html\n\nggplot(mean.price, aes(x=cut, y=color, fill=price)) + \n    geom_tile() + \n    labs(title=\"Average prices\") + \n    scale_fill_gradient2(low=\"darkblue\", mid=\"white\", high=\"darkred\", midpoint = 4500) + \n    theme_minimal()"
  },
  {
    "objectID": "functions_intro.html",
    "href": "functions_intro.html",
    "title": "Functions 1",
    "section": "",
    "text": "Functions are things you can do. R comes with predefined functions which do many things from basic file management to complex statistics. To get started, below are some oft used functions. This default set of functions is easily extended by defining your own functions and adding those defined by others conveniently in CRAN and BioConductor packages:\nhttp://stat.ethz.ch/R-manual/R-patched/library/base/html/00Index.html\nhttp://cran.r-project.org/web/packages/available_packages_by_name.html\nhttp://www.bioconductor.org/packages/release/bioc/\nFunctions are expressed as:\nfunction.name(), e.g., t.test() or, an operator, e.g., +\nEasily obtain functions from other R users using install.packages():\ninstall.packages(\"packageName\", lib = \"/directory/to/my custom R library\", repos = \"http://cran.xl-mirror.nl\")\nThe package name must be quoted when installing. Besides installing the package on your PC, you need to load it into your R session before you can use it:\nlibrary(\"packageName\") ## quotes are optional when loading a package"
  },
  {
    "objectID": "functions_types.html",
    "href": "functions_types.html",
    "title": "13  Types of available functions",
    "section": "",
    "text": "Arithmetic Operators\nR can simply be used as a calculator.\n\nx <- 10\ny <- 3\nx + y\n\n[1] 13\n\nx - y\n\n[1] 7\n\nx * y\n\n[1] 30\n\nx / y\n\n[1] 3.333333\n\nx ^ y           # exponentiation\n\n[1] 1000\n\nx %% y          # modular arithmetic, remainder after division\n\n[1] 1\n\nx %/% y         # integer part of a fraction\n\n[1] 3\n\n\nHow these functions work on vectors:\n\n\n\n\na_vector\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\na_vector + x                    # x is recycled without warning\n\n [1] 11 12 13 14 15 16 17 18 19 20\n\na_vector - y\n\n [1] -2 -1  0  1  2  3  4  5  6  7\n\na_vector + a_vector\n\n [1]  2  4  6  8 10 12 14 16 18 20\n\nvec_of_thr <- c(2, 4, 6)\na_vector\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\na_vector + vec_of_thr           # recycled with a warning\n\nWarning in a_vector + vec_of_thr: longer object length is not a multiple of\nshorter object length\n\n\n [1]  3  6  9  6  9 12  9 12 15 12\n\nvec_of_fi <- c(1, 2, 3, 4, 5)\na_vector\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\na_vector + vec_of_fi            # recycled without warning\n\n [1]  2  4  6  8 10  7  9 11 13 15\n\n\nHow these functions work on matrices:\n\n\n\n\nano_matrix\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    4    7   10\n[2,]    2    5    8   11\n[3,]    3    6    9   12\n\nano_matrix + x\n\n     [,1] [,2] [,3] [,4]\n[1,]   11   14   17   20\n[2,]   12   15   18   21\n[3,]   13   16   19   22\n\nano_matrix - y\n\n     [,1] [,2] [,3] [,4]\n[1,]   -2    1    4    7\n[2,]   -1    2    5    8\n[3,]    0    3    6    9\n\nano_matrix + ano_matrix\n\n     [,1] [,2] [,3] [,4]\n[1,]    2    8   14   20\n[2,]    4   10   16   22\n[3,]    6   12   18   24\n\nano_matrix * ano_matrix\n\n     [,1] [,2] [,3] [,4]\n[1,]    1   16   49  100\n[2,]    4   25   64  121\n[3,]    9   36   81  144\n\n\n\n\nRelational Operators\nUsing these functions it is possible to compare variables to other variables or to specific values.\n\n#Previously we defined x as 10 and y as 3\nx < y   #Smaller than\n\n[1] FALSE\n\nx > y   #Larger than\n\n[1] TRUE\n\nx <= y  #Smaller or equal to\n\n[1] FALSE\n\nx >= y  #Larger or equal to\n\n[1] TRUE\n\nx == y  #Equal to (use two '=')\n\n[1] FALSE\n\nx != y  #Not equal to (! means 'not')\n\n[1] TRUE\n\n\n\n\nLogical Operators\nR has logical operators (or Boolean operators) corresponding to “and” and “or”. They’re used to combine two logical expressions together to form a single compound logical expression. Another logical operator corresponding to “not” is used to negate a logical expression.\nThese are written in R as:\n\n&&  # \"And\"   for logical scalars (single values)\n||  # \"Or\"    for logical scalars\n!   # \"Not\"   for logical scalars or vectors\n&   # \"And\"   for logical vectors (multiple values)\n|   # \"Or\"    for logical vectors\n\nThese operate on logical (TRUE or FALSE) expressions and return TRUE or FALSE or TRUE/FALSE vectors.\nThe distinction between && and &, and between || and | is that the former is for single values and the latter for multiple values.\nLogical Operations on Scalar Logical Expressions\n&& returns TRUE if both of the expressions are TRUE and it returns FALSE otherwise:\n\nTRUE && TRUE\n\n[1] TRUE\n\nTRUE && FALSE\n\n[1] FALSE\n\n\n|| returns TRUE if one or both of the expressions are TRUE and it returns FALSE otherwise:\n\nFALSE || TRUE\n\n[1] TRUE\n\nFALSE || FALSE\n\n[1] FALSE\n\n\nAs a practical example, if we want to test whether a variable x lies between two numbers, say 60 and 70, we type:\n\nx <- 75\nx > 60 && x < 70\n\n[1] FALSE\n\n\nand to test whether it lies outside the range 60 to 70, we type:\n\nx < 60 || x > 70\n\n[1] TRUE\n\n\nHere’s an example of using && in an if() statement:\n\nx <- 3\ny <- 5\n\nif(x < 10 && y < 10) {\n  print(\"Both less than 10\")\n} else {\n  print(\"Not both less than 10\")\n}\n\n[1] \"Both less than 10\"\n\n\nThe negation operator, !, returns “the opposite” of a logical expression:\n\n!TRUE\n\n[1] FALSE\n\n\n\n!FALSE\n\n[1] TRUE\n\n\n\n!(5 < 6)\n\n[1] FALSE\n\n\nPay attention to the operator precedence for &&, ||, and !. It can be found by typing: ?Syntax but parentheses can be used to control the order of operations.\nIf we try to apply && or || to vectors, R only applies it to their first elements, and you get a warning:\n\nc(TRUE, FALSE, TRUE) && c(TRUE, TRUE, FALSE)\n\nWarning in c(TRUE, FALSE, TRUE) && c(TRUE, TRUE, FALSE): 'length(x) = 3 > 1' in\ncoercion to 'logical(1)'\n\nWarning in c(TRUE, FALSE, TRUE) && c(TRUE, TRUE, FALSE): 'length(x) = 3 > 1' in\ncoercion to 'logical(1)'\n\n\n[1] TRUE\n\n\nLogical Operations on Logical Vectors\nTo apply the operations “and” and “or” element-wise on two logical vectors, use & and |. For example:\n\nc(TRUE, FALSE, TRUE) & c(TRUE, TRUE, FALSE)\n\n[1]  TRUE FALSE FALSE\n\n\n& and | are useful in ifelse() statements. (Recall that ifelse() operates element-wise on vectors). For example, consider the systolic and diastolic blood pressure readings:\n\nsystolic <- c(110, 119, 111, 113, 128)\ndiastolic <- c(70, 74, 88, 74, 83)\n\nA blood pressure is classified as normal if the systolic level is less than 120 and the diastolic level is less than 80:\n\nclassification <- ifelse(systolic < 120 & diastolic < 80, yes = \"Normal\", no = \"Abnormal\")\nclassification\n\n[1] \"Normal\"   \"Normal\"   \"Abnormal\" \"Normal\"   \"Abnormal\"\n\n\nIn the next example, we use & in square brackets [ ] to extract rows from a data frame:\n\nbpData <- data.frame(\n  name = c(\"Joe\", \"Katy\", \"Bill\", \"Kim\", \"Mark\"),\n  systolic = c(110, 119, 111, 113, 128),\n  diastolic = c(70, 74, 88, 74, 83)\n)\n\nbpData\n\n  name systolic diastolic\n1  Joe      110        70\n2 Katy      119        74\n3 Bill      111        88\n4  Kim      113        74\n5 Mark      128        83\n\nbpData[bpData$systolic < 120 & bpData$diastolic < 80, ]\n\n  name systolic diastolic\n1  Joe      110        70\n2 Katy      119        74\n4  Kim      113        74\n\n\n\n\nBuilt-in Named Functions\nR has an extensive set of built-in functions, a few of which are listed below:\nPrint structure of an object:\n\nstr()\n\nPrint class of an object:\n\nclass()\n\nFirst six elements/rows:\n\nhead()\n\nLast six elements/rows:\n\ntail()\n\nList all objects and functions that you currently made:\n\nls()\n\nGenerate a sequence of values:\n\nseq(from=1, to=10, by=2)\n\n[1] 1 3 5 7 9\n\n\nRun the entire contents of a script:\n\nsource(\"myScript.R\")\n\nFor a (very long) list of all named functions available in base-R have a look at this website:\nhttps://stat.ethz.ch/R-manual/R-patched/library/base/html/00Index.html"
  },
  {
    "objectID": "functions_arguments.html",
    "href": "functions_arguments.html",
    "title": "14  Function arguments",
    "section": "",
    "text": "Input of Functions\nEach function accepts one or more values passed to it as arguments, performs computations or operations on those values, and returns a single result.\nTo use a function, type the name of the function with the values of its argument(s) in parentheses ( ), then hit ‘Enter’. For example:\n\nsqrt(2)\n\n[1] 1.414214\n\n\nValues passed as arguments can be in the form of variables, such as x below:\n\nx <- 2\n\nsqrt(x)\n\n[1] 1.414214\n\n\nor they can be entire expressions, such as x^2 + 5 below:\n\nsqrt(x^2 + 5)\n\n[1] 3\n\n\nMost functions take multiple arguments, each of which has a name, and some of which are optional. One way to see what arguments a function takes and which ones are optional is to use the function args().Another way to view a function’s arguments is to look at its help file by typing a ? in front of the function ’s name like so: ?sqrt\nFor example, to see what arguments round() takes (using args()), we’d type:\n\nargs(round)\n\nfunction (x, digits = 0) \nNULL\n\n\nWe see that round() has two arguments, x, a numeric value to be rounded, and digits, an integer specifying the number of decimal places to round to. Thus to round 4.679 to 2 decimal places, we type:\n\nround(4.679, 2)\n\n[1] 4.68\n\n\n\n\nOptional Arguments and Default Values\nThe specification digits = 0 in the output from args(round) tells us that digits has a default value of 0. This means that it’s an optional argument and if no value is passed for that argument, rounding is done to 0 decimal places (i.e. to the nearest integer).\n\n\nPositional Matching and Named Argument Matching\nWhen we type round(4.679, 2) R knows, by positional matching, that the first value, 4.679, is the value to be rounded and the second one, 2, is the number of decimal places to round to.\nWe can also specify values for the arguments by name. For example:\n\nround(x = 4.679, digits = 2)\n\n[1] 4.68\n\n\nWhen named argument matching is used, as above, the order of the arguments is irrelevant. For example, we get the same result by typing:\n\nround(digits = 2, x = 4.679)\n\n[1] 4.68\n\n\nThe two types of argument specification (positional and named argument matching) can be mixed in the same function call:\n\nround(4.679, digits=2)\n\n[1] 4.68\n\n\nAlthough it may be confusing, it is also possible to specify the first argument in the second position, by using named argument matching for the second argument like so:\n\nround(digits=2, 4.679)\n\n[1] 4.68\n\n\n\n\n\n\n\n\nTip\n\n\n\nFor readability of your code it is advisable to name most of the arguments when calling a function"
  },
  {
    "objectID": "functions_custom.html",
    "href": "functions_custom.html",
    "title": "15  Creating your own functions",
    "section": "",
    "text": "To write your own function, you need to use the function function(), specify argument(s) that will be used in the function (with our without defaults), and in curly brackets { } specify what the function should do (referring to the argument(s)), including whether something is returned.\nThe general form is:\n\nmyFun <- function(arg1, arg2) {\n  ## Here you type expressions that use the arguments\n}\n\nEach line inside the function is an object assignment, a function call, a subsetting, a conditional statement, an if/else statement, a for loop, etc. - basically anything you have now learned how to do in R that you want the function to do!\nTo have the function output something, you must return something (either the value of the last command is returned or you can use return()).\nIf you have multiple objects to return, you have to put them in an object container, like a list, vector, array or data.frame. It is not possible to return multiple individual objects like this:\nreturn(x,y)\nbut it is possible to return them in a vector or list like this:\nreturn(c(x,y))\nreturn(list(x,y)\nHere are a few examples of functions with no default arguments; note the different outputs:\n\ndo1 <- function(x, y){\n  z <- x + y\n  x\n  z\n}\n\ndo1(x = 1, y = 3)\n\n[1] 4\n\n\nNote that x is not returned. Only the last expression is returned.\n\ndo2 <- function(x, y){\n  z <- x + y \n  return(x)\n  z\n}\n\ndo2(x = 1, y = 3)\n\n[1] 1\n\n\nNote that z is not returned, if a return statement is encountered in the function anything after that statement is not executed.\n\ndo3 <- function(x, y){ \n  z <- x + y \n  return(list(x, z))\n}\n\ndo3(x = 1, y = 3)\n\n[[1]]\n[1] 1\n\n[[2]]\n[1] 4\n\n\nx and z are returned in a list\nHere is an example of a function with default arguments that returns a vector:\n\ndo4 <- function(x, y = 2){ \n  z1 <- x + y\n  z2 <- x * y \n  return(c(z1, z2))\n} \n\ndo4(x = 1) ## uses y = 2\n\n[1] 3 2\n\ndo4(x = 1, y = 3) ## overwrites default value of y\n\n[1] 4 3\n\n\nYou can create functions with a variable number of arguments using .... For example, here’s a function that returns the mean of all the values in an arbitrary number of vectors:\n\nmeanOfAll <- function(...) {\n  x <- mean(c(...))\n  return(x)\n}\n\nThe command\n\nusSales <- c(123,456,789)\neuropeSales <- c(100,1000,10000,100000)\notherSales <- c(50,100,150,200,250,300,350)\n\nmeanOfAll(usSales, europeSales, otherSales)\n\n[1] 8133.429\n\n\ncombines the three vectors and take the mean of all the data."
  },
  {
    "objectID": "functions_conditional.html",
    "href": "functions_conditional.html",
    "title": "16  Conditional execution using if and else",
    "section": "",
    "text": "If? Then! Else?\nSometimes we’ll want R to execute a statement only if a certain condition is met. This can be accomplished via the if() and (optionally) else statements:\n\nif()    # Used to execute a statement only if the given condition\n        # is met\nelse    # Used to specify an alternative statement to be executed \n        # if the condition given in if() isn't met\n\nSuch conditional execution commands have the forms:\n\nif (condition) {\n  statement1\n}\n\nand\n\nif (condition) {\n  statement1\n} else {\n  statement2\n}\n\nwhere condition is a logical expression (i.e. it evaluates to TRUE or FALSE)\nIn both cases above, if condition is TRUE, statement is executed. If condition is FALSE, then in the first case nothing happens, but in the second case, statement2 is executed.\nHere’s a simple example:\n\nx <- 5\nif (x < 10) {\n  y <- 0\n}\ny\n\n[1] 0\n\n\nHere’s another:\n\nif (x >= 10) {\n  y <- 1\n  } else {\n    y <- 0\n}\ny\n\n[1] 0\n\n\nIt is also possible to write short if/else statements on a single line, in that case you do not have to include { }:\n\ny <- if(x >= 10) 1 else 0\ny\n\n[1] 0\n\n\nBe aware that when using such conditional assignment statements, in the absence of else, if() returns NULL if the condition isn’t met. So:\n\ny <- if(x >= 10) 1\ny\n\nNULL\n\n\nIn the next example, return() is used to terminate a function call and return a value that depends on whether or not a condition is met:\n\nmySign <- function(x) {\n    if(x < 0) {\n      return(\"Negative\")\n    } else {\n      return(\"Non-negative\")\n    }\n}\n\nWe get:\n\nmySign(13)\n\n[1] \"Non-negative\"\n\n\n\n\nNested if() Statements\nIn addition, if() statements can be nested. The form for nested if() statements is\n\nif(condition1) {\n  if(condition2) {\n    statement1 \n  } else {\n    statement2\n  }\n}\n\nThe else always refers to the most recent if(), but to keep our code readable, we use tab indentation for every level of nesting in our nested if-else statements.\nApart form nesting if() statements it is also possible to string multiple if statements together like so:\n\nwhatAnimalSound <- function(animal){\n  if(animal == \"cat\") {\n    return(\"Meow!\")\n  } else if (animal == \"frog\") {\n    return(\"Ribbit!\")\n  } else if (animal == \"dog\") {\n    return(\"Woof!\")\n  } else {\n    return(paste0(\"I don't know what sound a '\",animal,\"' makes...\"))\n  }\n}\n\n\nwhatAnimalSound(\"dog\")\n\n[1] \"Woof!\"\n\nwhatAnimalSound(\"bird\")\n\n[1] \"I don't know what sound a 'bird' makes...\"\n\n\n\n\n\n\n\n\nTip\n\n\n\nNotice that the last statement can be else, but to string together multiple statements you have to use if else.\n\n\n\n\nVectorized if-else: The ifelse() Function\nSometimes we’ll need to create a vector whose values depend on whether or not the values in another vector satisfies some condition. In that case we can use the ifelse() function, which works on a vector of values by repeating the same conditional statement for every value in the vector.\nifelse() takes argument test, the condition to be met, yes, the return value (or vector of values) when test is TRUE, and no, the return values (or vector of values) when test is FALSE.\nFor example, here we convert the values in height to \"short\" or \"tall\" based on whether they are larger than 69 or not:\n\nheight <- c(69, 71, 67, 66, 72, 71, 61, 65, 73, 70, 68, 74)\n\nhtCategory <- ifelse(height > 69, yes = \"tall\", no = \"short\")\n\nhtCategory\n\n [1] \"short\" \"tall\"  \"short\" \"short\" \"tall\"  \"tall\"  \"short\" \"short\" \"tall\" \n[10] \"tall\"  \"short\" \"tall\" \n\n\nThe ifelse function is a very simple way of applying a test to a vector of values. To apply a more complicated function to a vector or to apply a function to multiple rows of a matrix or a dataframe we can use the apply functions which will be discussed later on."
  },
  {
    "objectID": "functions_practicals1_questions.html#function-arguments",
    "href": "functions_practicals1_questions.html#function-arguments",
    "title": "17  Functions 1: Questions",
    "section": "17.1 Function Arguments",
    "text": "17.1 Function Arguments\n\nQuestion 1\n\n\nLook at the help file for the function mean().\nHow many arguments does the function have?\nWhat types of vectors are accepted?\nWhat is the default setting for dealing with NA values?\n\n\n\n\nQuestion 2\n\n\nUse the function mean() to calculate the mean of the following values:\n\n\n\n\n\n\nNote\n\n\n\nnote the NA and use named argument matching\n\n\n\nc(1, 2, NA, 6)\n\n\n\n\n\nQuestion 3\n\n\nDo Q2 again but rearrange the arguments.\n\n\n\n\nQuestion 4\n\n\nDo Q2 again using positional matching.\n\n\n\n\nQuestion 5\n\n\nDetermine the class of mean() using class().\n\n\n\n\nQuestion 6\n\n\nDetermine the class of mean() using str().\n\n\n\n\nQuestion 7\n\n\nDetermine the class of the value output in Q4 using class().\n\n\n\n\nQuestion 8\n\n\nDetermine the class of the value output in Q4 using str().\n\n\n\n\nQuestion 9\n\n\nUse R as a calculator to calculate the following values:\n17^4=?\n45-2*3=?\n(45-2)*3=?"
  },
  {
    "objectID": "functions_practicals1_questions.html#use-the-operators-and-to-do-the-following",
    "href": "functions_practicals1_questions.html#use-the-operators-and-to-do-the-following",
    "title": "17  Functions 1: Questions",
    "section": "17.2 Use the operators %% and %/% to do the following:",
    "text": "17.2 Use the operators %% and %/% to do the following:\n\nQuestion 10\n\n\nCalculate the remainder after dividing 29,079 into 184,277,809.\n\n\n\n\nQuestion 11\n\n\nHow many times does 29,079 go into 184,277,809 (i.e. what’s the integer divide value)?\n\n\n\n\nQuestion 12\n\n\nDo the last calculation from Q8 in another way, like this:\n\na <- 45\nb <- 2\nc <- 3\nd <- (a - b) * c\n\nNow check what a, b, c, and d are. You can just type the variable name (e.g. a) and hit ‘Control+Enter’ or use the command print(a)."
  },
  {
    "objectID": "functions_practicals1_questions.html#if-else-and-ifelse-and-vectorization",
    "href": "functions_practicals1_questions.html#if-else-and-ifelse-and-vectorization",
    "title": "17  Functions 1: Questions",
    "section": "17.3 if(), else, and ifelse() and Vectorization",
    "text": "17.3 if(), else, and ifelse() and Vectorization\n\nQuestion 13\n\n\nWrite a function called ‘evenOrOdd’ involving if and else that takes an argument x and returns “Even” or “Odd” depending on whether or not x is divisible by 2. (Do not use the ifelse() function).\n\n\n\n\nQuestion 14\n\n\nIs your function ‘evenOrOdd’ vectorized? Check by passing it the vector:\n\nw <- c(3, 6, 6, 4, 7, 9, 11, 6)\n\n\n\n\n\nQuestion 15\n\n\nAnother way to determine if each element of a vector is even or odd is to use the ifelse() function, which serves as a vectorized version if and else. Use ifelse() to obtain “Even” or “Odd” for each element of w."
  },
  {
    "objectID": "functions_practicals1_questions.html#logical-operators-and",
    "href": "functions_practicals1_questions.html#logical-operators-and",
    "title": "17  Functions 1: Questions",
    "section": "17.4 Logical Operators &, |, and !",
    "text": "17.4 Logical Operators &, |, and !\n\nQuestion 16\n\n\nWhat will be the result of the following:\n\n(10 < 20 && 15 < 16) || 9 == 10\n\n\n\n\n\nQuestion 17\n\n\nOne of the following evaluates to TRUE, the other to FALSE. Which is which?\n\n4 < 3 && (5 < 6 || 8 < 9)\n\n\n(4 < 3 && 5 < 6) || 8 < 9\n\n\n\n\n\nQuestion 18\n\n\nThe data set in ‘BPressure.txt’ contains the systolic and diastolic blood pressure readings for 22 patients.\n\nRead the data from BPressure.txt into a data frame called bp using read.table().\nA person’s blood pressure is classified as normal if the systolic level is below 120 and the diastolic level is below 80. Use relational, and logical operations in square brackets [ ] to extract from bp the rows corresponding to patients with normal blood pressures.\nNow use the same strategy to extract the rows corresponding to patients whose blood pressures aren’t normal."
  },
  {
    "objectID": "functions_practicals1_answers.html#function-arguments",
    "href": "functions_practicals1_answers.html#function-arguments",
    "title": "18  Functions 1: Answers",
    "section": "18.1 Function Arguments",
    "text": "18.1 Function Arguments\n\nQuestion 1Answer\n\n\nLook at the help file for the function mean().\nHow many arguments does the function have?\nWhat types of vectors are accepted?\nWhat is the default setting for dealing with NA values?\n\n\nThree arguments (plus further arguments).\nNumerical and logical vectors are accepted.\nThe default setting is to NOT remove NA (missing) values.\n\n\n\n\nQuestion 2Answer\n\n\nUse the function mean() to calculate the mean of the following values:\n\n\n\n\n\n\nNote\n\n\n\nnote the NA and use named argument matching\n\n\n\nc(1, 2, NA, 6)\n\n\n\n\nmean(x = c(1, 2, NA, 6), na.rm = TRUE)\n\n[1] 3\n\n\n\n\n\n\nQuestion 3Answer\n\n\nDo Q2 again but rearrange the arguments.\n\n\n\nmean(na.rm = TRUE, x = c(1, 2, NA, 6))\n\n[1] 3\n\n\n\n\n\n\nQuestion 4Answer\n\n\nDo Q2 again using positional matching.\n\n\n\nmean(c(1, 2, NA, 6), 0, TRUE)\n\n[1] 3\n\n\n\n\n\n\nQuestion 5Answer\n\n\nDetermine the class of mean() using class().\n\n\n\nclass(mean)\n\n[1] \"function\"\n\n\nThe class is function.\n\n\n\n\nQuestion 6Answer\n\n\nDetermine the class of mean() using str().\n\n\n\nstr(mean)\n\nfunction (x, ...)  \n\n\nThe class is function.\n\n\n\n\nQuestion 7Answer\n\n\nDetermine the class of the value output in Q4 using class().\n\n\n\nclass(mean(c(1, 2, NA, 6), 0, TRUE))\n\n[1] \"numeric\"\n\n\nThe class is numeric\n\n\n\n\nQuestion 8Answer\n\n\nDetermine the class of the value output in Q4 using str().\n\n\n\nstr(mean(c(1, 2, NA, 6), 0, TRUE))\n\n num 3\n\n\nThe num means the class is numeric.\n\n\n\n\nQuestion 9Answer\n\n\nUse R as a calculator to calculate the following values:\n17^4=?\n45-2*3=?\n(45-2)*3=?\n\n\n\n17^4\n\n[1] 83521\n\n45 - 2 * 3\n\n[1] 39\n\n(45 - 2) * 3\n\n[1] 129"
  },
  {
    "objectID": "functions_practicals1_answers.html#use-the-operators-and-to-do-the-following",
    "href": "functions_practicals1_answers.html#use-the-operators-and-to-do-the-following",
    "title": "18  Functions 1: Answers",
    "section": "18.2 Use the operators %% and %/% to do the following:",
    "text": "18.2 Use the operators %% and %/% to do the following:\n\nQuestion 10Answer\n\n\nCalculate the remainder after dividing 29,079 into 184,277,809.\n\n\n\n184277809 %% 29079\n\n[1] 4186\n\n\n\n\n\n\nQuestion 11Answer\n\n\nHow many times does 29,079 go into 184,277,809 (i.e. what’s the integer divide value)?\n\n\n\n184277809 %/% 29079\n\n[1] 6337\n\n\n\n\n\n\nQuestion 12Answer\n\n\nDo the last calculation from Q8 in another way, like this:\n\na <- 45\nb <- 2\nc <- 3\nd <- (a - b) * c\n\nNow check what a, b, c, and d are. You can just type the variable name (e.g. a) and hit ‘Control+Enter’ or use the command print(a).\n\n\n\na <- 45\nb <- 2\nc <- 3\nd <- (a - b) * c\n\n\na\n\n[1] 45\n\nb\n\n[1] 2\n\nc\n\n[1] 3\n\nd\n\n[1] 129"
  },
  {
    "objectID": "functions_practicals1_answers.html#if-else-and-ifelse-and-vectorization",
    "href": "functions_practicals1_answers.html#if-else-and-ifelse-and-vectorization",
    "title": "18  Functions 1: Answers",
    "section": "18.3 if(), else, and ifelse() and Vectorization",
    "text": "18.3 if(), else, and ifelse() and Vectorization\n\nQuestion 13Anwser\n\n\nWrite a function called ‘evenOrOdd’ involving if and else that takes an argument x and returns “Even” or “Odd” depending on whether or not x is divisible by 2. (Do not use the ifelse() function).\n\n\n\nevenOrOdd <- function(x) {\n  if(x %% 2 == 0) {\n    return(\"Even\")\n  } else {\n    return(\"Odd\")\n  }\n}\n\n\n\n\n\nQuestion 14Answer\n\n\nIs your function ‘evenOrOdd’ vectorized? Check by passing it the vector:\n\nw <- c(3, 6, 6, 4, 7, 9, 11, 6)\n\n\n\n\nevenOrOdd(w)\n\nError in if (x%%2 == 0) {: the condition has length > 1\n\n\nAn error is given, because x in if(x %% 2 == 0) is longer than 1.\n\n\n\n\nQuestion 15Answer\n\n\nAnother way to determine if each element of a vector is even or odd is to use the ifelse() function, which serves as a vectorized version if and else. Use ifelse() to obtain “Even” or “Odd” for each element of w.\n\n\n\nifelse(w %% 2 == 0, \"Even\", \"Odd\")\n\n[1] \"Odd\"  \"Even\" \"Even\" \"Even\" \"Odd\"  \"Odd\"  \"Odd\"  \"Even\""
  },
  {
    "objectID": "functions_practicals1_answers.html#logical-operators-and",
    "href": "functions_practicals1_answers.html#logical-operators-and",
    "title": "18  Functions 1: Answers",
    "section": "18.4 Logical Operators &, |, and !",
    "text": "18.4 Logical Operators &, |, and !\n\nQuestion 16Answer\n\n\nWhat will be the result of the following:\n\n(10 < 20 && 15 < 16) || 9 == 10\n\n\n\n\n(10 < 20 && 15 < 16) || 9 == 10\n\n[1] TRUE\n\n\nTRUE because the first statement (in parentheses) is TRUE and the second is FALSE.\n\n\n\n\nQuestion 17Answer\n\n\nOne of the following evaluates to TRUE, the other to FALSE. Which is which?\n\n4 < 3 && (5 < 6 || 8 < 9)\n\n\n(4 < 3 && 5 < 6) || 8 < 9\n\n\n\n\n4 < 3 && (5 < 6 || 8 < 9)\n\n\n(4 < 3 && 5 < 6) || 8 < 9\n\nThe first one FALSE because the first statement before && is FALSE. The second one is TRUE because one of the two statements to the left and right of || is TRUE\n\n\n\n\nQuestion 18Answer\n\n\nThe data set in ‘BPressure.txt’ contains the systolic and diastolic blood pressure readings for 22 patients.\n\nRead the data from BPressure.txt into a data frame called bp using read.table().\nA person’s blood pressure is classified as normal if the systolic level is below 120 and the diastolic level is below 80. Use relational, and logical operations in square brackets [ ] to extract from bp the rows corresponding to patients with normal blood pressures.\nNow use the same strategy to extract the rows corresponding to patients whose blood pressures aren’t normal.\n\n\n\n\n\n\n\nbp <- read.table(\"Data/BPressure.txt\", header=TRUE)\n\n\n\n\n\nbp[(bp$Systolic < 120 & bp$Diastolic < 80), ]\n\n   PatientID Systolic Diastolic\n2         SS       96        60\n3         FR      100        70\n8         JI      110        40\n9         MC      119        66\n12        KD      108        54\n13        DS      110        50\n17        SB      118        76\n21        EC      112        62\n\n\n\n\n\n\nbp[!(bp$Systolic < 120 & bp$Diastolic < 80), ]\n\n   PatientID Systolic Diastolic\n1         CK      120        50\n4         CP      120        75\n5         BL      140        90\n6         ES      120        70\n7         CP      165       110\n10        FC      125        76\n11        RW      133        60\n14        JW      130        80\n15        BH      120        65\n16        JW      134        80\n18        NS      122        78\n19        GS      122        70\n20        AB      122        78\n22        HH      122        82"
  },
  {
    "objectID": "functions_intro2.html",
    "href": "functions_intro2.html",
    "title": "Functions 2",
    "section": "",
    "text": "Functions are things you can do. R comes with predefined functions which do many things from basic file management to complex statistics. To get started, below are some oft used functions. This default set of functions is easily extended by defining your own functions and adding those defined by others conveniently in CRAN and BioConductor packages:\nhttp://stat.ethz.ch/R-manual/R-patched/library/base/html/00Index.html\nhttp://cran.r-project.org/web/packages/available_packages_by_name.html\nhttp://www.bioconductor.org/packages/release/bioc/\nFunctions are expressed as:\nfunction.name(), e.g., t.test() or, an operator, e.g., +\nEasily obtain functions from other R users using install.packages():\ninstall.packages(\"packageName\", lib = \"/directory/to/my custom R library\", repos = \"http://cran.xl-mirror.nl\")\nThe package name must be quoted when installing. Besides installing the package on your PC, you need to load it into your R session before you can use it:\nlibrary(\"packageName\") ## quotes are optional when loading a package"
  },
  {
    "objectID": "functions_scoping.html",
    "href": "functions_scoping.html",
    "title": "19  Function environments and scoping",
    "section": "",
    "text": "Each function, whether built-in or user-defined, has an associated environment, which can be thought of as a container that holds all of the objects present at the time the function is created.\n\nThe Top-Level (or Global) Environment\nWhen a function is created on the command line, it’s environment is the so-called “Global Environment”:\n\nw <- 2\nf <- function(y) {\n  d <- 3\n  return(d * (w + y))\n}\nenvironment(f)\n\n<environment: R_GlobalEnv>\n\n\nThe function objects() (or ls()), when called from the command line, lists the objects in the Global Environment:\n\nobjects()\n\n[1] \"f\" \"w\"\n\n\n\n\nGlobal and Local Variables\nIn the function f() defined above, the variable w is said to be global to f() and the variable d, because it’s created within f(), is said to be local to f(). Global variables (like w) are visible from within a function, but local variables (like d) aren’t visible from outside the function. In fact, local variables are temporary, and disappear when the function call is completed:\n\nf(y = 1)\nd\n\nYou get an error: Error in eval(expr, envir, enclos) : object ‘d’ not found, indicating that the variable d does not exist in the ‘Global Environment’.\nWhen a global and local variable share the same name, the local variable is used:\n\nw <- 2\nd <- 4\n\nf <- function(y) {\n  d <- 3\n  return(d * (w + y))\n}\n\nf(y = 1)\n\n[1] 9\n\n\nNote also that when an assignment takes place within a function, and the local variable shares its name with an existing global variable, only the local variable is affected:\n\nw <- 2\nd <- 4 # This value of d will remain unchanged.\n\nf <- function(y) {\n  d <- 3 # This doesnt affect the value of d in the global environment\n  return(d * (w + y))\n}\n\nf(y = 1)\n\n[1] 9\n\nd\n\n[1] 4\n\n\n\n\nNested Functions and the Scope Hierarchy\nFor user-defined functions created on the command line, the global variables for that function are those in the global environment. They’re listed by typing ls() (or objects()) on the command line. When a function is created inside another function, its global variables are the local variables of the outer function plus the outer function’s global variables. Regardless of whether a function is created on the command line or inside another function, its local variables are the variables created inside of it plus its formal arguments to which values have been passed\nFor example:\n\nw <- 2 # w is global to f() and therefore also to h()\nf <- function(y) {\n  d <- 3\n  h <- function() {\n    b <- 5 # b is local to h()\n    return(d * (w + y))\n  }\n  return(h())\n}\n\nAbove,\n\nw is a global environment variable to f() and also to h()\ny and d are local variables to f(), but “global” to h()\nb is local to h()\n\nThis scope hierarchy continues when multiple function definitions are nested inside of each other.\nWe can use a print(ls()) statement to see which objects are local to f():\n\nw <- 2 # w is global to f() and therefore also to h()\nf <- function(y) {\n  d <- 3 # y and d are local to f() but global to h()\n  h <- function() {\n    b <- 5 # b is local to h()\n    return(d * (w + y))\n  }\n  print(ls())\n  return(h())\n}\n\nf(y = 2)\n\n[1] \"d\" \"h\" \"y\"\n\n\n[1] 12\n\n\nNote that b is not printed, as it is local to h(), but not to f().\nLikewise we can use a print(environment(h)) statement to view the environment of h():\n\nw <- 2 # w is global to f() and therefore also to h()\nf <- function(y) {\n  d <- 3 # y and d are local to f() but global to h()\n  h <- function() {\n    b <- 5 # b is local to h()\n    return(d * (w + y))\n  }\n  print(environment(h))\n  return(h())\n}\nf(y = 2)\n\n<environment: 0x000001ccbd742350>\n\n\n[1] 12\n\n\nIn the output above, the environment of h() is referred to by its memory location. The environment of h() is the “container” that contains h() as well as the objects d and y."
  },
  {
    "objectID": "functions_decoration.html",
    "href": "functions_decoration.html",
    "title": "20  Decorating a function with returns, errors, and warnings",
    "section": "",
    "text": "The following functions are useful for terminating a function call or just printing a warning message:\n\nreturn()     # Terminate a function call and return a value.\nstop()       # Terminate a function call and print an error message.\nwarning()    # Print a warning message (without terminating the \n             # function call).\n\n\nTerminating a Function Call Using if() and return()\nOne way to terminate a function call is with return() which, when encountered, immediately terminates the call and returns a value. For example:\n\nmySign <- function(x) {\n  if(x < 0) return(\"Negative\")\n  if(x > 0) return(\"Positive\")\n  return(\"Zero\")\n}\n\nPassing mySign() the value x = 13 produces the following:\n\nmySign(x = 13)\n\n[1] \"Positive\"\n\n\n(Note that the last line, return(\"Zero\"), was never encountered during the call to my.sign().)\n\n\nTerminating a Function Call and Printing an Error Message Using if() and stop()\nAnother way to terminate a function call is with stop(), which then prints an error message without returning a value. Here’s an example:\n\nmyRatio <- function(x, y) {\n  if(y == 0) stop(\"Cannot divide by 0\")\n  return(x/y)\n}\n\nAn attempt to pass the value 0 for y now results in the following:\n\nmyRatio(x = 3, y = 0)\n\nError in myRatio(x = 3, y = 0): Cannot divide by 0\n\n\n(Note that the last line, return(x/y), was never encountered during the call to myRatio())\n\n\nPrinting a Warning Message Using if() and warning()\nwarning() just prints a warning message to the screen without terminating the function call. Here’s an example:\n\nmyRatio <- function(x, y) {\n  if(y == 0) warning(\"Attempt made to divide by 0\")\n  return(x/y)\n}\n\nNow when we pass the value 0 for y the function call isn’t terminated (the special value Inf is returned), but we get the warning message:\n\nmyRatio(x = 3, y = 0)\n\nWarning in myRatio(x = 3, y = 0): Attempt made to divide by 0\n\n\n[1] Inf\n\n\nBy adding error messages and warnings to you functions it is easier for you and others using your scripts to figure out what went wrong if your script doesn’t return the anticipated answer."
  },
  {
    "objectID": "functions_looping.html#for-loops",
    "href": "functions_looping.html#for-loops",
    "title": "21  Looping",
    "section": "21.1 for() Loops",
    "text": "21.1 for() Loops\nfor() loops are used when we know in advance how many iterations the loop should perform. The general form of a for() loop is:\n\nfor(i in sequence) {\n  statement1\n  statement2\n  .\n  .\n  .\n  statementq\n}\n\nwhere sequence is a vector, i (whose name you’re free to change) assumes the values in sequence one after another, each time triggering another iteration of the loop during which statements 1 through q are executed. The statements usually involve the variable i.\nHere’s an example. Suppose we have the data frame describing someone’s coin collection:\n\ncoins <- data.frame(Coin = c(\"penny\", \"quarter\", \"nickel\", \"quarter\", \"dime\", \"penny\"),\n                    Year = c(1943, 1905, 1889, 1960, 1937, 1900),\n                    Mint = c(\"Den\", \"SF\", \"Phil\", \"Den\", \"SF\", \"Den\"),\n                    Condition = c(\"good\", \"fair\", \"excellent\", \"good\", \"poor\", \"good\"),\n                    Value = c(12.00, 55.00, 300.00, 40.00, 18.00, 28.00),\n                    Price = c(15.00, 45.00, 375.00, 25.00, 20.00, 20.00))\ncoins\n\n     Coin Year Mint Condition Value Price\n1   penny 1943  Den      good    12    15\n2 quarter 1905   SF      fair    55    45\n3  nickel 1889 Phil excellent   300   375\n4 quarter 1960  Den      good    40    25\n5    dime 1937   SF      poor    18    20\n6   penny 1900  Den      good    28    20\n\n\nIf we type:\n\ncolMeans(coins)\n\nError in colMeans(coins): 'x' must be numeric\n\n\nwe get an error message because some of the columns are non-numeric. We can compute the means of the numeric columns by looping over the columns, each time checking whether it’s numeric before computing it’s mean:\n\nmeans <- NULL\nfor(i in 1:ncol(coins)) {\n  if (is.numeric(coins[ , i])) {\n    means <- c(means, mean(coins[ , i]))\n  }\n}\n\nThe result is:\n\nmeans\n\n[1] 1922.33333   75.50000   83.33333"
  },
  {
    "objectID": "functions_looping.html#looping-over-list-elements",
    "href": "functions_looping.html#looping-over-list-elements",
    "title": "21  Looping",
    "section": "21.2 Looping Over List Elements",
    "text": "21.2 Looping Over List Elements\nIn the next example, we loop over the elements of a list, printing a list element and recording it’s length during each iteration:\n\nmyList <- list(\n  w = c(4, 4, 5, 5, 6, 6),\n  x = c(\"a\", \"b\", \"c\"),\n  y = c(5, 10, 15),\n  z = c(\"r\", \"s\", \"t\", \"u\", \"v\")\n)\n\nlengths <- NULL\n\nfor(i in myList) {\n  print(i)\n  lengths <- c(lengths, length(i))\n}\n\n[1] 4 4 5 5 6 6\n[1] \"a\" \"b\" \"c\"\n[1]  5 10 15\n[1] \"r\" \"s\" \"t\" \"u\" \"v\"\n\nlengths\n\n[1] 6 3 3 5\n\n\nThese examples are very simple, but looping is a very powerful programming structure for automating analyses, or data processing.\nIn the next chapter we will look at the apply() family of functions, that have been designed for applying functions to a data set in several convenient ways."
  },
  {
    "objectID": "functions_apply.html",
    "href": "functions_apply.html",
    "title": "22  Using apply functions",
    "section": "",
    "text": "Once you have written a function, you would like to apply it to some piece of data. As described in the previous chapter you can simply enter some values as arguments of the function and run it. However, usually you would like to run the function on all of your data. To do that you could write a for loop that loops through you data and applies the function to the whole dataset. However, there is a special family of functions in R that make it easier to apply your function to a range of different data classes in different ways. This family of functions are called apply functions.\nThe apply functions make it easier to run functions over vectors, matrixes, and data.frames. We will discuss four functions of the apply family that are regularly used apply(), lapply(), sapply() and tapply().\n\nUsing apply on matrices\nThe apply function works by “applying” a specified function to an data object. It requires 3 arguments: the data, a so-called “MARGIN”, and a function. The data can be a vector, data.frame or a matrix. The MARGIN indicates whether you want to apply the function to the rows or the columns of your data, or both. To apply the function to the rows the MARGIN should be 1, to apply it to the columns it should be 2 and to apply it to both it should be c(1,2). The function can be an existing function, such as sum() or mean(), or your own custom function.\nAs an example we will apply the function max() to some data, in this case a matrix.\nFirst we create a matrix of 10 by 10.\n\nmat <- matrix(1:100,nrow=10)\n\nmat\n\n      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n [1,]    1   11   21   31   41   51   61   71   81    91\n [2,]    2   12   22   32   42   52   62   72   82    92\n [3,]    3   13   23   33   43   53   63   73   83    93\n [4,]    4   14   24   34   44   54   64   74   84    94\n [5,]    5   15   25   35   45   55   65   75   85    95\n [6,]    6   16   26   36   46   56   66   76   86    96\n [7,]    7   17   27   37   47   57   67   77   87    97\n [8,]    8   18   28   38   48   58   68   78   88    98\n [9,]    9   19   29   39   49   59   69   79   89    99\n[10,]   10   20   30   40   50   60   70   80   90   100\n\n\nThen we apply our function “max” to the matrix rows, indicated with a 1 (notice that we do not run the function by writing max(), but we just give the name of the function that should be run: max).\n\napply(mat, 1, max)\n\n [1]  91  92  93  94  95  96  97  98  99 100\n\n\nThe result of applying the function max to the rows of the matrix is a vector containing the maximal values for each row.\nWe can also determine the maximal value in each column by using 2 as the MARGIN value.\n\napply(mat, 2, max)\n\n [1]  10  20  30  40  50  60  70  80  90 100\n\n\nAs mentionned before, it is also possible to apply the functions to each element in the matrix by using c(1,2). In that case it doesn’t make sense to determine the maximum value, so lets take the square root.\n\napply(mat, c(1,2), sqrt)\n\n          [,1]     [,2]     [,3]     [,4]     [,5]     [,6]     [,7]     [,8]\n [1,] 1.000000 3.316625 4.582576 5.567764 6.403124 7.141428 7.810250 8.426150\n [2,] 1.414214 3.464102 4.690416 5.656854 6.480741 7.211103 7.874008 8.485281\n [3,] 1.732051 3.605551 4.795832 5.744563 6.557439 7.280110 7.937254 8.544004\n [4,] 2.000000 3.741657 4.898979 5.830952 6.633250 7.348469 8.000000 8.602325\n [5,] 2.236068 3.872983 5.000000 5.916080 6.708204 7.416198 8.062258 8.660254\n [6,] 2.449490 4.000000 5.099020 6.000000 6.782330 7.483315 8.124038 8.717798\n [7,] 2.645751 4.123106 5.196152 6.082763 6.855655 7.549834 8.185353 8.774964\n [8,] 2.828427 4.242641 5.291503 6.164414 6.928203 7.615773 8.246211 8.831761\n [9,] 3.000000 4.358899 5.385165 6.244998 7.000000 7.681146 8.306624 8.888194\n[10,] 3.162278 4.472136 5.477226 6.324555 7.071068 7.745967 8.366600 8.944272\n          [,9]     [,10]\n [1,] 9.000000  9.539392\n [2,] 9.055385  9.591663\n [3,] 9.110434  9.643651\n [4,] 9.165151  9.695360\n [5,] 9.219544  9.746794\n [6,] 9.273618  9.797959\n [7,] 9.327379  9.848858\n [8,] 9.380832  9.899495\n [9,] 9.433981  9.949874\n[10,] 9.486833 10.000000\n\n\nBecause sqrt also works on matrices, it is actually unnecessary to use apply to run it for each element in the matrix. In cases where functions cannot directly be run on a matrix, apply offers a short and readible alternative to writing a nested for loop.\n\n\nUsing lapply on lists to return lists\nThe lapply function is used to run a function on list objects. Let’s assume we have a list of different sized matrices and we would like to know the dimensions of these matrices. We can then run the function “dim” on the list using lapply. lapply only requires a list object and a function as arguments and always returns a list of results.\n\nmylist <- list(matrix(1:16,nrow=4), matrix(1:9,nrow=3),matrix(1:4,nrow=2))\n\nlapply(mylist, dim)\n\n[[1]]\n[1] 4 4\n\n[[2]]\n[1] 3 3\n\n[[3]]\n[1] 2 2\n\n\nBecause dataframes are lists of lists, it is also possible to run lapply on dataframes. In that case lapply will apply the function to the columns of the data.frame object and it returns a list of values.\n\ndf <- data.frame(\"col1\"=c(1,1,1,1), \"col2\"=c(2,2,2,2), \"col3\"=c(3,3,3,3))\n\nlapply(df, sum)\n\n$col1\n[1] 4\n\n$col2\n[1] 8\n\n$col3\n[1] 12\n\n\n\n\nUsing lapply alternative sapply\nsapply is a user-friendly version of lapply. The difference with lapply is that sapply tries to turn the list of results into a more user-friendly format, such as a vector or a matrix.\nFor the first example the results are turned into a matrix.\n\nsapply(mylist, dim)\n\n     [,1] [,2] [,3]\n[1,]    4    3    2\n[2,]    4    3    2\n\n\nFor the second example, the results are turned into a vector.\n\nsapply(df, sum)\n\ncol1 col2 col3 \n   4    8   12 \n\n\nThere is no difference between lapply and sapply in how the data is used, but it gives you more flexibility in how the results are created.\n\n\nUsing tapply on groups of data\ntapply lets you apply a function on groupings of your data. Imagine that you have a dataset in which a grouping factor separates your data into two groups of patients. With tapply you can apply a function to those two groups separately. The only thing tapply requires is the column you would like to apply the function to, the grouping factor and the function you would like to apply.\n\npatients <- data.frame(\"group\"=paste('grp',c(1,1,1,1,1,1,2,2,2,2,2,2),sep='-'), \"outcome\"=rnorm(12))\npatients\n\n   group     outcome\n1  grp-1 -0.64695462\n2  grp-1 -0.07898993\n3  grp-1  1.25278157\n4  grp-1 -0.79867922\n5  grp-1 -0.88513122\n6  grp-1 -0.70290872\n7  grp-2 -1.98243795\n8  grp-2 -1.71847206\n9  grp-2 -1.02435321\n10 grp-2  1.95638719\n11 grp-2  0.57480933\n12 grp-2  0.26020285\n\ntapply(patients$outcome, patients$group, mean)\n\n     grp-1      grp-2 \n-0.3099804 -0.3223106 \n\n\nIt is also possible to use multiple factors in a list to create groups, which returns a matrix.\n\npatients <- data.frame(\"group\"=paste('grp',c(1,1,1,1,1,1,2,2,2,2,2,2),sep='-'),\n                       \"serotype\"=c(\"A\",\"B\",\"A\",\"B\",\"A\",\"B\",\"A\",\"B\",\"A\",\"B\",\"A\",\"B\"),\n                       \"outcome\"=rnorm(12))\n\ntapply(patients$outcome, list(patients$group, patients$serotype), mean)\n\n               A          B\ngrp-1 -0.6541681 -0.3428128\ngrp-2  0.6882501  0.0619898\n\n\nThese are some (trivial) examples of how you can use the apply family of functions to quickly apply a function to your data. It is possible to do the same thing by using for loops, but apply functions are generally faster to write and read. In some cases using apply to run your function can also increase the speed of your code. More on increasing the speed of your code will follow in later lectures."
  },
  {
    "objectID": "functions_practicals2_questions.html#function-environment-and-scoping",
    "href": "functions_practicals2_questions.html#function-environment-and-scoping",
    "title": "23  Functions 2: Questions",
    "section": "23.1 Function environment and scoping",
    "text": "23.1 Function environment and scoping\n\nQuestion 1\n\n\nFor each of the following sets of commands, give the value that will be returned by the last command. Try to answer without using R.\n\n\n\n\nw <- 5\nf <- function(y) {\n  return(w + y)\n}\nf(y = 2)\n\n\n\n\n\nw <- 5\nf <- function(y) {\n  w <- 4\n  return(w + y)\n}\nf(y = 2)\n\n\n\n\n\nQuestion 2\n\n\nAmong the variables w, d, and y, which are global to f() and which are local? What is the value of z when executing f(w)\n\nw <- 2\nf <- function(y) {\n  d <- 3\n  h <- function(z) {\n    return(z + d)\n  }\n  return(y * h(y))\n}\n\n\n\n\n\nQuestion 3\n\n\nDo the following in R:\n\nTry:\n\n\nmyFun1 <- function(a) {\n  b <- 3\n  myFun2(a)\n}\n\nmyFun2 <- function(y) {\n  return(y + a + b)\n}\n\nmyFun1(10)\n\nWhat happens?\n\nNow try:\n\n\na <- 1\nb <- 2\nmyFun1(10)\n\nWhat happens?"
  },
  {
    "objectID": "functions_practicals2_questions.html#decorating-a-function-with-returns-errors-and-warnings",
    "href": "functions_practicals2_questions.html#decorating-a-function-with-returns-errors-and-warnings",
    "title": "23  Functions 2: Questions",
    "section": "23.2 Decorating a function with returns, errors, and warnings",
    "text": "23.2 Decorating a function with returns, errors, and warnings\nThe functions warning() and stop() are used to print a warning message and to stop the execution of the function call and print an error message. For example:\n\nnoNegMean <- function(x) {\n  if(all(x < 0)) {\n    stop(\"All values in x are negative\")\n  }\n  \n  if(any(x < 0)) {\n    x[x < 0] <- 0\n    warning(\"Negative values in x replaced by zero\")\n  }\n  \n  return(mean(x))\n}\n\n\nQuestion 1\n\n\nCopy the above code and then pass noNegMean() a vector containing some negative and some positive values. What happens?\n\n\n\n\nQuestion 2\n\n\nWhat happens when you pass noNegMean() a vector containing all negative values?\n\n\n\n\nQuestion 3\n\n\nWrite a function ratio() that takes two arguments, x and y, and attempts to compute the ratio x/y.\nIf both x == 0 & y == 0, the function should stop and print an error message about dividing 0 by 0.\nIf y == 0 (but not x), the function should print a warning message about dividing by 0, and then return x/y (which will be Inf).\nIn all other cases, it should return x/y.\nTest your ratio() function first using two nonzero values for x and y, then using a nonzero x but y = 0, and finally using x = 0 and y = 0."
  },
  {
    "objectID": "functions_practicals2_questions.html#looping-using-for-loops-and-the-apply-functions",
    "href": "functions_practicals2_questions.html#looping-using-for-loops-and-the-apply-functions",
    "title": "23  Functions 2: Questions",
    "section": "23.3 Looping using for() loops and the apply functions",
    "text": "23.3 Looping using for() loops and the apply functions\n\nQuestion 1\n\n\nCopy this is a function to determine if a number is a prime number:\n\nisPrime <- function(num){\n  if (num == 2) {\n    return(TRUE)\n  }\n  if(num > 1) {\n    for(i in 2:(num-1)) {\n      if ((num %% i) == 0) {\n        return(FALSE)\n      }\n    }\n  } else {\n    return(FALSE)\n  }\n  \n  return(TRUE)\n}\n\nCopy this matrix for which we would like to check if a number is a prime number:\n\nmat <- matrix(1:100, nrow=10)\n\nUse the apply() function to calculate the prime number for each number in the matrix.\nWhat numbers from 1 until 100 are prime numbers?\n\n\n\n\nQuestion 2\n\n\nCopy the following command to create a list containing two generations of the famous Kennedy family:\n\nKennedys <- list(\n    JosephJr = character(0),\n    John = c(\"Caroline\", \"JohnJr\", \"Patrick\"),\n    Rosemary = character(0),\n    Kathleen = character(0),\n    Eunice = c(\"RobertIII\", \"Maria\", \"Timothy\", \"Mark\", \"Anthony\"),\n    Patricia = c(\"Christopher\", \"Sydney\", \"Victoria\", \"Robin\"),\n    Robert = c(\"Kathleen\", \"JosephII\", \"RobertJr\", \"David\", \n               \"MaryC\", \"Michael\", \"MaryK\", \"Christopher\", \n               \"Matthew\", \"Douglas\", \"Rory\"),\n    Jean = c(\"Stephen\", \"William\", \"Amanda\", \"Kym\"),\n    Edward = c(\"Kara\", \"EdwardJr\", \"Patrick\")\n)\n\nUse a for() loop to loop over the list of the first generation of Kennedys, keeping track of how many children each one has in a vector.\n\n\n\n\nQuestion 3\n\n\nNow, using the lapply() function, loop over the list of the first generation of Kennedys and keep track of how many children each Kennedy has. What is the class of the output?\n\n\n\n\nQuestion 3\n\n\nAnswer Q2 again using the sapply() function. What is the class of the output?\n\n\n\n\nQuestion 4\n\n\nLoad the “diamonds” dataset from the ggplot2 package by running library(gglot2) and calculate the average price of diamonds by color and clarity using the tapply() function."
  },
  {
    "objectID": "functions_practicals2_answers.html#function-environment-and-scoping",
    "href": "functions_practicals2_answers.html#function-environment-and-scoping",
    "title": "24  Functions 2: Answers",
    "section": "24.1 Function environment and scoping",
    "text": "24.1 Function environment and scoping\n\nQuestion 1Answer\n\n\nFor each of the following sets of commands, give the value that will be returned by the last command. Try to answer without using R.\n\n\n\n\nw <- 5\nf <- function(y) {\n  return(w + y)\n}\nf(y = 2)\n\n\n\n\n\nw <- 5\nf <- function(y) {\n  w <- 4\n  return(w + y)\n}\nf(y = 2)\n\n\n\n\nThis will return 7 because w is 5 and we are evaluating the function at y = 2\nThis will return 6 because w is reassigned as 4 inside the function and we are evaluating the function at y = 2.\n\n\n\n\n\nQuestion 2Answer\n\n\nAmong the variables w, d, and y, which are global to f() and which are local? What is the value of z when executing f(w)\n\nw <- 2\nf <- function(y) {\n  d <- 3\n  h <- function(z) {\n    return(z + d)\n  }\n  return(y * h(y))\n}\n\n\n\nThe object w is global to f() while d and y are local to f().\nz is 2, because it takes the value of y when executing h(y) in function f(), which takes the value of global variable w when executing f(w)\n\n\n\n\nQuestion 3Answer\n\n\nDo the following in R:\n\nTry:\n\n\nmyFun1 <- function(a) {\n  b <- 3\n  myFun2(a)\n}\n\nmyFun2 <- function(y) {\n  return(y + a + b)\n}\n\nmyFun1(10)\n\nWhat happens?\n\nNow try:\n\n\na <- 1\nb <- 2\nmyFun1(10)\n\nWhat happens?\n\n\n\nWe get an error message because a and b are local to myFun1 so the function myFun2 can’t find them in the global environment.\nWe get get the value 13 because the values a and b are global so myFun2 can find them and use them in its commands."
  },
  {
    "objectID": "functions_practicals2_answers.html#decorating-a-function-with-returns-errors-and-warnings",
    "href": "functions_practicals2_answers.html#decorating-a-function-with-returns-errors-and-warnings",
    "title": "24  Functions 2: Answers",
    "section": "24.2 Decorating a function with returns, errors, and warnings",
    "text": "24.2 Decorating a function with returns, errors, and warnings\nThe functions warning() and stop() are used to print a warning message and to stop the execution of the function call and print an error message. For example:\n\nnoNegMean <- function(x) {\n  if(all(x < 0)) {\n    stop(\"All values in x are negative\")\n  }\n  \n  if(any(x < 0)) {\n    x[x < 0] <- 0\n    warning(\"Negative values in x replaced by zero\")\n  }\n  \n  return(mean(x))\n}\n\n\nQuestion 1Answer\n\n\nCopy the above code and then pass noNegMean() a vector containing some negative and some positive values. What happens?\n\n\n\nnoNegMean(c(-1,0,1))\n\nWarning in noNegMean(c(-1, 0, 1)): Negative values in x replaced by zero\n\n\n[1] 0.3333333\n\n\nWe get the warning message and it returned 0.3333, which is the average of c(0, 0, 1).\n\n\n\n\nQuestion 2Answer\n\n\nWhat happens when you pass noNegMean() a vector containing all negative values?\n\n\n\nnoNegMean(c(-1,-1,-1))\n\nError in noNegMean(c(-1, -1, -1)): All values in x are negative\n\n\nWe get the error message and nothing is returned.\n\n\n\n\nQuestion 3Answer\n\n\nWrite a function ratio() that takes two arguments, x and y, and attempts to compute the ratio x/y.\nIf both x == 0 & y == 0, the function should stop and print an error message about dividing 0 by 0.\nIf y == 0 (but not x), the function should print a warning message about dividing by 0, and then return x/y (which will be Inf).\nIn all other cases, it should return x/y.\nTest your ratio() function first using two nonzero values for x and y, then using a nonzero x but y = 0, and finally using x = 0 and y = 0.\n\n\n\nratio <- function(x,y) {\n  if(x == 0 & y == 0) {\n    stop(\"Cannot divide zero by zero.\")\n  }\n\n  if(y == 0) {\n    warning(\"Cannot divide by zero.\")\n  }\n\n  ratio <- x/y\n  return(ratio)\n}\n\n\nratio(2,3)\n\n[1] 0.6666667\n\nratio(0,0)\n\nError in ratio(0, 0): Cannot divide zero by zero.\n\nratio(1,0)\n\nWarning in ratio(1, 0): Cannot divide by zero.\n\n\n[1] Inf"
  },
  {
    "objectID": "functions_practicals2_answers.html#looping-using-for-loops-and-the-apply-functions",
    "href": "functions_practicals2_answers.html#looping-using-for-loops-and-the-apply-functions",
    "title": "24  Functions 2: Answers",
    "section": "24.3 looping using for() loops and the apply functions",
    "text": "24.3 looping using for() loops and the apply functions\n\nQuestion 1Answer\n\n\nCopy this is a function to determine if a number is a prime number:\n\nisPrime <- function(num){\n  if (num == 2) {\n    return(TRUE)\n  }\n  if(num > 1) {\n    for(i in 2:(num-1)) {\n      if ((num %% i) == 0) {\n        return(FALSE)\n      }\n    }\n  } else {\n    return(FALSE)\n  }\n  \n  return(TRUE)\n}\n\nCopy this matrix for which we would like to check if a number is a prime number:\n\nmat <- matrix(1:100, nrow=10)\n\nUse the apply() function to calculate the prime number for each number in the matrix.\nWhat numbers from 1 until 100 are prime numbers?\n\n\n\napply(mat, c(1,2), isPrime)\n\n       [,1]  [,2]  [,3]  [,4]  [,5]  [,6]  [,7]  [,8]  [,9] [,10]\n [1,] FALSE  TRUE FALSE  TRUE  TRUE FALSE  TRUE  TRUE FALSE FALSE\n [2,]  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n [3,]  TRUE  TRUE  TRUE FALSE  TRUE  TRUE FALSE  TRUE  TRUE FALSE\n [4,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n [5,]  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n [6,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n [7,]  TRUE  TRUE FALSE  TRUE  TRUE FALSE  TRUE FALSE FALSE  TRUE\n [8,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n [9,] FALSE  TRUE  TRUE FALSE FALSE  TRUE FALSE  TRUE  TRUE FALSE\n[10,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n\n\n\nmat[apply(mat, c(1,2), isPrime)]\n\n [1]  2  3  5  7 11 13 17 19 23 29 31 37 41 43 47 53 59 61 67 71 73 79 83 89 97\n\n\n\n\n\n\nQuestion 2Answer\n\n\nCopy the following command to create a list containing two generations of the famous Kennedy family:\n\nKennedys <- list(\n    JosephJr = character(0),\n    John = c(\"Caroline\", \"JohnJr\", \"Patrick\"),\n    Rosemary = character(0),\n    Kathleen = character(0),\n    Eunice = c(\"RobertIII\", \"Maria\", \"Timothy\", \"Mark\", \"Anthony\"),\n    Patricia = c(\"Christopher\", \"Sydney\", \"Victoria\", \"Robin\"),\n    Robert = c(\"Kathleen\", \"JosephII\", \"RobertJr\", \"David\", \n               \"MaryC\", \"Michael\", \"MaryK\", \"Christopher\", \n               \"Matthew\", \"Douglas\", \"Rory\"),\n    Jean = c(\"Stephen\", \"William\", \"Amanda\", \"Kym\"),\n    Edward = c(\"Kara\", \"EdwardJr\", \"Patrick\")\n)\n\nUse a for() loop to loop over the list of the first generation of Kennedys, keeping track of how many children each one has in a vector.\n\n\n\nchildren <- NULL\nfor(i in Kennedys){\n  children <- c(children, length(i))\n}\nchildren\n\n[1]  0  3  0  0  5  4 11  4  3\n\n\n\n\n\n\nQuestion 3Answer\n\n\nNow, using the lapply() function, loop over the list of the first generation of Kennedys and keep track of how many children each Kennedy has. What is the class of the output?\n\n\n\nresult <- lapply(Kennedys, length)\nresult\n\n$JosephJr\n[1] 0\n\n$John\n[1] 3\n\n$Rosemary\n[1] 0\n\n$Kathleen\n[1] 0\n\n$Eunice\n[1] 5\n\n$Patricia\n[1] 4\n\n$Robert\n[1] 11\n\n$Jean\n[1] 4\n\n$Edward\n[1] 3\n\nclass(result)\n\n[1] \"list\"\n\n\n\n\n\n\nQuestion 4Answer\n\n\nAnswer Q2 again using the sapply() function. What is the class of the output?\n\n\n\nresult <- sapply(Kennedys, length)\nresult\n\nJosephJr     John Rosemary Kathleen   Eunice Patricia   Robert     Jean \n       0        3        0        0        5        4       11        4 \n  Edward \n       3 \n\nclass(result)\n\n[1] \"integer\"\n\n\n\n\n\n\nQuestion 5Answer\n\n\nLoad the “diamonds” dataset from the ggplot2 package by running library(gglot2) and calculate the average price of diamonds by color and clarity using the tapply() function.\n\n\n\nlibrary(ggplot2)\ntapply(diamonds$price, list(diamonds$color, diamonds$clarity), mean)\n\n        I1      SI2      SI1      VS2      VS1     VVS2     VVS1       IF\nD 3863.024 3931.101 2976.146 2587.226 3030.159 3351.128 2947.913 8307.370\nE 3488.422 4173.826 3161.838 2750.942 2856.294 2499.674 2219.820 3668.506\nF 3342.182 4472.625 3714.226 3756.795 3796.718 3475.513 2804.277 2750.836\nG 3545.693 5021.684 3774.787 4416.256 4131.362 3845.283 2866.821 2558.034\nH 4453.414 6099.895 5032.415 4722.414 3780.689 2649.067 1845.658 2287.870\nI 4302.185 7002.649 5355.020 5690.506 4633.184 2968.233 2034.862 1994.937\nJ 5254.060 6520.958 5186.048 5311.059 4884.461 5142.397 4034.176 3363.882"
  },
  {
    "objectID": "basic_markdown.html#reproducible-research",
    "href": "basic_markdown.html#reproducible-research",
    "title": "25  Basic Markdown",
    "section": "25.1 Reproducible research",
    "text": "25.1 Reproducible research\nAn analysis is reproducible when all information is available (for somebody) to do your analysis and obtain the same results. This includes the data, code and the documentation. This somebody else can even be your future self.\nWhen data is reproducible it makes it easier to go back and figure out what you did, perform checks and make adjustments. It also makes collaboration with other people easier.\nThere are some software tools that make it easier to do your amalyses in a reproducible way. In this course, we will talk about Quatro and Git.\nQuatro is a program that allows you to combine code and documentation in a single text document. The code is then run and included in the document which is then converted an output format. There are many different options for the output format and they include such things as a pdf, an html file or a word-document."
  },
  {
    "objectID": "basic_markdown.html#markdown",
    "href": "basic_markdown.html#markdown",
    "title": "25  Basic Markdown",
    "section": "25.2 Markdown",
    "text": "25.2 Markdown\nQuatro files consist of code and markdown. We have discussed how to code in the previous chapters and will discuss markdown here. Markdown is a specific kind of markup language. What we mean by that is that the text in the document also indicates how it should be formatted in the result (For example if we surround a word by double asterikses (like so **bold**) it will bold in the resulting output. Below we will discuss the different types of markup that you can use.\n\nBasic Formatting\n\n\n\n\nSyntax\nOutput\n\n\n\n\n*italics*\nitalics\n\n\n**bold**\nbold\n\n\n***bold italics***\nbold italics\n\n\nsubscript~2~\nsubscript2\n\n\nsuperscript^2^\nsuperscript2\n\n\n~~crossed out~~\ncrossed out\n\n\n`code`\ncode\n\n\n\n\n\n\nHeadings\n\n\n\n\n\n\n\nSyntax\nOutput\n\n\n\n\n# Header 1\n26 Header 1\n\n\n## Header 2\n26.1 Header 2\n\n\n### Header 3\nHeader 3\n\n\n#### Header 4\nHeader 4\n\n\n##### Header 5\nHeader 5\n\n\n###### Header 6\nHeader 6\n\n\n\n\n\n\nLinks\n\n\n\n\nSyntax\nOutput\n\n\n\n\n<https://www.erasmusmc.nl>\nhttps://www.erasmusmc.nl\n\n\n[EMC](https://www.erasmusmc.nl)\nEMC\n\n\n\n\n\n\nImages\n\n\n\n\n\n\n\n\nSyntax\nOutput\n\n\n\n\n![Caption](Logo.svg)\n\n\n\n![Caption](Logo.svg) “hovertext”\n\n\n\n![Caption](Logo.svg){fig-alt=“Alt text”}\n\n\n\n\n\nIt is also possible to include images in links.\n\n\nLists\n\n\n\n\n\n\n\nMarkdown Syntax\nOutput\n\n\n\n\n* item 1\n* item 2\n    + sub-item 1\n    + sub-item 2\n        - sub-sub-item 1\n\nitem 1\nitem 2\n\nsub-item 1\nsub-item 2\n\nsub-sub-item 1\n\n\n\n\n\n*   item 2\n\n    Part of item (Extra spaces)\n\nitem 2\nPart of item (Extra spaces)\n\n\n\n1. ordered list\n2. item 2\n    i) sub-item 1\n    ii) sub-item 2\n         A.  etc.\n\nordered list\nitem 2\n\nsub-item 1\nsub-item 1\n\nA.  etc.\n\n\n\n\n\n\nTables\nThere are multiple ways to make tables\nThe easiest way is to use a so called pipe-table like this:\n | foo|  bar  | Left align | Right Align | Center |\n |----|-------|:-----------|------------:|:------:|\n | 1  |    2  | 1  |    2  | 1|  \n | 3  |    4  |3  |    4  | 4 |\n \n : an optional caption\nThe result is:\n\nan optional caption\n\n\nfoo\nbar\nLeft align\nRight Align\nCenter\n\n\n\n\n1\n2\n1\n2\n1\n\n\n3\n4\n3\n4\n4\n\n\n\nThe first and last pipe character at each row are optional, the ones separating the columns are not although they do not have to be aligned. The header cannot be omited. The relative width is determined by the number of dashes.\nAn alternative way to specify the relative column widths is by including the attribyte after the caption, like this:\n: an optional caption {tbl-colwidths=\"[40,15,15,15,15]\"} \nSometimes it is easiest to directly make the tables from R code.\n\nSource code\nYou can use delimited blocks with three backticks to use source code formatting. The syntax:\n````\nfoo <- bar\n````\nBecomes:\nfoo <- bar\nIt is possible to add an R to indicate the R language is used and apply apropriate highlighting:\n``` R\nfoo <- bar\n```\nBecomes:\nfoo <- bar\n\n\n\nMath\nYou can use TeX like syntax to format equations. Inline formulas are delimeted by single $s and display math uses double $$s.\n\n\n\n\nSyntax\nOutput\n\n\n\n\n$a2=b2+c^2$\n\\(a^2=b^2+c^2\\)\n\n\n$$a2=b2+c^2$$\n\\[a^2=b^2+c^2\\]"
  },
  {
    "objectID": "basic_markdown_practicals_questions.html",
    "href": "basic_markdown_practicals_questions.html",
    "title": "26  Markdown: Questions",
    "section": "",
    "text": "We are going to do an analysis in R using quatro to produce an html file that contains both the code and the results. To help you on your way you can use the file practicaltemplate.qmd that you can find on Canvas.\n\nQuestion 1\n\n\nWe are going to explore the build-in data set ‘ToothGrowth’ that is beging loaded in the setup chuck of the template document. In the second chunk we create histograms for the length of the teeth given the dose and the supplement given. If needed go back to the chapter about creating plots to find information on how to do this.\n\n\n\n\nQuestion 2\n\n\nWe focus on the Guinea pigs that received 2 mg of Vitamin C by either delivery method. Create a new data frame that makes the appropriate selection. What is are the mean and median tooth lengths?\n\n\n\n\nQuestion 3\n\n\nUse a statistical test to compare the tooth lengths between delivery methods (still focusing on the highest dose).\n\n\n\n\nQuestion 4\n\n\nNow adjust the text the text of the document to explain what you have done and state your conclusions. Use bold text to indicate the most important points. Use a mathematical formula to state the null hypothesis of your test.\n\n\n\n\nQuestion 5\n\n\nRender the html document. Now change the html header to also generate a pdf.\n\n\n\n\nQuestion 6\n\n\nChange the markdown so the output from the setup chunk is not shown in the output document."
  },
  {
    "objectID": "codeblocks.html#introduction",
    "href": "codeblocks.html#introduction",
    "title": "27  Code Blocks",
    "section": "27.1 Introduction",
    "text": "27.1 Introduction\nThe main feature of quarto is that we can interweave the text with code blocks. These code blocks are the point of discussion of this section."
  },
  {
    "objectID": "codeblocks.html#code-blocks",
    "href": "codeblocks.html#code-blocks",
    "title": "27  Code Blocks",
    "section": "27.2 Code blocks",
    "text": "27.2 Code blocks\nWhen we include a code block (also called chunk) we start by writing three back ticks (```) followed by the name of the language you use in the code block (we will only use R) surrounded with braces. The chunk again is ended by writing three back ticks. So the whole thing looks like this\n```{r}\n1 + 1\n```\nOptionally you can also include a chunk name after the name of the language. This helps if there are any errors as the chunk name will be included in the error message. Additionally figures that are created within the code will use the chunk name in the name of the figure.\n```{r examplename}\nBy default, when the document is rendered the code in the chunks will be executed and both the contents of the code block as the output will be included in the document. Execution of the code, insertion of the code and insertion of the output can be suppressed by so-called chunk options (see below). A given document can include menu code chunks that all will be executed in order. Variables that are defined in a certain code block can be used in the following ones, just as if the code would have formed a single R-script."
  },
  {
    "objectID": "codeblocks.html#chunk-options",
    "href": "codeblocks.html#chunk-options",
    "title": "27  Code Blocks",
    "section": "27.3 Chunk Options",
    "text": "27.3 Chunk Options\nIt is possible to modify the behavior of how the code blocks are executed. This is done by including special comments at the top of the code blocks. Alternatively we can include them between the braces. That is we can either write\n```{r}\n#| echo: false\n\n# some code\n\n```\nor\n```{r echo=FALSE}\n\n# some code\n\n```\nSome options that are often used are:\n\neval\n\nwhen TRUE (the default) the code is evaluated when FALSE it is not\n\necho\n\nwhen TRUE (default) the source is displayed in the output decument. When it is FALSE it is not.\n\nresults\n\nspecifies how the resuls are displayed. When it is ‘markup’ it is displayed as a code-block. When it is asis it will not be modified. A situation in which this is convinient when the R functions formats its output in html. When ‘hide’ or FALSE the results are not shown at all.\n\nwarning\n\nwhen FALSE, all warnings will be suppressed\n\nmessage\n\nwhen FALSE, all messages (printed by the message function) will be suppressed\n\ninclude\n\nWhen TRUE the output is shown in the document when FALSE all output is suppressed but the code is still executed\n\nfile\n\nthe code content is read from an external file that is named in the option\n\nchild\n\nthe content of an external file is inserted in place"
  },
  {
    "objectID": "codeblocks.html#inline-code",
    "href": "codeblocks.html#inline-code",
    "title": "27  Code Blocks",
    "section": "27.4 Inline code",
    "text": "27.4 Inline code\nBeside complete code blocks it is also possible to include short bits of R code in the running text. The code should be included between `r and ` , for example `r nrow(data_set)`."
  },
  {
    "objectID": "codeblocks.html#yaml-header",
    "href": "codeblocks.html#yaml-header",
    "title": "27  Code Blocks",
    "section": "27.5 YAML header",
    "text": "27.5 YAML header\nEach markdown document starts with a header that specifies such things as the title, author, date and output format. For example\n---\ntitle: \"My document\"\nauthor: \"Sten Willemsen\"\ndate: \"21 May 2023\"\nformat: html\n---\nBesides html we can also create word documents by using output: docx and pdf documents by specifying output: pdf. The last option requires TeX to be installed."
  },
  {
    "objectID": "tidyverse.html#introduction",
    "href": "tidyverse.html#introduction",
    "title": "28  Tidyverse",
    "section": "28.1 Introduction",
    "text": "28.1 Introduction\nThe so called tidyverse is a collection of connected R-packages that are created by the same people that also made R-studio. You have already seen one of these packages: ggplot. Like ggplot, many of these packages do things that could, in principle, also be done in base R but in a may that some people find more intuitive. Because these packages are so and general popular it may well well happen that when you try to find something R-related on the internet you find a solution using the tidyverse. For this reason we give a short introduction to the tidyverse here."
  },
  {
    "objectID": "tidyverse.html#tibble",
    "href": "tidyverse.html#tibble",
    "title": "28  Tidyverse",
    "section": "28.2 tibble",
    "text": "28.2 tibble\nThe package tibble provides the tibble class and some functions to work with this class. A tibble is an alternative to a data.frame and is mostly (but not completely) compatible with this class. The most important differences are the following: Unlike a data.frame a tibble does not use row names. When a single column is selected from a data.frame using [,] the result is converted to a vector. This does not happen with a tibble. Finally, when a tibble is printed only a few rows and columns are shown. tibble is an important package because most other tidyverse packages use tibbles."
  },
  {
    "objectID": "tidyverse.html#dplyr",
    "href": "tidyverse.html#dplyr",
    "title": "28  Tidyverse",
    "section": "28.3 dplyr",
    "text": "28.3 dplyr\nThe dplyr package provides new methods to do data manipulation. It also provides the so-called pipe operator %>% that takes the output of a function on the left-hand-side and uses it as input for a function on the right (by default as the fist argument). This often can make long sequences of transformations much more readable.\n\nlibrary(dplyr)\n\nWarning: package 'dplyr' was built under R version 4.2.3\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nstarwars %>% \n  select(mass, height, gender, homeworld) %>% \n  group_by(gender, homeworld) %>% \n  filter(mass > mean(mass, na.rm = TRUE)) %>% \n  summarise(min_height=min(height,na.rm = TRUE), n=n())\n\n`summarise()` has grouped output by 'gender'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 7 × 4\n# Groups:   gender [2]\n  gender    homeworld min_height     n\n  <chr>     <chr>          <int> <int>\n1 feminine  Mirial           170     1\n2 masculine Corellia         180     1\n3 masculine Kamino           229     1\n4 masculine Kashyyyk         234     1\n5 masculine Naboo            170     3\n6 masculine Tatooine         178     2\n7 masculine <NA>             193     2"
  },
  {
    "objectID": "tidyverse.html#readr",
    "href": "tidyverse.html#readr",
    "title": "28  Tidyverse",
    "section": "28.4 readr",
    "text": "28.4 readr\nA package to read text files, mostly much faster than base R does."
  },
  {
    "objectID": "tidyverse.html#purrr",
    "href": "tidyverse.html#purrr",
    "title": "28  Tidyverse",
    "section": "28.5 purrr",
    "text": "28.5 purrr\nThe package purrr makes functional programming with R easier. That is it contains methods that apply functions to the elements of lists or otherwise work with lists and functions. An example is shown below:\n\nlibrary(dplyr)\nlibrary(purrr)\n\nWarning: package 'purrr' was built under R version 4.2.3\n\ndata(\"ToothGrowth\")\nToothGrowth %>% \n  split(.$supp) %>% \n  map(function(x) lm(len ~ dose, data=x)) %>% \n  map(coef) %>% \n  bind_rows()\n\n# A tibble: 2 × 2\n  `(Intercept)`  dose\n          <dbl> <dbl>\n1         11.5   7.81\n2          3.29 11.7"
  },
  {
    "objectID": "tidyverse.html#forcats",
    "href": "tidyverse.html#forcats",
    "title": "28  Tidyverse",
    "section": "28.6 forcats",
    "text": "28.6 forcats\nThis package makes working with factors easier."
  },
  {
    "objectID": "tidyverse.html#stringr",
    "href": "tidyverse.html#stringr",
    "title": "28  Tidyverse",
    "section": "28.7 stringr",
    "text": "28.7 stringr\nThe stringr package helps you ro work with character data (strings). It does things like merging and splitting and otherwise manipulating character variables and finding and selecting substrings in larger strings."
  },
  {
    "objectID": "tidyverse.html#tidyr",
    "href": "tidyverse.html#tidyr",
    "title": "28  Tidyverse",
    "section": "28.8 tidyr",
    "text": "28.8 tidyr\nThe tidyr package can be used to make data.frames or tibbles ‘tidy’. That is make sure it is organised in a way so that each variable is in a column of its own and each observation has a separate row. This is the format that is expected by most functions in R. However many data sets (for example from excel) do not have this structure. The package also contains functions to reshape data (from long to wide format or vice-versa) or work with nested data, that is tibbles that are stored in single cells of an other table."
  }
]